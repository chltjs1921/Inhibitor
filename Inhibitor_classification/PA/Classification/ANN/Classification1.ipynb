{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Classification1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Tensorflow","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"code","metadata":{"id":"zYumNZ19p-qM","outputId":"740f6ba7-0de5-4b6d-c2f9-40cf327bf27f"},"source":["#ANN StandardScaler 전처리\n","\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense, Dropout, BatchNormalization, Activation\n","from tensorflow.python.keras.utils import np_utils\n","from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from tensorflow.python.keras import regularizers\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n","\n","\n","#seed 값 설정\n","np.random.seed(0)\n","tf.random.set_seed(0)\n","\n","#데이터 입력\n","df = pd.read_csv('./VRK2_inhibitor_descriptor_Internal_dataset_dropunmane.csv')\n","df1 = pd.read_csv('./VRK2_inhibitor_descriptor_external_dataset_dropunmane.csv')\n","df2 = pd.concat([df, df1])\n","\n","#데이터 분류\n","dataset = df.values\n","X = dataset[:,0:-1]\n","Y = dataset[:,-1]\n","#print(Y)\n","\n","ex_data =df1.values\n","exX = ex_data[:,0:-1]\n","exY = ex_data[:,-1]\n","\n","tot_data = df2.values\n","totX = tot_data[:,0:-1]\n","totY = tot_data[:,-1]\n","\n","#X 표준화\n","\n","scaler = StandardScaler()\n","\n","scaler.fit(X)\n","X_scaled = scaler.transform(X)\n","exX_scaled = scaler.transform(exX)\n","totX_scaled = scaler.transform(totX)\n","\n","#원-핫 인코딩\n","Y_encoded =np_utils.to_categorical(Y)\n","exY_encoded = np_utils.to_categorical(exY)\n","\n","#학습셋과 테스트셋을 나눔\n","\n","#X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, random_state=0)\n","\n","#모델 설정\n","\n","n_feat = X.shape[1]\n","n_class = len(set(Y))\n","\n","model = Sequential()\n","model.add(Dense(100, input_dim=n_feat))\n","#model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","#model.add(Dense(500))\n","#model.add(Activation('relu'))\n","#model.add(Dense(60))\n","#model.add(Activation('relu'))\n","model.add(Dense(n_class))\n","model.add(Activation('softmax'))\n","\n","#model.summary()\n","\n","#모델 컴파일\n","model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","#모델 학습\n","model.fit(X_scaled,Y, epochs=10, batch_size=5)\n","\n","#학습 평가\n","\n","print(model.evaluate(X_scaled, Y)[1])\n","print(model.evaluate(exX_scaled, exY)[1])\n","print(model.evaluate(totX_scaled, totY)[1])\n","\n","#testset 정확도 0.6 X 표준화시 0.4 X 정규화시 0.6\n","\n","#데이터셋을 나눈 결과 정확도 0.5\n","\n","\n","#피처별 중요도, 파라미터 튜닝 필요"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","6/6 [==============================] - 0s 2ms/step - loss: 3.1464 - accuracy: 0.3462\n","Epoch 2/10\n","6/6 [==============================] - 0s 3ms/step - loss: 1.5128 - accuracy: 0.6538\n","Epoch 3/10\n","6/6 [==============================] - 0s 3ms/step - loss: 2.1181 - accuracy: 0.8462\n","Epoch 4/10\n","6/6 [==============================] - 0s 3ms/step - loss: 1.4047 - accuracy: 0.7308\n","Epoch 5/10\n","6/6 [==============================] - 0s 3ms/step - loss: 0.7778 - accuracy: 0.8462\n","Epoch 6/10\n","6/6 [==============================] - 0s 4ms/step - loss: 1.3317 - accuracy: 0.8462\n","Epoch 7/10\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3667 - accuracy: 0.8846\n","Epoch 8/10\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.8462\n","Epoch 9/10\n","6/6 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.9615\n","Epoch 10/10\n","6/6 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.8846\n","WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000000005643790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 1000us/step - loss: 0.3173 - accuracy: 0.9231\n","0.9230769276618958\n","1/1 [==============================] - 0s 2ms/step - loss: 16.8897 - accuracy: 0.3333\n","0.3333333432674408\n","WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x0000000005643790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 2ms/step - loss: 3.4246 - accuracy: 0.8125\n","0.8125\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J2m693gqp-qT","outputId":"3a420c52-cfec-4fb3-95ed-242f10d0affe"},"source":["#ANN MinMaxScaler 전처리\n","\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense, Dropout, BatchNormalization, Activation\n","from tensorflow.python.keras.utils import np_utils\n","from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from tensorflow.python.keras import regularizers\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","\n","#seed 값 설정\n","np.random.seed(0)\n","tf.random.set_seed(0)\n","\n","#데이터 입력\n","df = pd.read_csv('./VRK2_inhibitor_descriptor_Internal_dataset_dropunmane.csv')\n","df1 = pd.read_csv('./VRK2_inhibitor_descriptor_external_dataset_dropunmane.csv')\n","df2 = pd.concat([df, df1])\n","\n","#데이터 분류\n","dataset = df.values\n","X = dataset[:,0:-1]\n","Y = dataset[:,-1]\n","#print(Y)\n","\n","ex_data =df1.values\n","exX = ex_data[:,0:-1]\n","exY = ex_data[:,-1]\n","\n","tot_data = df2.values\n","totX = tot_data[:,0:-1]\n","totY = tot_data[:,-1]\n","\n","#X 표준화\n","\n","scaler = MinMaxScaler()\n","\n","scaler.fit(X)\n","X_scaled = scaler.transform(X)\n","exX_scaled = scaler.transform(exX)\n","totX_scaled = scaler.transform(totX)\n","\n","#원-핫 인코딩\n","Y_encoded =np_utils.to_categorical(Y)\n","exY_encoded = np_utils.to_categorical(exY)\n","\n","#학습셋과 테스트셋을 나눔\n","\n","#X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, random_state=0)\n","\n","#모델 설정\n","\n","n_feat = X.shape[1]\n","n_class = len(set(Y))\n","\n","model = Sequential()\n","model.add(Dense(100, input_dim=n_feat))\n","#model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","#model.add(Dense(500))\n","#model.add(Activation('relu'))\n","#model.add(Dense(60))\n","#model.add(Activation('relu'))\n","model.add(Dense(n_class))\n","model.add(Activation('softmax'))\n","\n","#model.summary()\n","\n","#모델 컴파일\n","model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","#모델 학습\n","model.fit(X_scaled,Y, epochs=20, batch_size=5)\n","\n","#학습 평가\n","\n","print(model.evaluate(X_scaled, Y)[1])\n","print(model.evaluate(exX_scaled, exY)[1])\n","print(model.evaluate(totX_scaled, totY)[1])\n","\n","#testset 정확도 0.6 X 표준화시 0.4 X 정규화시 0.6\n","\n","#데이터셋을 나눈 결과 정확도 0.5\n","\n","\n","#피처별 중요도, 파라미터 튜닝 필요"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","6/6 [==============================] - 0s 3ms/step - loss: 2.1249 - accuracy: 0.1923\n","Epoch 2/20\n","6/6 [==============================] - 0s 3ms/step - loss: 1.4861 - accuracy: 0.5385\n","Epoch 3/20\n","6/6 [==============================] - 0s 3ms/step - loss: 1.0565 - accuracy: 0.5000\n","Epoch 4/20\n","6/6 [==============================] - 0s 4ms/step - loss: 0.8643 - accuracy: 0.7308\n","Epoch 5/20\n","6/6 [==============================] - 0s 4ms/step - loss: 1.0524 - accuracy: 0.6154\n","Epoch 6/20\n","6/6 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.7308\n","Epoch 7/20\n","6/6 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7692\n","Epoch 8/20\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.6923\n","Epoch 9/20\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8462\n","Epoch 10/20\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8462\n","Epoch 11/20\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8077\n","Epoch 12/20\n","6/6 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8077\n","Epoch 13/20\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3066 - accuracy: 0.8846\n","Epoch 14/20\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.8846\n","Epoch 15/20\n","6/6 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.9231\n","Epoch 16/20\n","6/6 [==============================] - 0s 5ms/step - loss: 0.2232 - accuracy: 0.9615\n","Epoch 17/20\n","6/6 [==============================] - 0s 6ms/step - loss: 0.2523 - accuracy: 0.9231\n","Epoch 18/20\n","6/6 [==============================] - 0s 4ms/step - loss: 0.2115 - accuracy: 0.9231\n","Epoch 19/20\n","6/6 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.9231\n","Epoch 20/20\n","6/6 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9615\n","WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000000131A3550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 1000us/step - loss: 0.1772 - accuracy: 0.9615\n","0.9615384340286255\n","1/1 [==============================] - 0s 2ms/step - loss: 2.3605 - accuracy: 0.3333\n","0.3333333432674408\n","WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x00000000131A3550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.8438\n","0.84375\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WQm1LqzPp-qV","outputId":"a2863d6e-ed2c-4f6e-a544-ef60a899ad97"},"source":["\n","\n","import sklearn\n","print(sklearn.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.23.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uXYqOfTNp-qV","outputId":"5f8823f7-6af6-4dab-9031-ec0bdae7af3f"},"source":["#하이퍼파라미터 실습 (출처: https://towardsdatascience.com/simple-guide-to-hyperparameter-tuning-in-neural-networks-3fe03dad8594)\n","\n","import tensorflow as tf\n","import keras\n","\n","from keras import layers\n","from keras import models\n","from keras import utils\n","from keras.layers import Dense\n","from keras.models import Sequential\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import Activation\n","from keras.regularizers import l2\n","from keras.optimizers import SGD\n","from keras.optimizers import RMSprop\n","\n","from keras.callbacks import LearningRateScheduler\n","from keras.callbacks import History\n","\n","from keras import losses\n","from sklearn.utils import shuffle\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","\n","#print(tf.__version__): 2.3.0\n","#print(tf.keras.__version__) :2.4.0\n","\n","# fix random seed for reproducibility\n","np.random.seed(5)\n","\n","#데이터 입력\n","df = pd.read_csv('./VRK2_inhibitor_descriptor_Internal_dataset_dropunmane.csv')\n","df1 = pd.read_csv('./VRK2_inhibitor_descriptor_external_dataset_dropunmane.csv')\n","df2 = pd.concat([df, df1])\n","\n","#데이터 분류\n","dataset = df.values\n","X = dataset[:,0:-1]\n","Y = dataset[:,-1]\n","\n","ex_data =df1.values\n","exX = ex_data[:,0:-1]\n","exY = ex_data[:,-1]\n","\n","tot_data = df2.values\n","totX = tot_data[:,0:-1]\n","totY = tot_data[:,-1]\n","\n","#X 표준화\n","\n","scaler = MinMaxScaler()\n","\n","scaler.fit(X)\n","X_scaled = scaler.transform(X)\n","exX_scaled = scaler.transform(exX)\n","totX_scaled = scaler.transform(totX)\n","\n","#epochs=60\n","#learning_rate = 0.1\n","#decay_rate = learning_rate / epochs\n","#momentum = 0.8\n","#n_class = len(set(Y))\n","\n","#sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n","\n","# build the model\n","\n","#input_dim = X_scaled.shape[1]\n","\n","#lr_model = Sequential()\n","#lr_model.add(Dense(64, activation=tf.nn.relu, kernel_initializer='uniform', \n","                #input_dim = input_dim)) \n","#lr_model.add(Dropout(0.1))\n","#lr_model.add(Dense(64, kernel_initializer='uniform', activation=tf.nn.relu))\n","#lr_model.add(Dense(n_class, kernel_initializer='uniform', activation=tf.nn.softmax))\n","\n","# compile the model\n","#lr_model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n","\n","# Fit the model\n","#batch_size = int(input_dim/100)\n","\n","#lr_model_history = lr_model.fit(X_scaled, Y,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(exX_scaled, exY))\n","\n","# Plot the loss function\n","#fig, ax = plt.subplots(1, 1, figsize=(10,6))\n","#ax.plot(np.sqrt(lr_model_history.history['loss']), 'r', label='train')\n","#ax.plot(np.sqrt(lr_model_history.history['val_loss']), 'b' ,label='val')\n","#ax.set_xlabel(r'Epoch', fontsize=20)\n","#ax.set_ylabel(r'Loss', fontsize=20)\n","#ax.legend()\n","#ax.tick_params(labelsize=20)\n","\n","# Plot the accuracy\n","#fig, ax = plt.subplots(1, 1, figsize=(10,6))\n","#ax.plot(np.sqrt(lr_model_history.history['accuracy']), 'r', label='train')\n","#ax.plot(np.sqrt(lr_model_history.history['val_accuracy']), 'b' ,label='val')\n","#ax.set_xlabel(r'Epoch', fontsize=20)\n","#ax.set_ylabel(r'Accuracy', fontsize=20)\n","#ax.legend()\n","#ax.tick_params(labelsize=20)\n","\n","#여기까지 시행한 결과 Epoch 50일 때가 가장 괜찮음\n","\n","#learning rate 교체\n","\n","epochs = 25\n","learning_rate = 0.1 # initial learning rate는 0.1\n","decay_rate = 0.1\n","momentum = 0.8\n","\n","# define the optimizer function\n","sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n","\n","input_dim = X_scaled.shape[1]\n","batch_size = 90\n","n_class = len(set(Y))\n","\n","# build the model\n","exponential_decay_model = Sequential()\n","exponential_decay_model.add(Dense(290, activation=tf.nn.relu, kernel_initializer='uniform', input_dim = input_dim))\n","exponential_decay_model.add(Dropout(0.3))\n","exponential_decay_model.add(Dense(64, kernel_initializer='uniform', activation=tf.nn.relu))\n","exponential_decay_model.add(Dense(n_class, kernel_initializer='uniform', activation=tf.nn.softmax))\n","\n","# compile the model\n","exponential_decay_model.compile(loss='sparse_categorical_crossentropy', \n","                                optimizer=sgd, \n","                                metrics=['accuracy'])\n","                                \n","# define the learning rate change \n","def exp_decay(epoch):\n","    lrate = learning_rate * np.exp(-decay_rate*epoch)\n","    print(lrate)\n","    return lrate\n","    \n","# learning schedule callback\n","loss_history = History()\n","lr_rate = LearningRateScheduler(exp_decay)\n","callbacks_list = [loss_history, lr_rate]\n","\n","# you invoke the LearningRateScheduler during the .fit() phase\n","exponential_decay_model_history = exponential_decay_model.fit(X_scaled, Y,batch_size=batch_size,epochs=epochs,\n","                                                              callbacks=callbacks_list,verbose=1,\n","                                                              validation_data=(exX_scaled, exY))\n","\n","print(exponential_decay_model.evaluate(X_scaled, Y)[1])\n","print(exponential_decay_model.evaluate(exX_scaled, exY)[1])\n","print(exponential_decay_model.evaluate(totX_scaled, totY)[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.1\n","Epoch 1/25\n","1/1 [==============================] - 0s 153ms/step - loss: 1.3833 - accuracy: 0.3077 - val_loss: 1.2941 - val_accuracy: 0.3333\n","0.09048374180359596\n","Epoch 2/25\n","1/1 [==============================] - 0s 16ms/step - loss: 1.3520 - accuracy: 0.4615 - val_loss: 1.2797 - val_accuracy: 0.5000\n","0.0818730753077982\n","Epoch 3/25\n","1/1 [==============================] - 0s 60ms/step - loss: 1.3211 - accuracy: 0.4615 - val_loss: 1.2666 - val_accuracy: 0.5000\n","0.0740818220681718\n","Epoch 4/25\n","1/1 [==============================] - 0s 22ms/step - loss: 1.2821 - accuracy: 0.4231 - val_loss: 1.2609 - val_accuracy: 0.5000\n","0.06703200460356394\n","Epoch 5/25\n","1/1 [==============================] - 0s 32ms/step - loss: 1.2168 - accuracy: 0.5385 - val_loss: 1.2670 - val_accuracy: 0.5000\n","0.06065306597126335\n","Epoch 6/25\n","1/1 [==============================] - ETA: 0s - loss: 1.1726 - accuracy: 0.53 - 0s 30ms/step - loss: 1.1726 - accuracy: 0.5385 - val_loss: 1.2845 - val_accuracy: 0.5000\n","0.05488116360940264\n","Epoch 7/25\n","1/1 [==============================] - 0s 53ms/step - loss: 1.1369 - accuracy: 0.5000 - val_loss: 1.2934 - val_accuracy: 0.3333\n","0.04965853037914095\n","Epoch 8/25\n","1/1 [==============================] - 0s 44ms/step - loss: 1.1532 - accuracy: 0.5385 - val_loss: 1.2713 - val_accuracy: 0.5000\n","0.044932896411722156\n","Epoch 9/25\n","1/1 [==============================] - 0s 36ms/step - loss: 1.0540 - accuracy: 0.6538 - val_loss: 1.2405 - val_accuracy: 0.6667\n","0.04065696597405991\n","Epoch 10/25\n","1/1 [==============================] - 0s 28ms/step - loss: 1.0276 - accuracy: 0.6923 - val_loss: 1.2194 - val_accuracy: 0.6667\n","0.036787944117144235\n","Epoch 11/25\n","1/1 [==============================] - 0s 24ms/step - loss: 0.9707 - accuracy: 0.6923 - val_loss: 1.2063 - val_accuracy: 0.6667\n","0.03328710836980796\n","Epoch 12/25\n","1/1 [==============================] - 0s 29ms/step - loss: 0.9610 - accuracy: 0.6154 - val_loss: 1.1925 - val_accuracy: 0.6667\n","0.030119421191220203\n","Epoch 13/25\n","1/1 [==============================] - 0s 18ms/step - loss: 0.9395 - accuracy: 0.6538 - val_loss: 1.1852 - val_accuracy: 0.6667\n","0.02725317930340126\n","Epoch 14/25\n","1/1 [==============================] - 0s 22ms/step - loss: 0.8940 - accuracy: 0.6923 - val_loss: 1.1737 - val_accuracy: 0.6667\n","0.024659696394160643\n","Epoch 15/25\n","1/1 [==============================] - 0s 17ms/step - loss: 0.8909 - accuracy: 0.6923 - val_loss: 1.1614 - val_accuracy: 0.5000\n","0.022313016014842982\n","Epoch 16/25\n","1/1 [==============================] - 0s 16ms/step - loss: 0.8603 - accuracy: 0.7308 - val_loss: 1.1454 - val_accuracy: 0.5000\n","0.02018965179946554\n","Epoch 17/25\n","1/1 [==============================] - 0s 20ms/step - loss: 0.8792 - accuracy: 0.6154 - val_loss: 1.1239 - val_accuracy: 0.5000\n","0.018268352405273462\n","Epoch 18/25\n","1/1 [==============================] - 0s 18ms/step - loss: 0.8295 - accuracy: 0.6154 - val_loss: 1.0985 - val_accuracy: 0.5000\n","0.016529888822158653\n","Epoch 19/25\n","1/1 [==============================] - 0s 17ms/step - loss: 0.8238 - accuracy: 0.6923 - val_loss: 1.0779 - val_accuracy: 0.5000\n","0.014956861922263504\n","Epoch 20/25\n","1/1 [==============================] - 0s 13ms/step - loss: 0.7993 - accuracy: 0.7692 - val_loss: 1.0618 - val_accuracy: 0.5000\n","0.013533528323661271\n","Epoch 21/25\n","1/1 [==============================] - 0s 15ms/step - loss: 0.7492 - accuracy: 0.7308 - val_loss: 1.0526 - val_accuracy: 0.5000\n","0.012245642825298192\n","Epoch 22/25\n","1/1 [==============================] - 0s 15ms/step - loss: 0.7888 - accuracy: 0.7692 - val_loss: 1.0477 - val_accuracy: 0.5000\n","0.011080315836233388\n","Epoch 23/25\n","1/1 [==============================] - 0s 16ms/step - loss: 0.7561 - accuracy: 0.7308 - val_loss: 1.0453 - val_accuracy: 0.5000\n","0.010025884372280372\n","Epoch 24/25\n","1/1 [==============================] - 0s 17ms/step - loss: 0.7689 - accuracy: 0.7692 - val_loss: 1.0432 - val_accuracy: 0.5000\n","0.009071795328941248\n","Epoch 25/25\n","1/1 [==============================] - 0s 18ms/step - loss: 0.7678 - accuracy: 0.7308 - val_loss: 1.0419 - val_accuracy: 0.5000\n","1/1 [==============================] - 0s 2ms/step - loss: 0.7214 - accuracy: 0.7308\n","0.7307692170143127\n","1/1 [==============================] - 0s 2ms/step - loss: 1.0419 - accuracy: 0.5000\n","0.5\n","1/1 [==============================] - 0s 0s/step - loss: 0.7815 - accuracy: 0.6875\n","0.6875\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YVGczpeFp-qW","scrolled":true,"executionInfo":{"status":"ok","timestamp":1617776929239,"user_tz":-540,"elapsed":3184006,"user":{"displayName":"최은우","photoUrl":"","userId":"09535764796893882081"}},"outputId":"b537c9f6-2799-425c-8297-6ec767b6b5d0"},"source":["#하이퍼파라미터 실습 2(출처:https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)\n","\n","\n","# Use scikit-learn to grid search the batch size and epochs\n","\n","import numpy as np\n","import pandas as pd\n","import joblib\n","\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.layers import Dropout\n","from keras.constraints import maxnorm\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, f1_score\n","from keras.models import load_model\n","from keras.optimizers import Adadelta\n","from scipy.stats import randint, uniform, loguniform\n","from imblearn.over_sampling import SMOTE\n","\n","# fix random seed for reproducibility\n","\n","seed = 0\n","np.random.seed(seed)\n","\n","#데이터 입력\n","df = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/MORDRED_2D/PA_morgan_2D_apppendscore_dropsmiles.csv')\n","data = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/MORDRED_2D/PAOthers_morgan_2D_apppendscore_dropsmiles.csv')\n","\n","#데이터 분류\n","dataset = df.values\n","X = dataset[:,0:-1]\n","Y = dataset[:,-1]\n","\n","data = data.values\n","X_others =data[:,0:-1]\n","Y_others =data[:,-1]\n","\n","#X 표준화\n","\n","scaler = RobustScaler()\n","\n","X_scaled = scaler.fit_transform(X)\n","X_others_scaled = scaler.transform(X_others)\n","\n","#Oversampling using SMOTE\n","\n","#smote = SMOTE(random_state=0)\n","#X_over, Y_over = smote.fit_sample(X_scaled, Y)\n","\n","# Function to create model, required for KerasClassifier\n","input_dim = X_scaled.shape[1]\n","n_class = len(set(Y))\n","\n","def create_model(activation='relu', activation1='softmax', optimizer='adam'):\n","   # create model\n","    model = Sequential()\n","    model.add(Dense(100, input_dim=input_dim , activation=activation))\n","    model.add(Dense(n_class, activation=activation1))\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","\n","# create model\n","model = KerasClassifier(create_model, epochs = 100, batch_size = 10, verbose=0)\n","\n","# define the grid search parameters\n","\n","param_grid = {'activation':['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'], \n","              'activation1':['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'], \n","              'optimizer':['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']}\n","grid = GridSearchCV(model, param_grid, n_jobs=-1, cv=5)\n","grid_result = grid.fit(X_scaled, Y)\n","\n","#정해진 파라미터 'optimizer': 'Adadelta' , 'init_mode': 'lecun_uniform', activation: 'sigmoid' , dropout: 0.3, constraint:5, neuron:290\n","\n","# summarize results\n","#print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","#means = grid_result.cv_results_['mean_test_score']\n","#stds = grid_result.cv_results_['std_test_score']\n","#params = grid_result.cv_results_['params']\n","#for mean, stdev, param in zip(means, stds, params):\n","#    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n","print(grid_result.best_params_)\n","\n","ann = grid_result.best_estimator_   \n","   \n","#print(ann.evaluate(X_scaled, Y)[1])\n","#print(ann.evaluate(exX_scaled, exY)[1])\n","#print(ann.evaluate(totX_scaled, totY)[1])   \n","\n","#결과리포트 생성(단일)\n","\n","#def get_clf_eval(y_test=None, pred=None):\n","#    confusion = confusion_matrix(y_test, pred)\n","#    accuracy = accuracy_score(y_test, pred)\n","#   print('오차행렬')\n","#    print(confusion)\n","#    print('정확도: {0:.4f}'.format(accuracy))\n","\n","#def get_model_train_eval(model, ftr_train=None, ftr_test=None, ftr_tot=None, tgt_train=None, tgt_test=None, tgt_tot=None):\n","#    model.fit(ftr_train, tgt_train)\n","#    pred = model.predict(ftr_train)\n","#    predex = model.predict(ftr_test)\n","#    predtot = model.predict(ftr_tot)\n","#    get_clf_eval(tgt_train, pred)\n","#    get_clf_eval(tgt_test, predex)\n","#    get_clf_eval(tgt_tot, predtot)\n","    \n","#get_model_train_eval(ann, ftr_train=X_scaled, ftr_test=exX_scaled, ftr_tot=totX_scaled, tgt_train=Y, tgt_test=exY, tgt_tot=totY) \n","\n","#top 5 리포트 작성\n","\n","def report(results, n_top=5):\n","    for i in range(1, n_top + 1):\n","        candidates = np.flatnonzero(results['rank_test_score'] == i)\n","        for candidate in candidates:\n","            print(\"Model with rank: {0}\".format(i))\n","            print(\"Parameters: {0}\".format(results['params'][candidate]))\n","            print(\"\") #여기에 accu, conf 추가해야 함\n","            \n","report(grid.cv_results_)            \n","    \n","#정확도와 혼동함수 생성\n","\n","pred = ann.predict(X_scaled)\n","accuracy = accuracy_score(Y, pred)\n","print('ann 정확도: {0:.4f}'.format(accuracy))\n","conf_matrix = confusion_matrix(Y, pred, labels=[0,1,2,3])\n","print(conf_matrix)\n","#conf_matrix_nor = confusion_matrix(Y, pred)/60\n","#print(conf_matrix_nor)\n","\n","pred2 = ann.predict(X_others_scaled)\n","accuracy2 = accuracy_score(Y_others, pred2)\n","print('ann others 정확도: {0:.4f}'.format(accuracy2))\n","conf_matrix2 = confusion_matrix(Y_others, pred2, labels=[0,1,2,3])\n","print(conf_matrix2)\n","#conf_matrix2_nor = confusion_matrix(exY, pred2)/14\n","#print(conf_matrix2_nor)\n","\n","#pred3 = ann.predict(totX_scaled)\n","#accuracy = accuracy_score(totY, pred3)\n","#print('ann 전체 정확도: {0:.4f}'.format(accuracy))\n","#conf_matrix3 = confusion_matrix(totY, pred3)\n","#print(conf_matrix3)\n","#conf_matrix3_nor = confusion_matrix(totY, pred3)/74\n","#print(conf_matrix3_nor)    \n","    \n","#모델 저장\n","\n","#ann.model.save('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/Classification/ANN/PA_ann_0406_02.h5')\n","\n","#0324 total 0.93 test 0.64 0324_2 total 0.95 test 0.71(그치만 과적합) 0324_3 total 0.96 test 0.79"],"execution_count":35,"outputs":[{"output_type":"stream","text":["{'activation': 'softmax', 'activation1': 'hard_sigmoid', 'optimizer': 'SGD'}\n","Model with rank: 1\n","Parameters: {'activation': 'softmax', 'activation1': 'hard_sigmoid', 'optimizer': 'SGD'}\n","\n","Model with rank: 2\n","Parameters: {'activation': 'softmax', 'activation1': 'sigmoid', 'optimizer': 'SGD'}\n","\n","Model with rank: 3\n","Parameters: {'activation': 'softmax', 'activation1': 'softmax', 'optimizer': 'SGD'}\n","\n","Model with rank: 4\n","Parameters: {'activation': 'sigmoid', 'activation1': 'softmax', 'optimizer': 'Adadelta'}\n","\n","Model with rank: 5\n","Parameters: {'activation': 'softmax', 'activation1': 'softplus', 'optimizer': 'SGD'}\n","\n","ann 정확도: 0.5743\n","[[ 0 21  0  0]\n"," [ 0 58  0  0]\n"," [ 0 10  0  0]\n"," [ 0 12  0  0]]\n","ann others 정확도: 0.0000\n","[[ 0 42  0  0]\n"," [ 0  0  0  0]\n"," [ 0  0  0  0]\n"," [ 0  0  0  0]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmeZsNjFp-qa","executionInfo":{"elapsed":5656,"status":"ok","timestamp":1617089126706,"user":{"displayName":"최은우","photoUrl":"","userId":"09535764796893882081"},"user_tz":-540},"outputId":"90cb6964-f430-4436-e0eb-d9ed748e254a"},"source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 8899457230196092810, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 15703311680\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 11924361053094878025\n"," physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZ8iem72p-qd","executionInfo":{"status":"ok","timestamp":1617695460770,"user_tz":-540,"elapsed":17468,"user":{"displayName":"최은우","photoUrl":"","userId":"09535764796893882081"}},"outputId":"9b36094d-171e-4e85-9710-4da27122eb35"},"source":["#ANN 정해진 파라미터로 실험\n","\n","import numpy as np\n","import pandas as pd\n","import joblib\n","\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n","from sklearn.preprocessing import StandardScaler, RobustScaler\n","from keras.models import Sequential, load_model\n","from keras.layers import Dense\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from keras.models import load_model\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# fix random seed for reproducibility\n","\n","seed = 0\n","np.random.seed(seed)\n","\n","#데이터 입력\n","df = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/rdkit_fingerprint/PA_rdkitfingerprint_apppendscore_dropsmiles.csv')\n","\n","#데이터 분류\n","dataset = df.values\n","X = dataset[:,0:-1]\n","Y = dataset[:,-1]\n","\n","#X 표준화\n","\n","scaler = RobustScaler()\n","\n","X_scaled = scaler.fit_transform(X)\n","\n","#데이터셋 쪼개기\n","\n","n_fold = 5\n","skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n","\n","#빈 accu 배열\n","\n","accuracy = []\n","\n","#모델 설정, 컴파일, 실행\n","\n","n_feat = X_scaled.shape[1]\n","n_class = len(set(Y))\n","\n","for train,test in skf.split(X_scaled,Y):\n","    model = Sequential()\n","    model.add(Dense(500, input_dim=n_feat , activation='relu'))\n","    model.add(Dense(n_class, activation='softmax'))\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n","    model.fit(X[train],Y[train], epochs=100, batch_size=10)\n","    k_accuracy = \"%.4f\" % (model.evaluate(X_scaled, Y)[1])\n","    accuracy.append(k_accuracy)\n","\n"," #결과 출력\n"," \n","print('\\n %.f fold accuracy:' % n_fold, accuracy)\n","\n"," #모델 저장   \n","\n","model.save('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/Classification/ANN/PA_ann_0406_01.h5')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Epoch 1/100\n","8/8 [==============================] - 0s 2ms/step - loss: 4.1081 - accuracy: 0.4065\n","Epoch 2/100\n","8/8 [==============================] - 0s 2ms/step - loss: 2.1736 - accuracy: 0.4277\n","Epoch 3/100\n","8/8 [==============================] - 0s 2ms/step - loss: 1.4630 - accuracy: 0.5622\n","Epoch 4/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7978\n","Epoch 5/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8816\n","Epoch 6/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8615\n","Epoch 7/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8355\n","Epoch 8/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6969\n","Epoch 9/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8330\n","Epoch 10/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.8145\n","Epoch 11/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.7710\n","Epoch 12/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8449\n","Epoch 13/100\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8197\n","Epoch 14/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8581\n","Epoch 15/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9030\n","Epoch 16/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9019\n","Epoch 17/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.9341\n","Epoch 18/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9229\n","Epoch 19/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9763\n","Epoch 20/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9116\n","Epoch 21/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9246\n","Epoch 22/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9361\n","Epoch 23/100\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9803\n","Epoch 24/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.9704\n","Epoch 25/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9711\n","Epoch 26/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9752\n","Epoch 27/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9888\n","Epoch 28/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9853\n","Epoch 29/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9916\n","Epoch 30/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9888\n","Epoch 31/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9888\n","Epoch 32/100\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9733\n","Epoch 33/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9795\n","Epoch 34/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9972\n","Epoch 35/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9888\n","Epoch 36/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9956\n","Epoch 37/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9853\n","Epoch 38/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9711\n","Epoch 39/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9535\n","Epoch 40/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9956\n","Epoch 41/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9803\n","Epoch 42/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9972\n","Epoch 43/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9894\n","Epoch 44/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.9368\n","Epoch 45/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9956\n","Epoch 46/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9888\n","Epoch 47/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9795\n","Epoch 48/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9956\n","Epoch 49/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9888\n","Epoch 50/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9910\n","Epoch 51/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9916\n","Epoch 52/100\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9972\n","Epoch 53/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9823\n","Epoch 54/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9851\n","Epoch 55/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9711\n","Epoch 56/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9479\n","Epoch 57/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9656\n","Epoch 58/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9972\n","Epoch 59/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9711\n","Epoch 60/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9956\n","Epoch 61/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.9479\n","Epoch 62/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9826\n","Epoch 63/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.9972\n","Epoch 64/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.9972\n","Epoch 65/100\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9683\n","Epoch 66/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8547\n","Epoch 67/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.7571\n","Epoch 68/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9306\n","Epoch 69/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9766\n","Epoch 70/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9853\n","Epoch 71/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9853\n","Epoch 72/100\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9460\n","Epoch 73/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.9088\n","Epoch 74/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.9349\n","Epoch 75/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9761\n","Epoch 76/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9910\n","Epoch 77/100\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9956\n","Epoch 78/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9739\n","Epoch 79/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9956\n","Epoch 80/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9851\n","Epoch 81/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9938\n","Epoch 82/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9711\n","Epoch 83/100\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9535\n","Epoch 84/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9956\n","Epoch 85/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9826\n","Epoch 86/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9789\n","Epoch 87/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9656\n","Epoch 88/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9851\n","Epoch 89/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9972\n","Epoch 90/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9888\n","Epoch 91/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9888\n","Epoch 92/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9956\n","Epoch 93/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9851\n","Epoch 94/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9853\n","Epoch 95/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9938\n","Epoch 96/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9795\n","Epoch 97/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9789\n","Epoch 98/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9910\n","Epoch 99/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9646\n","Epoch 100/100\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9851\n","4/4 [==============================] - 0s 3ms/step - loss: 9.2339 - accuracy: 0.4158\n","Epoch 1/100\n","9/9 [==============================] - 0s 3ms/step - loss: 4.1208 - accuracy: 0.4837\n","Epoch 2/100\n","9/9 [==============================] - 0s 2ms/step - loss: 2.1378 - accuracy: 0.4261\n","Epoch 3/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.9457 - accuracy: 0.6799\n","Epoch 4/100\n","9/9 [==============================] - 0s 2ms/step - loss: 1.5503 - accuracy: 0.4709\n","Epoch 5/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.9128 - accuracy: 0.6980\n","Epoch 6/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.8951 - accuracy: 0.6602\n","Epoch 7/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.8341\n","Epoch 8/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7996 - accuracy: 0.6317\n","Epoch 9/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8411\n","Epoch 10/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8288\n","Epoch 11/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.7944\n","Epoch 12/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7288 - accuracy: 0.7555\n","Epoch 13/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7351 - accuracy: 0.7213\n","Epoch 14/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.9475\n","Epoch 15/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.9177\n","Epoch 16/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.9021\n","Epoch 17/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.9031\n","Epoch 18/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.9416\n","Epoch 19/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.8807\n","Epoch 20/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.9454\n","Epoch 21/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.9356\n","Epoch 22/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8203\n","Epoch 23/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9615\n","Epoch 24/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.8886\n","Epoch 25/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.9351\n","Epoch 26/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9482\n","Epoch 27/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9558\n","Epoch 28/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9473\n","Epoch 29/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9895\n","Epoch 30/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9949\n","Epoch 31/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9854\n","Epoch 32/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9622\n","Epoch 33/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9728\n","Epoch 34/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9767\n","Epoch 35/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9556\n","Epoch 36/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9607\n","Epoch 37/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9487\n","Epoch 38/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9635\n","Epoch 39/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9620\n","Epoch 40/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9622\n","Epoch 41/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9601\n","Epoch 42/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.9489\n","Epoch 43/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9887\n","Epoch 44/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9707\n","Epoch 45/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9578\n","Epoch 46/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9880\n","Epoch 47/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9692\n","Epoch 48/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1587 - accuracy: 0.9598\n","Epoch 49/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9686\n","Epoch 50/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9932\n","Epoch 51/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9589\n","Epoch 52/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9787\n","Epoch 53/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9949\n","Epoch 54/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9785\n","Epoch 55/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9804\n","Epoch 56/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9431\n","Epoch 57/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9949\n","Epoch 58/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9887\n","Epoch 59/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9912\n","Epoch 60/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9507\n","Epoch 61/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9887\n","Epoch 62/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9666\n","Epoch 63/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9715\n","Epoch 64/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9912\n","Epoch 65/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9963\n","Epoch 66/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 1.0000\n","Epoch 67/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9975\n","Epoch 68/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.8621\n","Epoch 69/100\n","9/9 [==============================] - 0s 2ms/step - loss: 1.3155 - accuracy: 0.6834\n","Epoch 70/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8970\n","Epoch 71/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.8979\n","Epoch 72/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.9154\n","Epoch 73/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8810\n","Epoch 74/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9009\n","Epoch 75/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9594\n","Epoch 76/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9583\n","Epoch 77/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9975\n","Epoch 78/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.8442\n","Epoch 79/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9860\n","Epoch 80/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9887\n","Epoch 81/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9812\n","Epoch 82/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 0.9785\n","Epoch 83/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9844\n","Epoch 84/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9963\n","Epoch 85/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9897\n","Epoch 86/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9816\n","Epoch 87/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9785\n","Epoch 88/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9963\n","Epoch 89/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9690\n","Epoch 90/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9963\n","Epoch 91/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9615\n","Epoch 92/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9735\n","Epoch 93/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9804\n","Epoch 94/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9963\n","Epoch 95/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9804\n","Epoch 96/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9615\n","Epoch 97/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9590\n","Epoch 98/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9666\n","Epoch 99/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9735\n","Epoch 100/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9615\n","4/4 [==============================] - 0s 3ms/step - loss: 2.6462 - accuracy: 0.5347\n","Epoch 1/100\n","9/9 [==============================] - 0s 3ms/step - loss: 4.8648 - accuracy: 0.4598\n","Epoch 2/100\n","9/9 [==============================] - 0s 3ms/step - loss: 2.2540 - accuracy: 0.4117\n","Epoch 3/100\n","9/9 [==============================] - 0s 3ms/step - loss: 1.4421 - accuracy: 0.5470\n","Epoch 4/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.8366 - accuracy: 0.7068\n","Epoch 5/100\n","9/9 [==============================] - 0s 2ms/step - loss: 1.0278 - accuracy: 0.7348\n","Epoch 6/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.8455 - accuracy: 0.6514\n","Epoch 7/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7437 - accuracy: 0.7392\n","Epoch 8/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.7752\n","Epoch 9/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7870 - accuracy: 0.7580\n","Epoch 10/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7985\n","Epoch 11/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8347\n","Epoch 12/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7724\n","Epoch 13/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8189\n","Epoch 14/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8964\n","Epoch 15/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7978\n","Epoch 16/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8148\n","Epoch 17/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.9183\n","Epoch 18/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.9279\n","Epoch 19/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.9040\n","Epoch 20/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.7021\n","Epoch 21/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8899\n","Epoch 22/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9587\n","Epoch 23/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.9476\n","Epoch 24/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8114\n","Epoch 25/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.8604\n","Epoch 26/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.9178\n","Epoch 27/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9231\n","Epoch 28/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.9210\n","Epoch 29/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9283\n","Epoch 30/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9490\n","Epoch 31/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9426\n","Epoch 32/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9433\n","Epoch 33/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.9963\n","Epoch 34/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9426\n","Epoch 35/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9639\n","Epoch 36/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.9492\n","Epoch 37/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.9647\n","Epoch 38/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1067 - accuracy: 0.9454\n","Epoch 39/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9880\n","Epoch 40/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9456\n","Epoch 41/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9782\n","Epoch 42/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9835\n","Epoch 43/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9309\n","Epoch 44/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9673\n","Epoch 45/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9219\n","Epoch 46/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1096 - accuracy: 0.9622\n","Epoch 47/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9731\n","Epoch 48/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9409\n","Epoch 49/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 0.9774\n","Epoch 50/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8416\n","Epoch 51/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9652\n","Epoch 52/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9438\n","Epoch 53/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.7755\n","Epoch 54/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8743\n","Epoch 55/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9621\n","Epoch 56/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9465\n","Epoch 57/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9844\n","Epoch 58/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9752\n","Epoch 59/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9629\n","Epoch 60/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9606\n","Epoch 61/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9506\n","Epoch 62/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9522\n","Epoch 63/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9844\n","Epoch 64/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9850\n","Epoch 65/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9748\n","Epoch 66/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9372\n","Epoch 67/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9779\n","Epoch 68/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9816\n","Epoch 69/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9895\n","Epoch 70/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.9408\n","Epoch 71/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9626\n","Epoch 72/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9589\n","Epoch 73/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9485\n","Epoch 74/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9640\n","Epoch 75/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9802\n","Epoch 76/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9799\n","Epoch 77/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9616\n","Epoch 78/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9652\n","Epoch 79/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9469\n","Epoch 80/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9686\n","Epoch 81/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9875\n","Epoch 82/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9615\n","Epoch 83/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9911\n","Epoch 84/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9776\n","Epoch 85/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9737\n","Epoch 86/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9844\n","Epoch 87/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9666\n","Epoch 88/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9850\n","Epoch 89/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9824\n","Epoch 90/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9619\n","Epoch 91/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9765\n","Epoch 92/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9875\n","Epoch 93/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9539\n","Epoch 94/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9672\n","Epoch 95/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9569\n","Epoch 96/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9735\n","Epoch 97/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9875\n","Epoch 98/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9844\n","Epoch 99/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9411\n","Epoch 100/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.8697\n","4/4 [==============================] - 0s 4ms/step - loss: 1.0277 - accuracy: 0.7822\n","Epoch 1/100\n","9/9 [==============================] - 0s 2ms/step - loss: 4.4368 - accuracy: 0.3324\n","Epoch 2/100\n","9/9 [==============================] - 0s 2ms/step - loss: 2.7279 - accuracy: 0.2591\n","Epoch 3/100\n","9/9 [==============================] - 0s 2ms/step - loss: 1.4989 - accuracy: 0.6720\n","Epoch 4/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7702 - accuracy: 0.7444\n","Epoch 5/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.6909\n","Epoch 6/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.7395\n","Epoch 7/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.9742 - accuracy: 0.7098\n","Epoch 8/100\n","9/9 [==============================] - 0s 2ms/step - loss: 1.4398 - accuracy: 0.6277\n","Epoch 9/100\n","9/9 [==============================] - 0s 2ms/step - loss: 1.6585 - accuracy: 0.6993\n","Epoch 10/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7249 - accuracy: 0.6595\n","Epoch 11/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.8196 - accuracy: 0.7092\n","Epoch 12/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.7227\n","Epoch 13/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.7014\n","Epoch 14/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8657\n","Epoch 15/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.7381\n","Epoch 16/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.8491\n","Epoch 17/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7583\n","Epoch 18/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8022\n","Epoch 19/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2430 - accuracy: 0.9433\n","Epoch 20/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9048\n","Epoch 21/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.9070\n","Epoch 22/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1897 - accuracy: 0.9210\n","Epoch 23/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1640 - accuracy: 0.9731\n","Epoch 24/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1987 - accuracy: 0.9023\n","Epoch 25/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9210\n","Epoch 26/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9596\n","Epoch 27/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7839\n","Epoch 28/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.8802\n","Epoch 29/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7870\n","Epoch 30/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9606\n","Epoch 31/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9729\n","Epoch 32/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9627\n","Epoch 33/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9447\n","Epoch 34/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9544\n","Epoch 35/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9561\n","Epoch 36/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8485\n","Epoch 37/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8947\n","Epoch 38/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9363\n","Epoch 39/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9584\n","Epoch 40/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0921 - accuracy: 0.9672\n","Epoch 41/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9547\n","Epoch 42/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9709\n","Epoch 43/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8746\n","Epoch 44/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8340\n","Epoch 45/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8518\n","Epoch 46/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.8986\n","Epoch 47/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8547\n","Epoch 48/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9789\n","Epoch 49/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9255\n","Epoch 50/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9434\n","Epoch 51/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9502\n","Epoch 52/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.9585\n","Epoch 53/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9887\n","Epoch 54/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9792\n","Epoch 55/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9273\n","Epoch 56/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1588 - accuracy: 0.9785\n","Epoch 57/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9857\n","Epoch 58/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9539\n","Epoch 59/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9615\n","Epoch 60/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9507\n","Epoch 61/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8761\n","Epoch 62/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9456\n","Epoch 63/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9802\n","Epoch 64/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9963\n","Epoch 65/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9850\n","Epoch 66/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9819\n","Epoch 67/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9570\n","Epoch 68/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9804\n","Epoch 69/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9604\n","Epoch 70/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9850\n","Epoch 71/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.8529\n","Epoch 72/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.8752\n","Epoch 73/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9075\n","Epoch 74/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9380\n","Epoch 75/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9426\n","Epoch 76/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9376\n","Epoch 77/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7936\n","Epoch 78/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9670\n","Epoch 79/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9432\n","Epoch 80/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9218\n","Epoch 81/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.9444\n","Epoch 82/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9641\n","Epoch 83/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9785\n","Epoch 84/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9875\n","Epoch 85/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9394\n","Epoch 86/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9698\n","Epoch 87/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9539\n","Epoch 88/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9779\n","Epoch 89/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8798\n","Epoch 90/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8515\n","Epoch 91/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1246 - accuracy: 0.9690\n","Epoch 92/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9237\n","Epoch 93/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9738\n","Epoch 94/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.9082\n","Epoch 95/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.9565\n","Epoch 96/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9670\n","Epoch 97/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9875\n","Epoch 98/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9816\n","Epoch 99/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9471\n","Epoch 100/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9553\n","4/4 [==============================] - 0s 4ms/step - loss: 8.9191 - accuracy: 0.3168\n","Epoch 1/100\n","9/9 [==============================] - 0s 3ms/step - loss: 4.5033 - accuracy: 0.4014\n","Epoch 2/100\n","9/9 [==============================] - 0s 2ms/step - loss: 2.5878 - accuracy: 0.4541\n","Epoch 3/100\n","9/9 [==============================] - 0s 2ms/step - loss: 1.5449 - accuracy: 0.6084\n","Epoch 4/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.9040 - accuracy: 0.6109\n","Epoch 5/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.8518 - accuracy: 0.6709\n","Epoch 6/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.8296\n","Epoch 7/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7672 - accuracy: 0.6298\n","Epoch 8/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7911 - accuracy: 0.7049\n","Epoch 9/100\n","9/9 [==============================] - 0s 2ms/step - loss: 1.1404 - accuracy: 0.7015\n","Epoch 10/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6607\n","Epoch 11/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.7536 - accuracy: 0.7291\n","Epoch 12/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8106\n","Epoch 13/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7757\n","Epoch 14/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7187\n","Epoch 15/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.7828\n","Epoch 16/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.7636\n","Epoch 17/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7851\n","Epoch 18/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7832\n","Epoch 19/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8222\n","Epoch 20/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8586\n","Epoch 21/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.9334\n","Epoch 22/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8413\n","Epoch 23/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8814\n","Epoch 24/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.9718\n","Epoch 25/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9534\n","Epoch 26/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1760 - accuracy: 0.9494\n","Epoch 27/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2573 - accuracy: 0.8785\n","Epoch 28/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.9448\n","Epoch 29/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9681\n","Epoch 30/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8244\n","Epoch 31/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9584\n","Epoch 32/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9854\n","Epoch 33/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1782 - accuracy: 0.9622\n","Epoch 34/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9200\n","Epoch 35/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.8957\n","Epoch 36/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8670\n","Epoch 37/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9698\n","Epoch 38/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1338 - accuracy: 0.9612\n","Epoch 39/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.9411\n","Epoch 40/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9321\n","Epoch 41/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9654\n","Epoch 42/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0823 - accuracy: 0.9912\n","Epoch 43/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9963\n","Epoch 44/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1070 - accuracy: 0.9779\n","Epoch 45/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1149 - accuracy: 0.9766\n","Epoch 46/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.9963\n","Epoch 47/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0845 - accuracy: 0.9802\n","Epoch 48/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.9747\n","Epoch 49/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9887\n","Epoch 50/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9907\n","Epoch 51/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8774\n","Epoch 52/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.6981 - accuracy: 0.7841\n","Epoch 53/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.8220\n","Epoch 54/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2836 - accuracy: 0.9129\n","Epoch 55/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9875\n","Epoch 56/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.8902\n","Epoch 57/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9880\n","Epoch 58/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9844\n","Epoch 59/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 1.0000\n","Epoch 60/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9615\n","Epoch 61/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9615\n","Epoch 62/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9547\n","Epoch 63/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9844\n","Epoch 64/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1761 - accuracy: 0.9223\n","Epoch 65/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9949\n","Epoch 66/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9875\n","Epoch 67/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9963\n","Epoch 68/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9557\n","Epoch 69/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9912\n","Epoch 70/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9932\n","Epoch 71/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9887\n","Epoch 72/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.2192 - accuracy: 0.9427\n","Epoch 73/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1403 - accuracy: 0.9173\n","Epoch 74/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9887\n","Epoch 75/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9766\n","Epoch 76/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9963\n","Epoch 77/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9932\n","Epoch 78/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9932\n","Epoch 79/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9932\n","Epoch 80/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9670\n","Epoch 81/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9932\n","Epoch 82/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9949\n","Epoch 83/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9835\n","Epoch 84/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9887\n","Epoch 85/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9912\n","Epoch 86/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9715\n","Epoch 87/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9949\n","Epoch 88/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9854\n","Epoch 89/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9932\n","Epoch 90/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9615\n","Epoch 91/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9672\n","Epoch 92/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9568\n","Epoch 93/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9949\n","Epoch 94/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9666\n","Epoch 95/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9963\n","Epoch 96/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9816\n","Epoch 97/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 1.0000\n","Epoch 98/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9887\n","Epoch 99/100\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9963\n","Epoch 100/100\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 1.0000\n","4/4 [==============================] - 0s 4ms/step - loss: 1.9476 - accuracy: 0.6238\n","\n"," 5 fold accuracy: ['0.4158', '0.5347', '0.7822', '0.3168', '0.6238']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xppe7M02p-qe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617243402699,"user_tz":-540,"elapsed":298116,"user":{"displayName":"최은우","photoUrl":"","userId":"09535764796893882081"}},"outputId":"280cbf43-baba-4a2c-ec6a-a6afab593732"},"source":["#핸즈온 머신러닝을 활용한 ann 튜닝\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import pandas as pd\n","import joblib\n","\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.layers import Dropout, InputLayer\n","from keras.constraints import maxnorm\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, f1_score\n","from keras.models import load_model\n","from keras.optimizers import SGD\n","from scipy.stats import randint, uniform, loguniform\n","from imblearn.over_sampling import SMOTE\n","from keras.callbacks import EarlyStopping\n","from scipy.stats import reciprocal\n","\n","# fix random seed for reproducibility\n","\n","seed = 7\n","np.random.seed(seed)\n","\n","#데이터 입력\n","df = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/csv/PA_inhibitor_descriptor_internal_dataset.csv')\n","df1 = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/csv/PA_inhibitor_descriptor_external_dataset.csv')\n","df2 = pd.concat([df, df1])\n","\n","#데이터 분류\n","dataset = df.values\n","X = dataset[:,0:-1]\n","Y = dataset[:,-1]\n","\n","ex_data =df1.values\n","exX = ex_data[:,0:-1]\n","exY = ex_data[:,-1]\n","\n","tot_data = df2.values\n","totX = tot_data[:,0:-1]\n","totY = tot_data[:,-1]\n","\n","#X 표준화\n","\n","scaler = StandardScaler()\n","\n","scaler.fit(X)\n","X_scaled = scaler.transform(X)\n","exX_scaled = scaler.transform(exX)\n","totX_scaled = scaler.transform(totX)\n","\n","#모델 만들고 컴파일하는 함수 생성\n","\n","input_dim = X_scaled.shape[1]\n","n_class = 4\n","\n","def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=input_dim):\n","    model = Sequential()\n","    model.add(InputLayer(input_shape=input_dim))\n","    for layer in range(n_hidden):\n","        model.add(Dense(n_neurons, activation='relu'))\n","    model.add(Dense(n_class))\n","    optimizer = SGD(learning_rate)\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","\n","#함수 파라미터 튜닝에 적용\n","\n","clf = KerasClassifier(build_model) \n","\n","clf.fit(X_scaled, Y, epochs=100, batch_size = 10, validation_data=(exX_scaled, exY), callbacks=[EarlyStopping(patience=10)])\n","mse_test = clf.score(exX_scaled, exY)\n","pred = clf.predict(exX_scaled)  \n","\n","param_distribs = {\"n_hidden\": [0,1,2,3], \"n_neurons\": [10,20,30,40,50,60,70,80,90,100],'learning_rate':[3e-5, 3e-4, 3e-3, 2e-3, 1e-3]}\n","\n","clf_cv = RandomizedSearchCV(clf, param_distribs, n_iter=20, cv=5)\n","clf_cv.fit(X_scaled, Y, epochs=100, validation_data=(exX_scaled, exY), callbacks=[EarlyStopping(patience=10)])  \n","\n","#top20 결과 리포트\n","\n","def report(results, n_top=20):\n","    for i in range(1, n_top + 1):\n","        candidates = np.flatnonzero(results['rank_test_score'] == i)\n","        for candidate in candidates:\n","            print(\"Model with rank: {0}\".format(i))\n","            print(\"Parameters: {0}\".format(results['params'][candidate]))\n","            print(\"\") #여기에 accu, conf 추가해야 함\n","            \n","report(clf_cv.cv_results_) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Epoch 1/100\n","10/10 [==============================] - 1s 24ms/step - loss: 9.4286 - accuracy: 0.3427 - val_loss: 10.6730 - val_accuracy: 0.3000\n","Epoch 2/100\n","10/10 [==============================] - 0s 7ms/step - loss: 9.4143 - accuracy: 0.3052 - val_loss: 9.8224 - val_accuracy: 0.3000\n","Epoch 3/100\n","10/10 [==============================] - 0s 6ms/step - loss: 7.4907 - accuracy: 0.3960 - val_loss: 9.0913 - val_accuracy: 0.3000\n","Epoch 4/100\n","10/10 [==============================] - 0s 8ms/step - loss: 6.9714 - accuracy: 0.4250 - val_loss: 9.8498 - val_accuracy: 0.3000\n","Epoch 5/100\n","10/10 [==============================] - 0s 6ms/step - loss: 6.8797 - accuracy: 0.4364 - val_loss: 9.7723 - val_accuracy: 0.3000\n","Epoch 6/100\n","10/10 [==============================] - 0s 7ms/step - loss: 7.8309 - accuracy: 0.3967 - val_loss: 10.5140 - val_accuracy: 0.3000\n","Epoch 7/100\n","10/10 [==============================] - 0s 6ms/step - loss: 7.7313 - accuracy: 0.3491 - val_loss: 10.5107 - val_accuracy: 0.3000\n","Epoch 8/100\n","10/10 [==============================] - 0s 6ms/step - loss: 6.6036 - accuracy: 0.3846 - val_loss: 10.5100 - val_accuracy: 0.3000\n","Epoch 9/100\n","10/10 [==============================] - 0s 6ms/step - loss: 6.6841 - accuracy: 0.3825 - val_loss: 10.5018 - val_accuracy: 0.3000\n","Epoch 10/100\n","10/10 [==============================] - 0s 6ms/step - loss: 8.3277 - accuracy: 0.3640 - val_loss: 10.5255 - val_accuracy: 0.3000\n","Epoch 11/100\n","10/10 [==============================] - 0s 7ms/step - loss: 7.1836 - accuracy: 0.4184 - val_loss: 10.5185 - val_accuracy: 0.3000\n","Epoch 12/100\n","10/10 [==============================] - 0s 6ms/step - loss: 7.5062 - accuracy: 0.3999 - val_loss: 10.4878 - val_accuracy: 0.3000\n","Epoch 13/100\n","10/10 [==============================] - 0s 7ms/step - loss: 7.3004 - accuracy: 0.4177 - val_loss: 10.4649 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 136ms/step - loss: 10.4649 - accuracy: 0.3000\n","Epoch 1/100\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","3/3 [==============================] - 0s 22ms/step - loss: 4.8525 - accuracy: 0.3195 - val_loss: 5.0943 - val_accuracy: 0.3500\n","Epoch 32/100\n","3/3 [==============================] - 0s 23ms/step - loss: 4.7100 - accuracy: 0.3117 - val_loss: 5.0752 - val_accuracy: 0.3500\n","Epoch 33/100\n","3/3 [==============================] - 0s 22ms/step - loss: 4.5699 - accuracy: 0.3312 - val_loss: 4.5519 - val_accuracy: 0.3500\n","Epoch 34/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.3846 - accuracy: 0.3117 - val_loss: 5.4285 - val_accuracy: 0.3000\n","Epoch 35/100\n","3/3 [==============================] - 0s 23ms/step - loss: 3.6661 - accuracy: 0.3138 - val_loss: 3.7007 - val_accuracy: 0.4000\n","Epoch 36/100\n","3/3 [==============================] - 0s 22ms/step - loss: 4.9374 - accuracy: 0.3234 - val_loss: 4.1106 - val_accuracy: 0.4000\n","Epoch 37/100\n","3/3 [==============================] - 0s 23ms/step - loss: 4.0485 - accuracy: 0.3351 - val_loss: 3.7247 - val_accuracy: 0.4500\n","Epoch 38/100\n","3/3 [==============================] - 0s 23ms/step - loss: 4.4825 - accuracy: 0.3020 - val_loss: 3.7153 - val_accuracy: 0.4500\n","Epoch 39/100\n","3/3 [==============================] - 0s 22ms/step - loss: 4.0674 - accuracy: 0.2893 - val_loss: 3.1382 - val_accuracy: 0.3500\n","Epoch 40/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.1326 - accuracy: 0.3077 - val_loss: 6.3057 - val_accuracy: 0.2500\n","Epoch 41/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.3278 - accuracy: 0.2622 - val_loss: 6.2531 - val_accuracy: 0.2500\n","Epoch 42/100\n","3/3 [==============================] - 0s 22ms/step - loss: 5.1331 - accuracy: 0.2378 - val_loss: 5.7371 - val_accuracy: 0.2500\n","Epoch 43/100\n","3/3 [==============================] - 0s 22ms/step - loss: 4.7161 - accuracy: 0.2612 - val_loss: 5.7351 - val_accuracy: 0.2500\n","Epoch 44/100\n","3/3 [==============================] - 0s 22ms/step - loss: 4.5115 - accuracy: 0.2690 - val_loss: 5.7948 - val_accuracy: 0.2500\n","Epoch 45/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.9614 - accuracy: 0.2456 - val_loss: 5.7743 - val_accuracy: 0.3000\n","Epoch 46/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.0577 - accuracy: 0.2612 - val_loss: 5.7547 - val_accuracy: 0.2500\n","Epoch 47/100\n","3/3 [==============================] - 0s 22ms/step - loss: 4.1740 - accuracy: 0.3020 - val_loss: 5.5297 - val_accuracy: 0.2500\n","Epoch 48/100\n","3/3 [==============================] - 0s 22ms/step - loss: 4.3932 - accuracy: 0.2942 - val_loss: 5.6543 - val_accuracy: 0.2500\n","Epoch 49/100\n","3/3 [==============================] - 0s 22ms/step - loss: 4.3267 - accuracy: 0.3049 - val_loss: 6.1034 - val_accuracy: 0.3500\n","1/1 [==============================] - 0s 131ms/step - loss: 8.2386 - accuracy: 0.3684\n","Epoch 1/100\n","3/3 [==============================] - 1s 98ms/step - loss: 7.7277 - accuracy: 0.2640 - val_loss: 2.6143 - val_accuracy: 0.6500\n","Epoch 2/100\n","3/3 [==============================] - 0s 22ms/step - loss: 7.3721 - accuracy: 0.2445 - val_loss: 2.6111 - val_accuracy: 0.7000\n","Epoch 3/100\n","3/3 [==============================] - 0s 24ms/step - loss: 7.4473 - accuracy: 0.2992 - val_loss: 2.6097 - val_accuracy: 0.7000\n","Epoch 4/100\n","3/3 [==============================] - 0s 23ms/step - loss: 7.4345 - accuracy: 0.2601 - val_loss: 2.6071 - val_accuracy: 0.7000\n","Epoch 5/100\n","3/3 [==============================] - 0s 25ms/step - loss: 7.7697 - accuracy: 0.2640 - val_loss: 2.6053 - val_accuracy: 0.7000\n","Epoch 6/100\n","3/3 [==============================] - 0s 24ms/step - loss: 7.0976 - accuracy: 0.2679 - val_loss: 2.6040 - val_accuracy: 0.7000\n","Epoch 7/100\n","3/3 [==============================] - 0s 22ms/step - loss: 7.4518 - accuracy: 0.2445 - val_loss: 2.6020 - val_accuracy: 0.7000\n","Epoch 8/100\n","3/3 [==============================] - 0s 22ms/step - loss: 7.5907 - accuracy: 0.2523 - val_loss: 2.5984 - val_accuracy: 0.7000\n","Epoch 9/100\n","3/3 [==============================] - 0s 23ms/step - loss: 7.4323 - accuracy: 0.2679 - val_loss: 2.5945 - val_accuracy: 0.7000\n","Epoch 10/100\n","3/3 [==============================] - 0s 23ms/step - loss: 7.5643 - accuracy: 0.2679 - val_loss: 2.5931 - val_accuracy: 0.7000\n","Epoch 11/100\n","3/3 [==============================] - 0s 23ms/step - loss: 7.4246 - accuracy: 0.2953 - val_loss: 2.5910 - val_accuracy: 0.7000\n","Epoch 12/100\n","3/3 [==============================] - 0s 24ms/step - loss: 7.3474 - accuracy: 0.2640 - val_loss: 2.5893 - val_accuracy: 0.7000\n","Epoch 13/100\n","3/3 [==============================] - 0s 24ms/step - loss: 7.1604 - accuracy: 0.2601 - val_loss: 2.5880 - val_accuracy: 0.7000\n","Epoch 14/100\n","3/3 [==============================] - 0s 22ms/step - loss: 7.3350 - accuracy: 0.2601 - val_loss: 2.5857 - val_accuracy: 0.7000\n","Epoch 15/100\n","3/3 [==============================] - 0s 22ms/step - loss: 7.5641 - accuracy: 0.2719 - val_loss: 2.5851 - val_accuracy: 0.7000\n","Epoch 16/100\n","3/3 [==============================] - 0s 23ms/step - loss: 7.1414 - accuracy: 0.2640 - val_loss: 2.5831 - val_accuracy: 0.7000\n","Epoch 17/100\n","3/3 [==============================] - 0s 25ms/step - loss: 7.3710 - accuracy: 0.2719 - val_loss: 2.5820 - val_accuracy: 0.7000\n","Epoch 18/100\n","3/3 [==============================] - 0s 23ms/step - loss: 7.1842 - accuracy: 0.2836 - val_loss: 2.5807 - val_accuracy: 0.7000\n","Epoch 19/100\n","3/3 [==============================] - 0s 22ms/step - loss: 7.1617 - accuracy: 0.2836 - val_loss: 2.5802 - val_accuracy: 0.7000\n","Epoch 20/100\n","3/3 [==============================] - 0s 23ms/step - loss: 7.3984 - accuracy: 0.2640 - val_loss: 2.5787 - val_accuracy: 0.7000\n","Epoch 21/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.6925 - accuracy: 0.2921 - val_loss: 1.8078 - val_accuracy: 0.6000\n","Epoch 22/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.8046 - accuracy: 0.3127 - val_loss: 1.8076 - val_accuracy: 0.6000\n","Epoch 23/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.9653 - accuracy: 0.2893 - val_loss: 1.8064 - val_accuracy: 0.6000\n","Epoch 24/100\n","3/3 [==============================] - 0s 22ms/step - loss: 5.8018 - accuracy: 0.3088 - val_loss: 1.8053 - val_accuracy: 0.6000\n","Epoch 25/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.0987 - accuracy: 0.3283 - val_loss: 1.8034 - val_accuracy: 0.6000\n","Epoch 26/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.1829 - accuracy: 0.2971 - val_loss: 1.8025 - val_accuracy: 0.6000\n","Epoch 27/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.8497 - accuracy: 0.3166 - val_loss: 1.8013 - val_accuracy: 0.6000\n","Epoch 28/100\n","3/3 [==============================] - 0s 22ms/step - loss: 5.8647 - accuracy: 0.2893 - val_loss: 1.8009 - val_accuracy: 0.6000\n","Epoch 29/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.3922 - accuracy: 0.3127 - val_loss: 1.8001 - val_accuracy: 0.6000\n","Epoch 30/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.9325 - accuracy: 0.2815 - val_loss: 1.7993 - val_accuracy: 0.6000\n","Epoch 31/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.1462 - accuracy: 0.2893 - val_loss: 1.7986 - val_accuracy: 0.6000\n","Epoch 32/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.7862 - accuracy: 0.3049 - val_loss: 1.7975 - val_accuracy: 0.6000\n","Epoch 33/100\n","3/3 [==============================] - 0s 21ms/step - loss: 6.0638 - accuracy: 0.2815 - val_loss: 1.7965 - val_accuracy: 0.6000\n","Epoch 34/100\n","3/3 [==============================] - 0s 22ms/step - loss: 5.7137 - accuracy: 0.2932 - val_loss: 1.7951 - val_accuracy: 0.6000\n","Epoch 35/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.4908 - accuracy: 0.2893 - val_loss: 1.7942 - val_accuracy: 0.6000\n","Epoch 36/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.6778 - accuracy: 0.2971 - val_loss: 1.7934 - val_accuracy: 0.6000\n","Epoch 37/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.7503 - accuracy: 0.3361 - val_loss: 1.7927 - val_accuracy: 0.6000\n","Epoch 38/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.8854 - accuracy: 0.3205 - val_loss: 1.7918 - val_accuracy: 0.6000\n","Epoch 39/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.2479 - accuracy: 0.2736 - val_loss: 1.7915 - val_accuracy: 0.6000\n","Epoch 40/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.8984 - accuracy: 0.3166 - val_loss: 1.7908 - val_accuracy: 0.6000\n","Epoch 41/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.3654 - accuracy: 0.2697 - val_loss: 1.7904 - val_accuracy: 0.6000\n","Epoch 42/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.6267 - accuracy: 0.3166 - val_loss: 1.7899 - val_accuracy: 0.6000\n","Epoch 43/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.2498 - accuracy: 0.2971 - val_loss: 1.7888 - val_accuracy: 0.6000\n","Epoch 44/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.7073 - accuracy: 0.3127 - val_loss: 1.7882 - val_accuracy: 0.6000\n","Epoch 45/100\n","3/3 [==============================] - 0s 22ms/step - loss: 5.4083 - accuracy: 0.3049 - val_loss: 1.7873 - val_accuracy: 0.6000\n","Epoch 46/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.7160 - accuracy: 0.3283 - val_loss: 1.7869 - val_accuracy: 0.6000\n","Epoch 47/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.2422 - accuracy: 0.3244 - val_loss: 2.3433 - val_accuracy: 0.5000\n","Epoch 48/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.1991 - accuracy: 0.2164 - val_loss: 2.3445 - val_accuracy: 0.5000\n","Epoch 49/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.4502 - accuracy: 0.2125 - val_loss: 2.3447 - val_accuracy: 0.5000\n","Epoch 50/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.6015 - accuracy: 0.2203 - val_loss: 2.3448 - val_accuracy: 0.5000\n","Epoch 51/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.3921 - accuracy: 0.2281 - val_loss: 2.3453 - val_accuracy: 0.5000\n","Epoch 52/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.3127 - accuracy: 0.2281 - val_loss: 2.3455 - val_accuracy: 0.5000\n","Epoch 53/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.7175 - accuracy: 0.2594 - val_loss: 2.3456 - val_accuracy: 0.5000\n","Epoch 54/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.9806 - accuracy: 0.2477 - val_loss: 2.3459 - val_accuracy: 0.5000\n","Epoch 55/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.3974 - accuracy: 0.2164 - val_loss: 2.3481 - val_accuracy: 0.5000\n","Epoch 56/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.5870 - accuracy: 0.2008 - val_loss: 2.3480 - val_accuracy: 0.5000\n","1/1 [==============================] - 0s 133ms/step - loss: 3.2302 - accuracy: 0.4211\n","Epoch 1/100\n","3/3 [==============================] - 1s 110ms/step - loss: 6.2891 - accuracy: 0.2661 - val_loss: 4.8742 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.5365 - accuracy: 0.2388 - val_loss: 4.8726 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 28ms/step - loss: 5.8785 - accuracy: 0.2740 - val_loss: 4.8712 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.7114 - accuracy: 0.2427 - val_loss: 4.8699 - val_accuracy: 0.2000\n","Epoch 5/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.7522 - accuracy: 0.2505 - val_loss: 4.8692 - val_accuracy: 0.2000\n","Epoch 6/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.5328 - accuracy: 0.2661 - val_loss: 4.8667 - val_accuracy: 0.2000\n","Epoch 7/100\n","3/3 [==============================] - 0s 22ms/step - loss: 6.2831 - accuracy: 0.2935 - val_loss: 4.8650 - val_accuracy: 0.2000\n","Epoch 8/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.5831 - accuracy: 0.2935 - val_loss: 4.8639 - val_accuracy: 0.2000\n","Epoch 9/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.7071 - accuracy: 0.2896 - val_loss: 4.8631 - val_accuracy: 0.2000\n","Epoch 10/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.4107 - accuracy: 0.2622 - val_loss: 4.8607 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.3321 - accuracy: 0.2740 - val_loss: 4.8592 - val_accuracy: 0.2000\n","Epoch 12/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.5461 - accuracy: 0.2622 - val_loss: 4.8578 - val_accuracy: 0.2000\n","Epoch 13/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.5887 - accuracy: 0.2427 - val_loss: 4.8568 - val_accuracy: 0.2000\n","Epoch 14/100\n","3/3 [==============================] - 0s 29ms/step - loss: 6.0527 - accuracy: 0.2661 - val_loss: 4.8543 - val_accuracy: 0.2000\n","Epoch 15/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.9076 - accuracy: 0.2896 - val_loss: 4.8529 - val_accuracy: 0.2000\n","Epoch 16/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.2111 - accuracy: 0.2661 - val_loss: 4.8512 - val_accuracy: 0.2000\n","Epoch 17/100\n","3/3 [==============================] - 0s 22ms/step - loss: 5.9586 - accuracy: 0.3091 - val_loss: 4.8500 - val_accuracy: 0.2000\n","Epoch 18/100\n","3/3 [==============================] - 0s 23ms/step - loss: 7.0332 - accuracy: 0.2388 - val_loss: 4.8493 - val_accuracy: 0.2000\n","Epoch 19/100\n","3/3 [==============================] - 0s 22ms/step - loss: 6.3136 - accuracy: 0.2622 - val_loss: 4.8485 - val_accuracy: 0.2000\n","Epoch 20/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.8258 - accuracy: 0.2779 - val_loss: 4.8480 - val_accuracy: 0.2000\n","Epoch 21/100\n","3/3 [==============================] - 0s 22ms/step - loss: 6.6990 - accuracy: 0.2388 - val_loss: 4.8472 - val_accuracy: 0.2000\n","Epoch 22/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.5912 - accuracy: 0.2740 - val_loss: 4.8466 - val_accuracy: 0.2000\n","Epoch 23/100\n","3/3 [==============================] - 0s 21ms/step - loss: 6.1483 - accuracy: 0.2661 - val_loss: 4.8459 - val_accuracy: 0.2000\n","Epoch 24/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.0522 - accuracy: 0.3130 - val_loss: 4.8454 - val_accuracy: 0.2000\n","Epoch 25/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.3647 - accuracy: 0.2349 - val_loss: 4.8448 - val_accuracy: 0.2000\n","Epoch 26/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.8822 - accuracy: 0.2896 - val_loss: 4.8440 - val_accuracy: 0.2000\n","Epoch 27/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.3123 - accuracy: 0.2622 - val_loss: 4.8428 - val_accuracy: 0.2000\n","Epoch 28/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.2173 - accuracy: 0.2583 - val_loss: 4.8424 - val_accuracy: 0.2000\n","Epoch 29/100\n","3/3 [==============================] - 0s 21ms/step - loss: 6.5694 - accuracy: 0.2661 - val_loss: 4.8413 - val_accuracy: 0.2000\n","Epoch 30/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.4589 - accuracy: 0.2427 - val_loss: 4.8408 - val_accuracy: 0.2000\n","Epoch 31/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.4484 - accuracy: 0.2857 - val_loss: 4.8400 - val_accuracy: 0.2000\n","Epoch 32/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.3769 - accuracy: 0.2505 - val_loss: 4.8404 - val_accuracy: 0.2000\n","Epoch 33/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.9962 - accuracy: 0.3146 - val_loss: 4.8406 - val_accuracy: 0.2000\n","Epoch 34/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.6420 - accuracy: 0.2599 - val_loss: 4.8403 - val_accuracy: 0.2000\n","Epoch 35/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.1379 - accuracy: 0.2795 - val_loss: 4.8397 - val_accuracy: 0.2000\n","Epoch 36/100\n","3/3 [==============================] - 0s 22ms/step - loss: 6.1075 - accuracy: 0.2951 - val_loss: 4.8387 - val_accuracy: 0.2000\n","Epoch 37/100\n","3/3 [==============================] - 0s 22ms/step - loss: 5.9544 - accuracy: 0.2951 - val_loss: 4.8389 - val_accuracy: 0.2000\n","Epoch 38/100\n","3/3 [==============================] - 0s 22ms/step - loss: 5.9264 - accuracy: 0.3264 - val_loss: 4.8384 - val_accuracy: 0.2000\n","Epoch 39/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.9422 - accuracy: 0.3185 - val_loss: 4.8373 - val_accuracy: 0.2000\n","Epoch 40/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.5517 - accuracy: 0.2599 - val_loss: 4.8381 - val_accuracy: 0.2000\n","Epoch 41/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.2327 - accuracy: 0.2795 - val_loss: 4.8366 - val_accuracy: 0.2000\n","Epoch 42/100\n","3/3 [==============================] - 0s 22ms/step - loss: 6.0161 - accuracy: 0.2834 - val_loss: 4.8361 - val_accuracy: 0.2000\n","Epoch 43/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.0517 - accuracy: 0.3029 - val_loss: 4.8356 - val_accuracy: 0.2000\n","Epoch 44/100\n","3/3 [==============================] - 0s 28ms/step - loss: 6.0966 - accuracy: 0.2912 - val_loss: 4.8349 - val_accuracy: 0.2000\n","Epoch 45/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.1750 - accuracy: 0.3146 - val_loss: 4.8343 - val_accuracy: 0.2000\n","Epoch 46/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.1043 - accuracy: 0.3107 - val_loss: 4.8335 - val_accuracy: 0.2000\n","Epoch 47/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.1670 - accuracy: 0.2951 - val_loss: 4.8332 - val_accuracy: 0.2000\n","Epoch 48/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.7023 - accuracy: 0.3185 - val_loss: 4.8340 - val_accuracy: 0.2000\n","Epoch 49/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.0972 - accuracy: 0.3029 - val_loss: 4.8340 - val_accuracy: 0.2000\n","Epoch 50/100\n","3/3 [==============================] - 0s 27ms/step - loss: 6.3673 - accuracy: 0.3068 - val_loss: 4.8337 - val_accuracy: 0.2000\n","Epoch 51/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.3350 - accuracy: 0.2951 - val_loss: 4.8337 - val_accuracy: 0.2500\n","Epoch 52/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.8109 - accuracy: 0.3146 - val_loss: 4.8333 - val_accuracy: 0.2500\n","Epoch 53/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.9150 - accuracy: 0.2834 - val_loss: 4.8333 - val_accuracy: 0.2500\n","Epoch 54/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.9942 - accuracy: 0.2912 - val_loss: 4.8340 - val_accuracy: 0.2500\n","Epoch 55/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.3017 - accuracy: 0.2678 - val_loss: 4.8344 - val_accuracy: 0.2500\n","Epoch 56/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.1410 - accuracy: 0.2912 - val_loss: 4.8329 - val_accuracy: 0.2500\n","Epoch 57/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.6786 - accuracy: 0.2756 - val_loss: 4.8327 - val_accuracy: 0.2500\n","Epoch 58/100\n","3/3 [==============================] - 0s 22ms/step - loss: 6.6595 - accuracy: 0.2795 - val_loss: 4.8313 - val_accuracy: 0.2500\n","Epoch 59/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.3812 - accuracy: 0.3068 - val_loss: 4.8305 - val_accuracy: 0.2500\n","Epoch 60/100\n","3/3 [==============================] - 0s 28ms/step - loss: 6.4096 - accuracy: 0.2795 - val_loss: 4.8294 - val_accuracy: 0.2500\n","Epoch 61/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.9179 - accuracy: 0.2834 - val_loss: 4.8285 - val_accuracy: 0.2500\n","Epoch 62/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.0370 - accuracy: 0.3146 - val_loss: 4.8281 - val_accuracy: 0.2500\n","Epoch 63/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.0696 - accuracy: 0.3146 - val_loss: 4.8278 - val_accuracy: 0.2500\n","Epoch 64/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.0712 - accuracy: 0.3146 - val_loss: 4.8255 - val_accuracy: 0.2500\n","Epoch 65/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.1328 - accuracy: 0.2951 - val_loss: 4.8245 - val_accuracy: 0.2500\n","Epoch 66/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.1287 - accuracy: 0.2873 - val_loss: 4.8241 - val_accuracy: 0.2500\n","Epoch 67/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.0927 - accuracy: 0.2951 - val_loss: 4.8235 - val_accuracy: 0.2500\n","Epoch 68/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.6543 - accuracy: 0.2873 - val_loss: 4.8231 - val_accuracy: 0.2500\n","Epoch 69/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.0589 - accuracy: 0.3174 - val_loss: 4.8232 - val_accuracy: 0.2500\n","Epoch 70/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.2746 - accuracy: 0.2666 - val_loss: 4.8208 - val_accuracy: 0.2500\n","Epoch 71/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.2726 - accuracy: 0.3057 - val_loss: 4.8206 - val_accuracy: 0.2500\n","Epoch 72/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.1978 - accuracy: 0.2979 - val_loss: 4.8198 - val_accuracy: 0.2500\n","Epoch 73/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.3634 - accuracy: 0.2705 - val_loss: 4.8193 - val_accuracy: 0.2500\n","Epoch 74/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.3071 - accuracy: 0.3330 - val_loss: 4.8198 - val_accuracy: 0.2500\n","Epoch 75/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.3663 - accuracy: 0.2979 - val_loss: 4.8209 - val_accuracy: 0.2500\n","Epoch 76/100\n","3/3 [==============================] - 0s 27ms/step - loss: 6.3563 - accuracy: 0.2940 - val_loss: 4.8207 - val_accuracy: 0.2500\n","Epoch 77/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.5269 - accuracy: 0.3018 - val_loss: 4.8204 - val_accuracy: 0.2500\n","Epoch 78/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.0994 - accuracy: 0.2783 - val_loss: 4.8207 - val_accuracy: 0.2500\n","Epoch 79/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.7737 - accuracy: 0.2822 - val_loss: 4.8203 - val_accuracy: 0.2500\n","Epoch 80/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.1574 - accuracy: 0.3057 - val_loss: 4.8199 - val_accuracy: 0.2500\n","Epoch 81/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.0730 - accuracy: 0.3018 - val_loss: 4.8203 - val_accuracy: 0.2500\n","Epoch 82/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.2997 - accuracy: 0.3096 - val_loss: 4.8187 - val_accuracy: 0.2500\n","Epoch 83/100\n","3/3 [==============================] - 0s 27ms/step - loss: 6.0236 - accuracy: 0.2940 - val_loss: 4.8177 - val_accuracy: 0.2500\n","Epoch 84/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.1019 - accuracy: 0.3135 - val_loss: 4.8177 - val_accuracy: 0.2500\n","Epoch 85/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.5508 - accuracy: 0.2928 - val_loss: 4.8188 - val_accuracy: 0.2500\n","Epoch 86/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.0493 - accuracy: 0.3006 - val_loss: 4.8194 - val_accuracy: 0.2500\n","Epoch 87/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.4117 - accuracy: 0.3084 - val_loss: 4.8205 - val_accuracy: 0.2500\n","Epoch 88/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.4119 - accuracy: 0.3280 - val_loss: 4.8209 - val_accuracy: 0.2500\n","Epoch 89/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.7998 - accuracy: 0.3397 - val_loss: 4.8210 - val_accuracy: 0.2500\n","Epoch 90/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.8721 - accuracy: 0.3045 - val_loss: 4.8222 - val_accuracy: 0.2500\n","Epoch 91/100\n","3/3 [==============================] - 0s 28ms/step - loss: 6.3508 - accuracy: 0.3202 - val_loss: 4.8225 - val_accuracy: 0.2500\n","Epoch 92/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.0577 - accuracy: 0.3123 - val_loss: 4.8250 - val_accuracy: 0.2500\n","Epoch 93/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.8073 - accuracy: 0.2928 - val_loss: 4.8248 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 139ms/step - loss: 3.7931 - accuracy: 0.2222\n","Epoch 1/100\n","3/3 [==============================] - 1s 102ms/step - loss: 9.7761 - accuracy: 0.1135 - val_loss: 11.1501 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 25ms/step - loss: 9.7664 - accuracy: 0.1370 - val_loss: 11.1462 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 25ms/step - loss: 8.9533 - accuracy: 0.1409 - val_loss: 10.6248 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 24ms/step - loss: 9.3961 - accuracy: 0.1214 - val_loss: 10.3341 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 23ms/step - loss: 8.7738 - accuracy: 0.1264 - val_loss: 10.3116 - val_accuracy: 0.2000\n","Epoch 6/100\n","3/3 [==============================] - 0s 25ms/step - loss: 8.8832 - accuracy: 0.1453 - val_loss: 10.2973 - val_accuracy: 0.2000\n","Epoch 7/100\n","3/3 [==============================] - 0s 27ms/step - loss: 9.1666 - accuracy: 0.1609 - val_loss: 10.2895 - val_accuracy: 0.2000\n","Epoch 8/100\n","3/3 [==============================] - 0s 24ms/step - loss: 9.6180 - accuracy: 0.1453 - val_loss: 10.2709 - val_accuracy: 0.2000\n","Epoch 9/100\n","3/3 [==============================] - 0s 25ms/step - loss: 9.0140 - accuracy: 0.1609 - val_loss: 10.2621 - val_accuracy: 0.2000\n","Epoch 10/100\n","3/3 [==============================] - 0s 24ms/step - loss: 8.3624 - accuracy: 0.1832 - val_loss: 10.2308 - val_accuracy: 0.2500\n","Epoch 11/100\n","3/3 [==============================] - 0s 23ms/step - loss: 8.8378 - accuracy: 0.1597 - val_loss: 10.1757 - val_accuracy: 0.2500\n","Epoch 12/100\n","3/3 [==============================] - 0s 24ms/step - loss: 8.2057 - accuracy: 0.1988 - val_loss: 9.6421 - val_accuracy: 0.2500\n","Epoch 13/100\n","3/3 [==============================] - 0s 25ms/step - loss: 8.3810 - accuracy: 0.2055 - val_loss: 10.1436 - val_accuracy: 0.2500\n","Epoch 14/100\n","3/3 [==============================] - 0s 24ms/step - loss: 8.0933 - accuracy: 0.1898 - val_loss: 9.6183 - val_accuracy: 0.2500\n","Epoch 15/100\n","3/3 [==============================] - 0s 23ms/step - loss: 7.7279 - accuracy: 0.2016 - val_loss: 9.6143 - val_accuracy: 0.2500\n","Epoch 16/100\n","3/3 [==============================] - 0s 29ms/step - loss: 8.1765 - accuracy: 0.1898 - val_loss: 9.6107 - val_accuracy: 0.2500\n","Epoch 17/100\n","3/3 [==============================] - 0s 24ms/step - loss: 7.7944 - accuracy: 0.2211 - val_loss: 11.9230 - val_accuracy: 0.2000\n","Epoch 18/100\n","3/3 [==============================] - 0s 25ms/step - loss: 10.1049 - accuracy: 0.1096 - val_loss: 11.9143 - val_accuracy: 0.2000\n","Epoch 19/100\n","3/3 [==============================] - 0s 28ms/step - loss: 9.9656 - accuracy: 0.1292 - val_loss: 11.9062 - val_accuracy: 0.2000\n","Epoch 20/100\n","3/3 [==============================] - 0s 26ms/step - loss: 10.1514 - accuracy: 0.1253 - val_loss: 11.8995 - val_accuracy: 0.2000\n","Epoch 21/100\n","3/3 [==============================] - 0s 28ms/step - loss: 10.1912 - accuracy: 0.1214 - val_loss: 11.8909 - val_accuracy: 0.2000\n","Epoch 22/100\n","3/3 [==============================] - 0s 23ms/step - loss: 9.8388 - accuracy: 0.1292 - val_loss: 11.8823 - val_accuracy: 0.2000\n","Epoch 23/100\n","3/3 [==============================] - 0s 23ms/step - loss: 10.1488 - accuracy: 0.1135 - val_loss: 11.8737 - val_accuracy: 0.2000\n","Epoch 24/100\n","3/3 [==============================] - 0s 26ms/step - loss: 10.0767 - accuracy: 0.1214 - val_loss: 11.8515 - val_accuracy: 0.2000\n","Epoch 25/100\n","3/3 [==============================] - 0s 23ms/step - loss: 9.1870 - accuracy: 0.1593 - val_loss: 11.8321 - val_accuracy: 0.2000\n","Epoch 26/100\n","3/3 [==============================] - 0s 28ms/step - loss: 9.5307 - accuracy: 0.1436 - val_loss: 11.8100 - val_accuracy: 0.2000\n","1/1 [==============================] - 0s 129ms/step - loss: 5.4299 - accuracy: 0.4444\n","Epoch 1/100\n","3/3 [==============================] - 1s 99ms/step - loss: 7.9102 - accuracy: 0.2776 - val_loss: 7.0392 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 25ms/step - loss: 7.4304 - accuracy: 0.2776 - val_loss: 6.3422 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.6919 - accuracy: 0.3593 - val_loss: 7.0472 - val_accuracy: 0.2500\n","Epoch 4/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.0031 - accuracy: 0.3486 - val_loss: 6.4656 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.7401 - accuracy: 0.3330 - val_loss: 6.3895 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.5701 - accuracy: 0.3564 - val_loss: 6.4391 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.6202 - accuracy: 0.3486 - val_loss: 6.4018 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.3199 - accuracy: 0.3095 - val_loss: 6.3793 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.5157 - accuracy: 0.3486 - val_loss: 6.3559 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.7286 - accuracy: 0.3408 - val_loss: 6.3398 - val_accuracy: 0.2500\n","Epoch 11/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.9513 - accuracy: 0.3564 - val_loss: 6.3270 - val_accuracy: 0.2500\n","Epoch 12/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.6037 - accuracy: 0.3486 - val_loss: 6.3206 - val_accuracy: 0.2500\n","Epoch 13/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.5314 - accuracy: 0.3369 - val_loss: 6.3169 - val_accuracy: 0.2500\n","Epoch 14/100\n","3/3 [==============================] - 0s 28ms/step - loss: 5.6691 - accuracy: 0.3174 - val_loss: 5.8285 - val_accuracy: 0.2500\n","Epoch 15/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.5118 - accuracy: 0.3720 - val_loss: 6.3051 - val_accuracy: 0.2500\n","Epoch 16/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.4566 - accuracy: 0.3788 - val_loss: 5.6889 - val_accuracy: 0.2500\n","Epoch 17/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.3194 - accuracy: 0.3554 - val_loss: 5.7032 - val_accuracy: 0.2500\n","Epoch 18/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.5398 - accuracy: 0.3632 - val_loss: 5.6810 - val_accuracy: 0.2500\n","Epoch 19/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.4595 - accuracy: 0.3632 - val_loss: 5.6649 - val_accuracy: 0.2500\n","Epoch 20/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.6033 - accuracy: 0.3280 - val_loss: 5.6524 - val_accuracy: 0.2500\n","Epoch 21/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.7184 - accuracy: 0.3515 - val_loss: 5.6472 - val_accuracy: 0.2500\n","Epoch 22/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.9326 - accuracy: 0.3358 - val_loss: 5.6433 - val_accuracy: 0.2500\n","Epoch 23/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.0780 - accuracy: 0.3280 - val_loss: 5.6327 - val_accuracy: 0.2500\n","Epoch 24/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.2457 - accuracy: 0.3934 - val_loss: 5.6202 - val_accuracy: 0.2500\n","Epoch 25/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.2120 - accuracy: 0.3934 - val_loss: 5.6002 - val_accuracy: 0.2500\n","Epoch 26/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.5141 - accuracy: 0.3309 - val_loss: 5.6003 - val_accuracy: 0.2500\n","Epoch 27/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.5547 - accuracy: 0.3777 - val_loss: 5.6008 - val_accuracy: 0.2500\n","Epoch 28/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.5817 - accuracy: 0.3856 - val_loss: 5.5929 - val_accuracy: 0.2500\n","Epoch 29/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.4786 - accuracy: 0.3582 - val_loss: 5.5832 - val_accuracy: 0.2500\n","Epoch 30/100\n","3/3 [==============================] - 0s 25ms/step - loss: 4.7552 - accuracy: 0.3856 - val_loss: 5.5781 - val_accuracy: 0.2500\n","Epoch 31/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.4636 - accuracy: 0.3777 - val_loss: 5.5681 - val_accuracy: 0.2500\n","Epoch 32/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.4382 - accuracy: 0.3699 - val_loss: 5.5600 - val_accuracy: 0.2500\n","Epoch 33/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.3170 - accuracy: 0.3621 - val_loss: 5.5455 - val_accuracy: 0.2500\n","Epoch 34/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.0012 - accuracy: 0.3621 - val_loss: 5.5405 - val_accuracy: 0.2500\n","Epoch 35/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.7302 - accuracy: 0.3426 - val_loss: 5.5125 - val_accuracy: 0.2500\n","Epoch 36/100\n","3/3 [==============================] - 0s 27ms/step - loss: 4.8083 - accuracy: 0.4197 - val_loss: 5.5039 - val_accuracy: 0.2500\n","Epoch 37/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.3758 - accuracy: 0.3572 - val_loss: 5.4990 - val_accuracy: 0.2500\n","Epoch 38/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.0482 - accuracy: 0.3806 - val_loss: 5.4960 - val_accuracy: 0.2500\n","Epoch 39/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.4368 - accuracy: 0.3689 - val_loss: 5.4921 - val_accuracy: 0.2500\n","Epoch 40/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.5197 - accuracy: 0.3572 - val_loss: 5.4925 - val_accuracy: 0.2500\n","Epoch 41/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.2260 - accuracy: 0.3923 - val_loss: 5.4886 - val_accuracy: 0.2500\n","Epoch 42/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.0611 - accuracy: 0.3767 - val_loss: 5.4887 - val_accuracy: 0.2500\n","Epoch 43/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.0322 - accuracy: 0.3884 - val_loss: 5.4865 - val_accuracy: 0.2500\n","Epoch 44/100\n","3/3 [==============================] - 0s 27ms/step - loss: 4.6714 - accuracy: 0.4236 - val_loss: 5.4828 - val_accuracy: 0.2500\n","Epoch 45/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.0871 - accuracy: 0.4040 - val_loss: 5.4779 - val_accuracy: 0.2500\n","Epoch 46/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.4435 - accuracy: 0.3884 - val_loss: 5.4783 - val_accuracy: 0.2500\n","Epoch 47/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.5569 - accuracy: 0.3689 - val_loss: 5.4740 - val_accuracy: 0.2500\n","Epoch 48/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.1866 - accuracy: 0.3611 - val_loss: 5.4689 - val_accuracy: 0.2500\n","Epoch 49/100\n","3/3 [==============================] - 0s 24ms/step - loss: 4.8196 - accuracy: 0.4040 - val_loss: 5.4675 - val_accuracy: 0.2500\n","Epoch 50/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.0187 - accuracy: 0.4001 - val_loss: 5.4659 - val_accuracy: 0.2500\n","Epoch 51/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.2885 - accuracy: 0.3717 - val_loss: 5.4658 - val_accuracy: 0.2500\n","Epoch 52/100\n","3/3 [==============================] - 0s 28ms/step - loss: 5.4545 - accuracy: 0.3561 - val_loss: 5.4607 - val_accuracy: 0.2500\n","Epoch 53/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.0823 - accuracy: 0.3639 - val_loss: 5.4575 - val_accuracy: 0.2500\n","Epoch 54/100\n","3/3 [==============================] - 0s 24ms/step - loss: 4.9619 - accuracy: 0.4254 - val_loss: 5.4605 - val_accuracy: 0.2500\n","Epoch 55/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.2658 - accuracy: 0.3756 - val_loss: 5.4536 - val_accuracy: 0.2500\n","Epoch 56/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.4233 - accuracy: 0.4097 - val_loss: 5.4503 - val_accuracy: 0.2500\n","Epoch 57/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.1624 - accuracy: 0.3913 - val_loss: 5.4499 - val_accuracy: 0.2500\n","Epoch 58/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.1175 - accuracy: 0.4254 - val_loss: 5.4458 - val_accuracy: 0.2500\n","Epoch 59/100\n","3/3 [==============================] - 0s 27ms/step - loss: 4.7020 - accuracy: 0.4058 - val_loss: 5.4475 - val_accuracy: 0.2500\n","Epoch 60/100\n","3/3 [==============================] - 0s 24ms/step - loss: 5.1982 - accuracy: 0.3941 - val_loss: 5.4442 - val_accuracy: 0.2500\n","Epoch 61/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.9379 - accuracy: 0.4303 - val_loss: 5.4322 - val_accuracy: 0.2500\n","Epoch 62/100\n","3/3 [==============================] - 0s 23ms/step - loss: 4.8333 - accuracy: 0.4097 - val_loss: 5.4282 - val_accuracy: 0.2500\n","Epoch 63/100\n","3/3 [==============================] - 0s 23ms/step - loss: 4.9100 - accuracy: 0.4193 - val_loss: 5.4260 - val_accuracy: 0.2500\n","Epoch 64/100\n","3/3 [==============================] - 0s 22ms/step - loss: 4.7516 - accuracy: 0.4350 - val_loss: 5.4222 - val_accuracy: 0.2500\n","Epoch 65/100\n","3/3 [==============================] - 0s 23ms/step - loss: 5.0241 - accuracy: 0.4389 - val_loss: 5.4232 - val_accuracy: 0.2500\n","Epoch 66/100\n","3/3 [==============================] - 0s 24ms/step - loss: 4.7773 - accuracy: 0.4428 - val_loss: 5.4208 - val_accuracy: 0.2500\n","Epoch 67/100\n","3/3 [==============================] - 0s 25ms/step - loss: 5.1549 - accuracy: 0.3998 - val_loss: 5.4175 - val_accuracy: 0.2500\n","Epoch 68/100\n","3/3 [==============================] - 0s 24ms/step - loss: 4.8836 - accuracy: 0.4350 - val_loss: 5.4137 - val_accuracy: 0.2500\n","Epoch 69/100\n","3/3 [==============================] - 0s 22ms/step - loss: 4.8541 - accuracy: 0.4272 - val_loss: 5.4098 - val_accuracy: 0.2500\n","Epoch 70/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.9535 - accuracy: 0.4662 - val_loss: 5.3979 - val_accuracy: 0.2500\n","Epoch 71/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.0329 - accuracy: 0.4378 - val_loss: 5.4009 - val_accuracy: 0.2500\n","Epoch 72/100\n","3/3 [==============================] - 0s 24ms/step - loss: 4.7125 - accuracy: 0.4311 - val_loss: 5.4006 - val_accuracy: 0.2500\n","Epoch 73/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.5542 - accuracy: 0.4701 - val_loss: 5.3930 - val_accuracy: 0.2500\n","Epoch 74/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.7095 - accuracy: 0.3920 - val_loss: 5.3927 - val_accuracy: 0.2500\n","Epoch 75/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.4053 - accuracy: 0.4389 - val_loss: 5.3903 - val_accuracy: 0.2500\n","Epoch 76/100\n","3/3 [==============================] - 0s 24ms/step - loss: 4.2241 - accuracy: 0.3959 - val_loss: 5.3947 - val_accuracy: 0.2500\n","Epoch 77/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.9544 - accuracy: 0.4613 - val_loss: 5.3915 - val_accuracy: 0.2500\n","Epoch 78/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.7588 - accuracy: 0.4534 - val_loss: 5.3777 - val_accuracy: 0.2500\n","Epoch 79/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.9511 - accuracy: 0.4691 - val_loss: 5.3715 - val_accuracy: 0.2500\n","Epoch 80/100\n","3/3 [==============================] - 0s 23ms/step - loss: 4.2692 - accuracy: 0.4456 - val_loss: 5.3638 - val_accuracy: 0.2500\n","Epoch 81/100\n","3/3 [==============================] - 0s 23ms/step - loss: 4.3618 - accuracy: 0.4417 - val_loss: 5.3529 - val_accuracy: 0.2500\n","Epoch 82/100\n","3/3 [==============================] - 0s 24ms/step - loss: 4.4236 - accuracy: 0.4485 - val_loss: 5.3428 - val_accuracy: 0.2500\n","Epoch 83/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.9301 - accuracy: 0.4836 - val_loss: 5.3282 - val_accuracy: 0.2500\n","Epoch 84/100\n","3/3 [==============================] - 0s 23ms/step - loss: 4.7157 - accuracy: 0.4105 - val_loss: 5.3028 - val_accuracy: 0.2500\n","Epoch 85/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.9855 - accuracy: 0.4573 - val_loss: 5.2054 - val_accuracy: 0.2500\n","Epoch 86/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.3314 - accuracy: 0.4456 - val_loss: 4.6249 - val_accuracy: 0.3000\n","Epoch 87/100\n","3/3 [==============================] - 0s 24ms/step - loss: 4.0305 - accuracy: 0.4417 - val_loss: 4.6238 - val_accuracy: 0.3000\n","Epoch 88/100\n","3/3 [==============================] - 0s 27ms/step - loss: 4.0745 - accuracy: 0.4534 - val_loss: 4.6205 - val_accuracy: 0.3000\n","Epoch 89/100\n","3/3 [==============================] - 0s 24ms/step - loss: 4.1354 - accuracy: 0.4730 - val_loss: 4.6212 - val_accuracy: 0.3000\n","Epoch 90/100\n","3/3 [==============================] - 0s 23ms/step - loss: 4.3446 - accuracy: 0.4378 - val_loss: 4.6969 - val_accuracy: 0.3000\n","Epoch 91/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.7907 - accuracy: 0.4524 - val_loss: 4.6933 - val_accuracy: 0.3000\n","Epoch 92/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.3267 - accuracy: 0.4250 - val_loss: 4.6914 - val_accuracy: 0.3000\n","Epoch 93/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.1788 - accuracy: 0.4680 - val_loss: 4.6887 - val_accuracy: 0.3000\n","Epoch 94/100\n","3/3 [==============================] - 0s 25ms/step - loss: 4.2684 - accuracy: 0.4758 - val_loss: 4.6848 - val_accuracy: 0.3000\n","Epoch 95/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.7101 - accuracy: 0.4875 - val_loss: 4.6105 - val_accuracy: 0.3000\n","Epoch 96/100\n","3/3 [==============================] - 0s 24ms/step - loss: 4.9919 - accuracy: 0.4815 - val_loss: 8.9795 - val_accuracy: 0.3500\n","Epoch 97/100\n","3/3 [==============================] - 0s 26ms/step - loss: 7.0047 - accuracy: 0.4215 - val_loss: 8.9728 - val_accuracy: 0.3500\n","Epoch 98/100\n","3/3 [==============================] - 0s 29ms/step - loss: 6.6031 - accuracy: 0.4477 - val_loss: 8.9716 - val_accuracy: 0.3500\n","Epoch 99/100\n","3/3 [==============================] - 0s 25ms/step - loss: 7.0119 - accuracy: 0.4243 - val_loss: 8.9703 - val_accuracy: 0.3500\n","Epoch 100/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.4157 - accuracy: 0.4477 - val_loss: 8.9693 - val_accuracy: 0.3500\n","1/1 [==============================] - 0s 127ms/step - loss: 11.3149 - accuracy: 0.2632\n","Epoch 1/100\n","3/3 [==============================] - 1s 98ms/step - loss: 7.2376 - accuracy: 0.2786 - val_loss: 5.3804 - val_accuracy: 0.4500\n","Epoch 2/100\n","3/3 [==============================] - 0s 27ms/step - loss: 6.8977 - accuracy: 0.3205 - val_loss: 5.3873 - val_accuracy: 0.4500\n","Epoch 3/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.6495 - accuracy: 0.3283 - val_loss: 5.3958 - val_accuracy: 0.4500\n","Epoch 4/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.9484 - accuracy: 0.3077 - val_loss: 5.4119 - val_accuracy: 0.4500\n","Epoch 5/100\n","3/3 [==============================] - 0s 28ms/step - loss: 6.8444 - accuracy: 0.3156 - val_loss: 5.4276 - val_accuracy: 0.4500\n","Epoch 6/100\n","3/3 [==============================] - 0s 25ms/step - loss: 7.1989 - accuracy: 0.2765 - val_loss: 5.4543 - val_accuracy: 0.4500\n","Epoch 7/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.3674 - accuracy: 0.3195 - val_loss: 5.5130 - val_accuracy: 0.4500\n","Epoch 8/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.3246 - accuracy: 0.3390 - val_loss: 6.0916 - val_accuracy: 0.4500\n","Epoch 9/100\n","3/3 [==============================] - 0s 25ms/step - loss: 6.6045 - accuracy: 0.3195 - val_loss: 6.1005 - val_accuracy: 0.4500\n","Epoch 10/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.9325 - accuracy: 0.3273 - val_loss: 6.1145 - val_accuracy: 0.4500\n","Epoch 11/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.9228 - accuracy: 0.2999 - val_loss: 6.1349 - val_accuracy: 0.4500\n","1/1 [==============================] - 0s 124ms/step - loss: 10.8653 - accuracy: 0.1053\n","Epoch 1/100\n","3/3 [==============================] - 1s 100ms/step - loss: 6.7186 - accuracy: 0.4371 - val_loss: 12.1820 - val_accuracy: 0.1500\n","Epoch 2/100\n","3/3 [==============================] - 0s 28ms/step - loss: 7.2163 - accuracy: 0.3980 - val_loss: 12.1770 - val_accuracy: 0.1500\n","Epoch 3/100\n","3/3 [==============================] - 0s 28ms/step - loss: 6.9361 - accuracy: 0.4136 - val_loss: 12.1714 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 28ms/step - loss: 7.4526 - accuracy: 0.3824 - val_loss: 12.1669 - val_accuracy: 0.1000\n","Epoch 5/100\n","3/3 [==============================] - 0s 25ms/step - loss: 7.5106 - accuracy: 0.4254 - val_loss: 12.1616 - val_accuracy: 0.1000\n","Epoch 6/100\n","3/3 [==============================] - 0s 26ms/step - loss: 7.0467 - accuracy: 0.4399 - val_loss: 12.1558 - val_accuracy: 0.1000\n","Epoch 7/100\n","3/3 [==============================] - 0s 25ms/step - loss: 7.6785 - accuracy: 0.4193 - val_loss: 12.1501 - val_accuracy: 0.1000\n","Epoch 8/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.8660 - accuracy: 0.4701 - val_loss: 11.6002 - val_accuracy: 0.1000\n","Epoch 9/100\n","3/3 [==============================] - 0s 24ms/step - loss: 7.1509 - accuracy: 0.4428 - val_loss: 12.1332 - val_accuracy: 0.1000\n","Epoch 10/100\n","3/3 [==============================] - 0s 24ms/step - loss: 6.7956 - accuracy: 0.4808 - val_loss: 12.1264 - val_accuracy: 0.1000\n","Epoch 11/100\n","3/3 [==============================] - 0s 27ms/step - loss: 7.0144 - accuracy: 0.4573 - val_loss: 12.1205 - val_accuracy: 0.1000\n","Epoch 12/100\n","3/3 [==============================] - 0s 29ms/step - loss: 7.1915 - accuracy: 0.4534 - val_loss: 12.1135 - val_accuracy: 0.0500\n","Epoch 13/100\n","3/3 [==============================] - 0s 23ms/step - loss: 6.8303 - accuracy: 0.4613 - val_loss: 12.1056 - val_accuracy: 0.0500\n","Epoch 14/100\n","3/3 [==============================] - 0s 24ms/step - loss: 7.4671 - accuracy: 0.4378 - val_loss: 12.0982 - val_accuracy: 0.0500\n","Epoch 15/100\n","3/3 [==============================] - 0s 28ms/step - loss: 7.3009 - accuracy: 0.4534 - val_loss: 12.0910 - val_accuracy: 0.0500\n","Epoch 16/100\n","3/3 [==============================] - 0s 26ms/step - loss: 7.4751 - accuracy: 0.4300 - val_loss: 12.0822 - val_accuracy: 0.0500\n","Epoch 17/100\n","3/3 [==============================] - 0s 25ms/step - loss: 7.3926 - accuracy: 0.4222 - val_loss: 12.0721 - val_accuracy: 0.0500\n","Epoch 18/100\n","3/3 [==============================] - 0s 27ms/step - loss: 7.1266 - accuracy: 0.4222 - val_loss: 12.0668 - val_accuracy: 0.0500\n","1/1 [==============================] - 0s 133ms/step - loss: 10.7558 - accuracy: 0.2632\n","Epoch 1/100\n","3/3 [==============================] - 0s 94ms/step - loss: 4.3482 - accuracy: 0.2689 - val_loss: 8.2054 - val_accuracy: 0.1000\n","Epoch 2/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.4157 - accuracy: 0.3080 - val_loss: 8.2048 - val_accuracy: 0.1000\n","Epoch 3/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.6584 - accuracy: 0.3041 - val_loss: 8.2045 - val_accuracy: 0.1000\n","Epoch 4/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.0008 - accuracy: 0.2963 - val_loss: 8.2038 - val_accuracy: 0.1000\n","Epoch 5/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.0010 - accuracy: 0.2806 - val_loss: 8.2033 - val_accuracy: 0.1000\n","Epoch 6/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.7597 - accuracy: 0.3041 - val_loss: 8.2030 - val_accuracy: 0.1000\n","Epoch 7/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.4510 - accuracy: 0.2806 - val_loss: 8.2023 - val_accuracy: 0.1000\n","Epoch 8/100\n","3/3 [==============================] - 0s 25ms/step - loss: 4.1516 - accuracy: 0.2806 - val_loss: 8.2024 - val_accuracy: 0.1000\n","Epoch 9/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.1421 - accuracy: 0.2728 - val_loss: 8.2018 - val_accuracy: 0.1000\n","Epoch 10/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.9914 - accuracy: 0.2884 - val_loss: 8.2010 - val_accuracy: 0.1000\n","Epoch 11/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.6810 - accuracy: 0.2884 - val_loss: 8.2005 - val_accuracy: 0.1000\n","Epoch 12/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.6705 - accuracy: 0.2767 - val_loss: 8.2000 - val_accuracy: 0.1000\n","Epoch 13/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.9004 - accuracy: 0.2845 - val_loss: 8.1994 - val_accuracy: 0.1000\n","Epoch 14/100\n","3/3 [==============================] - 0s 23ms/step - loss: 3.6102 - accuracy: 0.2689 - val_loss: 8.1988 - val_accuracy: 0.1000\n","Epoch 15/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.9114 - accuracy: 0.2806 - val_loss: 8.1977 - val_accuracy: 0.1000\n","Epoch 16/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.4022 - accuracy: 0.3158 - val_loss: 8.1970 - val_accuracy: 0.1000\n","Epoch 17/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.6854 - accuracy: 0.2767 - val_loss: 8.1961 - val_accuracy: 0.1000\n","Epoch 18/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.3406 - accuracy: 0.3197 - val_loss: 7.6969 - val_accuracy: 0.1000\n","Epoch 19/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.0224 - accuracy: 0.2806 - val_loss: 7.6177 - val_accuracy: 0.1000\n","Epoch 20/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.6573 - accuracy: 0.3002 - val_loss: 7.5866 - val_accuracy: 0.1000\n","Epoch 21/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.5828 - accuracy: 0.2884 - val_loss: 7.5709 - val_accuracy: 0.1000\n","Epoch 22/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.6049 - accuracy: 0.2923 - val_loss: 7.5634 - val_accuracy: 0.1000\n","Epoch 23/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.8041 - accuracy: 0.2806 - val_loss: 7.5533 - val_accuracy: 0.1000\n","Epoch 24/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.7434 - accuracy: 0.2767 - val_loss: 7.5488 - val_accuracy: 0.1000\n","Epoch 25/100\n","3/3 [==============================] - 0s 27ms/step - loss: 4.0023 - accuracy: 0.2533 - val_loss: 7.5342 - val_accuracy: 0.1000\n","Epoch 26/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.6377 - accuracy: 0.2533 - val_loss: 7.5308 - val_accuracy: 0.1000\n","Epoch 27/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.8556 - accuracy: 0.2767 - val_loss: 7.5232 - val_accuracy: 0.1000\n","Epoch 28/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.9751 - accuracy: 0.2845 - val_loss: 7.5210 - val_accuracy: 0.1000\n","Epoch 29/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.9160 - accuracy: 0.2650 - val_loss: 7.5178 - val_accuracy: 0.1000\n","Epoch 30/100\n","3/3 [==============================] - 0s 24ms/step - loss: 4.0479 - accuracy: 0.2767 - val_loss: 7.0897 - val_accuracy: 0.1000\n","Epoch 31/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.4853 - accuracy: 0.3041 - val_loss: 7.0417 - val_accuracy: 0.1000\n","Epoch 32/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.8505 - accuracy: 0.2884 - val_loss: 7.0150 - val_accuracy: 0.1000\n","Epoch 33/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.6551 - accuracy: 0.2728 - val_loss: 7.0060 - val_accuracy: 0.1000\n","Epoch 34/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.7574 - accuracy: 0.2806 - val_loss: 6.9859 - val_accuracy: 0.1000\n","Epoch 35/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.6121 - accuracy: 0.3041 - val_loss: 6.9763 - val_accuracy: 0.1000\n","Epoch 36/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.8655 - accuracy: 0.2728 - val_loss: 6.9795 - val_accuracy: 0.1000\n","Epoch 37/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.7195 - accuracy: 0.2728 - val_loss: 6.9714 - val_accuracy: 0.1000\n","Epoch 38/100\n","3/3 [==============================] - 0s 23ms/step - loss: 3.4039 - accuracy: 0.3041 - val_loss: 6.9691 - val_accuracy: 0.1000\n","Epoch 39/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.9469 - accuracy: 0.2650 - val_loss: 6.9572 - val_accuracy: 0.1000\n","Epoch 40/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.7454 - accuracy: 0.2963 - val_loss: 6.9513 - val_accuracy: 0.1000\n","Epoch 41/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.4548 - accuracy: 0.3275 - val_loss: 6.9470 - val_accuracy: 0.1000\n","Epoch 42/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.8308 - accuracy: 0.2740 - val_loss: 6.9419 - val_accuracy: 0.1000\n","Epoch 43/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.8492 - accuracy: 0.2857 - val_loss: 6.9395 - val_accuracy: 0.1000\n","Epoch 44/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.9053 - accuracy: 0.2466 - val_loss: 6.9373 - val_accuracy: 0.1000\n","Epoch 45/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.9003 - accuracy: 0.2779 - val_loss: 6.9285 - val_accuracy: 0.1000\n","Epoch 46/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.7442 - accuracy: 0.2896 - val_loss: 6.9247 - val_accuracy: 0.1000\n","Epoch 47/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.2912 - accuracy: 0.2974 - val_loss: 6.9195 - val_accuracy: 0.1000\n","Epoch 48/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.7512 - accuracy: 0.2857 - val_loss: 6.9159 - val_accuracy: 0.1000\n","Epoch 49/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.2764 - accuracy: 0.2701 - val_loss: 6.9129 - val_accuracy: 0.1000\n","Epoch 50/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.9817 - accuracy: 0.2740 - val_loss: 6.9084 - val_accuracy: 0.1000\n","Epoch 51/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.9787 - accuracy: 0.2517 - val_loss: 6.9031 - val_accuracy: 0.1000\n","Epoch 52/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.6245 - accuracy: 0.2204 - val_loss: 6.9057 - val_accuracy: 0.1000\n","Epoch 53/100\n","3/3 [==============================] - 0s 23ms/step - loss: 3.8346 - accuracy: 0.2740 - val_loss: 6.8980 - val_accuracy: 0.1000\n","Epoch 54/100\n","3/3 [==============================] - 0s 23ms/step - loss: 4.5362 - accuracy: 0.2845 - val_loss: 6.8906 - val_accuracy: 0.1000\n","Epoch 55/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.5191 - accuracy: 0.2728 - val_loss: 6.8845 - val_accuracy: 0.1000\n","Epoch 56/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.0936 - accuracy: 0.2884 - val_loss: 6.8824 - val_accuracy: 0.1000\n","Epoch 57/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.5137 - accuracy: 0.2923 - val_loss: 6.8784 - val_accuracy: 0.1000\n","Epoch 58/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.7766 - accuracy: 0.2728 - val_loss: 6.8790 - val_accuracy: 0.1000\n","Epoch 59/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.7830 - accuracy: 0.2650 - val_loss: 6.8768 - val_accuracy: 0.1000\n","Epoch 60/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.4232 - accuracy: 0.2845 - val_loss: 6.8734 - val_accuracy: 0.1000\n","Epoch 61/100\n","3/3 [==============================] - 0s 23ms/step - loss: 4.0319 - accuracy: 0.2728 - val_loss: 6.8652 - val_accuracy: 0.1000\n","Epoch 62/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.9248 - accuracy: 0.2572 - val_loss: 6.8644 - val_accuracy: 0.1000\n","Epoch 63/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.5369 - accuracy: 0.2884 - val_loss: 6.8641 - val_accuracy: 0.1000\n","Epoch 64/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.5541 - accuracy: 0.2611 - val_loss: 6.8602 - val_accuracy: 0.1000\n","Epoch 65/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.3125 - accuracy: 0.2728 - val_loss: 6.8568 - val_accuracy: 0.1000\n","Epoch 66/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.9635 - accuracy: 0.2572 - val_loss: 6.8517 - val_accuracy: 0.1000\n","Epoch 67/100\n","3/3 [==============================] - 0s 27ms/step - loss: 4.0853 - accuracy: 0.2884 - val_loss: 6.8469 - val_accuracy: 0.1000\n","Epoch 68/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.9167 - accuracy: 0.2756 - val_loss: 6.8481 - val_accuracy: 0.1000\n","Epoch 69/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.6801 - accuracy: 0.2834 - val_loss: 6.8448 - val_accuracy: 0.1000\n","Epoch 70/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.7994 - accuracy: 0.2912 - val_loss: 6.8436 - val_accuracy: 0.1000\n","Epoch 71/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.7176 - accuracy: 0.3107 - val_loss: 6.8408 - val_accuracy: 0.1000\n","Epoch 72/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.2769 - accuracy: 0.3107 - val_loss: 6.8398 - val_accuracy: 0.1000\n","Epoch 73/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.9092 - accuracy: 0.3068 - val_loss: 6.8403 - val_accuracy: 0.1000\n","Epoch 74/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.3049 - accuracy: 0.3029 - val_loss: 6.8366 - val_accuracy: 0.1000\n","Epoch 75/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.7814 - accuracy: 0.2834 - val_loss: 6.8332 - val_accuracy: 0.1000\n","Epoch 76/100\n","3/3 [==============================] - 0s 24ms/step - loss: 3.3868 - accuracy: 0.3029 - val_loss: 6.8306 - val_accuracy: 0.1000\n","Epoch 77/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.2725 - accuracy: 0.3224 - val_loss: 6.8275 - val_accuracy: 0.1000\n","Epoch 78/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.6288 - accuracy: 0.3264 - val_loss: 6.8266 - val_accuracy: 0.1000\n","Epoch 79/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.4239 - accuracy: 0.2756 - val_loss: 6.8246 - val_accuracy: 0.1000\n","Epoch 80/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.0324 - accuracy: 0.2990 - val_loss: 6.8236 - val_accuracy: 0.1000\n","Epoch 81/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.7472 - accuracy: 0.2951 - val_loss: 6.8220 - val_accuracy: 0.1000\n","Epoch 82/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.8791 - accuracy: 0.2873 - val_loss: 6.8200 - val_accuracy: 0.1000\n","Epoch 83/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.1176 - accuracy: 0.3224 - val_loss: 6.8181 - val_accuracy: 0.1000\n","Epoch 84/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.5668 - accuracy: 0.3068 - val_loss: 6.8151 - val_accuracy: 0.1000\n","Epoch 85/100\n","3/3 [==============================] - 0s 25ms/step - loss: 4.0334 - accuracy: 0.3135 - val_loss: 6.8122 - val_accuracy: 0.1000\n","Epoch 86/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.4367 - accuracy: 0.3174 - val_loss: 6.8127 - val_accuracy: 0.1000\n","Epoch 87/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.6331 - accuracy: 0.3057 - val_loss: 6.8093 - val_accuracy: 0.1000\n","Epoch 88/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.3984 - accuracy: 0.3057 - val_loss: 6.8089 - val_accuracy: 0.1000\n","Epoch 89/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.5304 - accuracy: 0.3057 - val_loss: 6.8066 - val_accuracy: 0.1000\n","Epoch 90/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.9875 - accuracy: 0.2979 - val_loss: 6.8030 - val_accuracy: 0.1000\n","Epoch 91/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.4506 - accuracy: 0.3174 - val_loss: 6.8009 - val_accuracy: 0.1000\n","Epoch 92/100\n","3/3 [==============================] - 0s 25ms/step - loss: 3.4846 - accuracy: 0.2940 - val_loss: 6.8003 - val_accuracy: 0.1000\n","Epoch 93/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.8211 - accuracy: 0.3174 - val_loss: 6.7971 - val_accuracy: 0.1000\n","Epoch 94/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.4396 - accuracy: 0.2901 - val_loss: 6.7936 - val_accuracy: 0.1000\n","Epoch 95/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.7886 - accuracy: 0.3174 - val_loss: 6.7905 - val_accuracy: 0.1000\n","Epoch 96/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.5989 - accuracy: 0.3291 - val_loss: 6.7902 - val_accuracy: 0.1000\n","Epoch 97/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.8728 - accuracy: 0.2861 - val_loss: 6.7885 - val_accuracy: 0.1000\n","Epoch 98/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.1867 - accuracy: 0.2549 - val_loss: 6.7870 - val_accuracy: 0.1000\n","Epoch 99/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.8991 - accuracy: 0.3135 - val_loss: 6.7829 - val_accuracy: 0.1000\n","Epoch 100/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.7085 - accuracy: 0.3174 - val_loss: 6.7820 - val_accuracy: 0.1000\n","1/1 [==============================] - 0s 126ms/step - loss: 7.5143 - accuracy: 0.0556\n","Epoch 1/100\n","3/3 [==============================] - 1s 103ms/step - loss: 10.8332 - accuracy: 0.0846 - val_loss: 11.2714 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 27ms/step - loss: 10.8465 - accuracy: 0.1119 - val_loss: 11.2694 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 26ms/step - loss: 10.7782 - accuracy: 0.1459 - val_loss: 11.2669 - val_accuracy: 0.3000\n","Epoch 4/100\n","3/3 [==============================] - 0s 27ms/step - loss: 10.9052 - accuracy: 0.1303 - val_loss: 11.2651 - val_accuracy: 0.3000\n","Epoch 5/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.5339 - accuracy: 0.1303 - val_loss: 11.2625 - val_accuracy: 0.3000\n","Epoch 6/100\n","3/3 [==============================] - 0s 25ms/step - loss: 11.8675 - accuracy: 0.1096 - val_loss: 11.2592 - val_accuracy: 0.3000\n","Epoch 7/100\n","3/3 [==============================] - 0s 25ms/step - loss: 10.9511 - accuracy: 0.1331 - val_loss: 11.2563 - val_accuracy: 0.3000\n","Epoch 8/100\n","3/3 [==============================] - 0s 28ms/step - loss: 10.5876 - accuracy: 0.1448 - val_loss: 11.2518 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 26ms/step - loss: 10.8612 - accuracy: 0.1370 - val_loss: 11.2479 - val_accuracy: 0.3000\n","Epoch 10/100\n","3/3 [==============================] - 0s 27ms/step - loss: 11.0515 - accuracy: 0.1331 - val_loss: 11.2455 - val_accuracy: 0.3000\n","Epoch 11/100\n","3/3 [==============================] - 0s 26ms/step - loss: 11.0770 - accuracy: 0.1487 - val_loss: 11.2419 - val_accuracy: 0.3000\n","Epoch 12/100\n","3/3 [==============================] - 0s 27ms/step - loss: 11.0073 - accuracy: 0.1253 - val_loss: 11.2395 - val_accuracy: 0.3000\n","Epoch 13/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.6884 - accuracy: 0.1554 - val_loss: 11.2356 - val_accuracy: 0.3000\n","Epoch 14/100\n","3/3 [==============================] - 0s 34ms/step - loss: 11.1117 - accuracy: 0.1202 - val_loss: 11.2324 - val_accuracy: 0.3000\n","Epoch 15/100\n","3/3 [==============================] - 0s 31ms/step - loss: 10.9630 - accuracy: 0.1386 - val_loss: 11.2289 - val_accuracy: 0.3000\n","Epoch 16/100\n","3/3 [==============================] - 0s 28ms/step - loss: 10.8838 - accuracy: 0.1542 - val_loss: 11.2278 - val_accuracy: 0.3000\n","Epoch 17/100\n","3/3 [==============================] - 0s 27ms/step - loss: 10.8179 - accuracy: 0.1737 - val_loss: 11.2258 - val_accuracy: 0.3000\n","Epoch 18/100\n","3/3 [==============================] - 0s 30ms/step - loss: 11.1054 - accuracy: 0.1503 - val_loss: 11.2238 - val_accuracy: 0.3000\n","Epoch 19/100\n","3/3 [==============================] - 0s 28ms/step - loss: 10.5552 - accuracy: 0.1620 - val_loss: 11.2294 - val_accuracy: 0.2500\n","Epoch 20/100\n","3/3 [==============================] - 0s 25ms/step - loss: 10.9224 - accuracy: 0.1542 - val_loss: 11.2256 - val_accuracy: 0.2500\n","Epoch 21/100\n","3/3 [==============================] - 0s 26ms/step - loss: 11.1465 - accuracy: 0.1581 - val_loss: 11.2208 - val_accuracy: 0.2500\n","Epoch 22/100\n","3/3 [==============================] - 0s 26ms/step - loss: 10.6482 - accuracy: 0.1581 - val_loss: 11.2163 - val_accuracy: 0.2500\n","Epoch 23/100\n","3/3 [==============================] - 0s 29ms/step - loss: 11.0015 - accuracy: 0.1503 - val_loss: 11.2112 - val_accuracy: 0.2500\n","Epoch 24/100\n","3/3 [==============================] - 0s 26ms/step - loss: 10.5286 - accuracy: 0.1620 - val_loss: 11.2087 - val_accuracy: 0.2500\n","Epoch 25/100\n","3/3 [==============================] - 0s 25ms/step - loss: 10.0159 - accuracy: 0.1816 - val_loss: 11.2046 - val_accuracy: 0.2500\n","Epoch 26/100\n","3/3 [==============================] - 0s 27ms/step - loss: 9.9848 - accuracy: 0.2039 - val_loss: 11.2015 - val_accuracy: 0.2500\n","Epoch 27/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.2221 - accuracy: 0.1609 - val_loss: 11.1981 - val_accuracy: 0.2500\n","Epoch 28/100\n","3/3 [==============================] - 0s 25ms/step - loss: 10.7312 - accuracy: 0.1570 - val_loss: 11.1956 - val_accuracy: 0.2500\n","Epoch 29/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.5622 - accuracy: 0.1882 - val_loss: 11.1935 - val_accuracy: 0.2500\n","Epoch 30/100\n","3/3 [==============================] - 0s 27ms/step - loss: 10.5126 - accuracy: 0.1597 - val_loss: 11.1919 - val_accuracy: 0.2500\n","Epoch 31/100\n","3/3 [==============================] - 0s 30ms/step - loss: 10.9262 - accuracy: 0.1676 - val_loss: 11.1893 - val_accuracy: 0.2500\n","Epoch 32/100\n","3/3 [==============================] - 0s 33ms/step - loss: 10.4218 - accuracy: 0.1949 - val_loss: 11.1864 - val_accuracy: 0.2500\n","Epoch 33/100\n","3/3 [==============================] - 0s 30ms/step - loss: 10.3941 - accuracy: 0.1949 - val_loss: 11.1841 - val_accuracy: 0.2500\n","Epoch 34/100\n","3/3 [==============================] - 0s 26ms/step - loss: 10.6690 - accuracy: 0.1754 - val_loss: 11.1805 - val_accuracy: 0.3000\n","Epoch 35/100\n","3/3 [==============================] - 0s 27ms/step - loss: 10.1930 - accuracy: 0.1949 - val_loss: 11.1765 - val_accuracy: 0.3000\n","Epoch 36/100\n","3/3 [==============================] - 0s 26ms/step - loss: 10.3868 - accuracy: 0.1910 - val_loss: 11.1743 - val_accuracy: 0.3000\n","Epoch 37/100\n","3/3 [==============================] - 0s 31ms/step - loss: 10.5524 - accuracy: 0.1754 - val_loss: 11.1701 - val_accuracy: 0.3000\n","Epoch 38/100\n","3/3 [==============================] - 0s 28ms/step - loss: 10.0244 - accuracy: 0.1910 - val_loss: 11.1685 - val_accuracy: 0.3000\n","Epoch 39/100\n","3/3 [==============================] - 0s 31ms/step - loss: 10.2948 - accuracy: 0.1715 - val_loss: 11.1721 - val_accuracy: 0.3000\n","Epoch 40/100\n","3/3 [==============================] - 0s 27ms/step - loss: 10.8985 - accuracy: 0.1547 - val_loss: 11.1668 - val_accuracy: 0.3000\n","Epoch 41/100\n","3/3 [==============================] - 0s 30ms/step - loss: 9.7878 - accuracy: 0.2094 - val_loss: 11.1625 - val_accuracy: 0.3000\n","Epoch 42/100\n","3/3 [==============================] - 0s 28ms/step - loss: 10.1297 - accuracy: 0.2172 - val_loss: 11.1895 - val_accuracy: 0.2000\n","Epoch 43/100\n","3/3 [==============================] - 0s 34ms/step - loss: 10.4632 - accuracy: 0.1682 - val_loss: 11.2494 - val_accuracy: 0.2000\n","Epoch 44/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.3178 - accuracy: 0.1476 - val_loss: 11.2619 - val_accuracy: 0.2000\n","Epoch 45/100\n","3/3 [==============================] - 0s 27ms/step - loss: 10.7575 - accuracy: 0.1397 - val_loss: 11.2786 - val_accuracy: 0.2000\n","Epoch 46/100\n","3/3 [==============================] - 0s 30ms/step - loss: 10.6820 - accuracy: 0.1319 - val_loss: 11.2960 - val_accuracy: 0.2000\n","Epoch 47/100\n","3/3 [==============================] - 0s 27ms/step - loss: 10.6818 - accuracy: 0.1280 - val_loss: 11.8620 - val_accuracy: 0.2000\n","Epoch 48/100\n","3/3 [==============================] - 0s 30ms/step - loss: 10.8249 - accuracy: 0.1515 - val_loss: 11.8568 - val_accuracy: 0.2500\n","Epoch 49/100\n","3/3 [==============================] - 0s 27ms/step - loss: 10.1967 - accuracy: 0.1319 - val_loss: 11.8513 - val_accuracy: 0.2500\n","Epoch 50/100\n","3/3 [==============================] - 0s 31ms/step - loss: 10.8456 - accuracy: 0.1319 - val_loss: 11.8453 - val_accuracy: 0.2500\n","Epoch 51/100\n","3/3 [==============================] - 0s 27ms/step - loss: 10.6027 - accuracy: 0.1648 - val_loss: 11.8383 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 128ms/step - loss: 15.0333 - accuracy: 0.0000e+00\n","Epoch 1/100\n","3/3 [==============================] - 1s 262ms/step - loss: 12.0423 - accuracy: 0.0370 - val_loss: 12.7891 - val_accuracy: 0.1500\n","Epoch 2/100\n","3/3 [==============================] - 0s 30ms/step - loss: 10.3024 - accuracy: 0.4030 - val_loss: 12.7886 - val_accuracy: 0.1500\n","Epoch 3/100\n","3/3 [==============================] - 0s 32ms/step - loss: 10.6796 - accuracy: 0.3795 - val_loss: 12.7879 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 30ms/step - loss: 10.7380 - accuracy: 0.3756 - val_loss: 12.7875 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 28ms/step - loss: 9.9835 - accuracy: 0.4225 - val_loss: 12.7870 - val_accuracy: 0.1500\n","Epoch 6/100\n","3/3 [==============================] - 0s 28ms/step - loss: 10.4279 - accuracy: 0.3952 - val_loss: 12.7862 - val_accuracy: 0.1500\n","Epoch 7/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.9293 - accuracy: 0.3639 - val_loss: 12.7854 - val_accuracy: 0.1500\n","Epoch 8/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.9908 - accuracy: 0.3600 - val_loss: 12.7847 - val_accuracy: 0.1500\n","Epoch 9/100\n","3/3 [==============================] - 0s 28ms/step - loss: 10.9890 - accuracy: 0.3600 - val_loss: 12.7836 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 30ms/step - loss: 10.6760 - accuracy: 0.3795 - val_loss: 12.7832 - val_accuracy: 0.1500\n","Epoch 11/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.2329 - accuracy: 0.4069 - val_loss: 12.7826 - val_accuracy: 0.1500\n","Epoch 12/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.5451 - accuracy: 0.3874 - val_loss: 12.7795 - val_accuracy: 0.1500\n","Epoch 13/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.4124 - accuracy: 0.3952 - val_loss: 12.7759 - val_accuracy: 0.1500\n","Epoch 14/100\n","3/3 [==============================] - 0s 30ms/step - loss: 10.4762 - accuracy: 0.3913 - val_loss: 12.7723 - val_accuracy: 0.1500\n","Epoch 15/100\n","3/3 [==============================] - 0s 28ms/step - loss: 10.4075 - accuracy: 0.3952 - val_loss: 12.7673 - val_accuracy: 0.1500\n","Epoch 16/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.2037 - accuracy: 0.4069 - val_loss: 12.7578 - val_accuracy: 0.1500\n","Epoch 17/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.3034 - accuracy: 0.3952 - val_loss: 13.3406 - val_accuracy: 0.1500\n","Epoch 18/100\n","3/3 [==============================] - 0s 33ms/step - loss: 9.6875 - accuracy: 0.4147 - val_loss: 13.4513 - val_accuracy: 0.1500\n","Epoch 19/100\n","3/3 [==============================] - 0s 31ms/step - loss: 9.2965 - accuracy: 0.4381 - val_loss: 13.7062 - val_accuracy: 0.1500\n","Epoch 20/100\n","3/3 [==============================] - 0s 28ms/step - loss: 10.2589 - accuracy: 0.3639 - val_loss: 13.7057 - val_accuracy: 0.1500\n","Epoch 21/100\n","3/3 [==============================] - 0s 28ms/step - loss: 9.9416 - accuracy: 0.3834 - val_loss: 13.7053 - val_accuracy: 0.1500\n","Epoch 22/100\n","3/3 [==============================] - 0s 27ms/step - loss: 10.2550 - accuracy: 0.3639 - val_loss: 13.7050 - val_accuracy: 0.1500\n","Epoch 23/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.1279 - accuracy: 0.3717 - val_loss: 13.7046 - val_accuracy: 0.1500\n","Epoch 24/100\n","3/3 [==============================] - 0s 33ms/step - loss: 10.0022 - accuracy: 0.3795 - val_loss: 13.7044 - val_accuracy: 0.1500\n","Epoch 25/100\n","3/3 [==============================] - 0s 27ms/step - loss: 9.8126 - accuracy: 0.3913 - val_loss: 13.7042 - val_accuracy: 0.1500\n","Epoch 26/100\n","3/3 [==============================] - 0s 28ms/step - loss: 10.0020 - accuracy: 0.3795 - val_loss: 13.7039 - val_accuracy: 0.1500\n","1/1 [==============================] - 0s 150ms/step - loss: 15.2698 - accuracy: 0.0526\n","Epoch 1/100\n","3/3 [==============================] - 1s 116ms/step - loss: 4.4898 - accuracy: 0.2466 - val_loss: 3.3126 - val_accuracy: 0.5000\n","Epoch 2/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.8962 - accuracy: 0.5089 - val_loss: 3.9089 - val_accuracy: 0.4500\n","Epoch 3/100\n","3/3 [==============================] - 0s 28ms/step - loss: 2.9931 - accuracy: 0.4737 - val_loss: 3.2275 - val_accuracy: 0.4500\n","Epoch 4/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.5407 - accuracy: 0.3891 - val_loss: 4.0567 - val_accuracy: 0.4000\n","Epoch 5/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.6036 - accuracy: 0.4623 - val_loss: 3.9205 - val_accuracy: 0.4000\n","Epoch 6/100\n","3/3 [==============================] - 0s 28ms/step - loss: 2.5351 - accuracy: 0.4378 - val_loss: 3.9284 - val_accuracy: 0.4500\n","Epoch 7/100\n","3/3 [==============================] - 0s 28ms/step - loss: 2.2194 - accuracy: 0.4719 - val_loss: 4.5764 - val_accuracy: 0.4500\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.6169 - accuracy: 0.4602 - val_loss: 4.5733 - val_accuracy: 0.4000\n","Epoch 9/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.5103 - accuracy: 0.4748 - val_loss: 4.5479 - val_accuracy: 0.4500\n","Epoch 10/100\n","3/3 [==============================] - 0s 27ms/step - loss: 2.3035 - accuracy: 0.4737 - val_loss: 4.6039 - val_accuracy: 0.3500\n","Epoch 11/100\n","3/3 [==============================] - 0s 27ms/step - loss: 2.0442 - accuracy: 0.5409 - val_loss: 4.6275 - val_accuracy: 0.3500\n","Epoch 12/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.3931 - accuracy: 0.4805 - val_loss: 4.6219 - val_accuracy: 0.3500\n","Epoch 13/100\n","3/3 [==============================] - 0s 27ms/step - loss: 2.1910 - accuracy: 0.5320 - val_loss: 5.1832 - val_accuracy: 0.3500\n","1/1 [==============================] - 0s 144ms/step - loss: 1.8569 - accuracy: 0.5263\n","Epoch 1/100\n","3/3 [==============================] - 1s 107ms/step - loss: 6.0046 - accuracy: 0.3884 - val_loss: 3.3357 - val_accuracy: 0.5000\n","Epoch 2/100\n","3/3 [==============================] - 0s 27ms/step - loss: 6.7294 - accuracy: 0.3689 - val_loss: 3.3279 - val_accuracy: 0.5000\n","Epoch 3/100\n","3/3 [==============================] - 0s 27ms/step - loss: 6.1358 - accuracy: 0.4197 - val_loss: 3.3190 - val_accuracy: 0.5000\n","Epoch 4/100\n","3/3 [==============================] - 0s 28ms/step - loss: 6.3835 - accuracy: 0.3728 - val_loss: 3.3057 - val_accuracy: 0.5000\n","Epoch 5/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.3781 - accuracy: 0.3650 - val_loss: 3.2937 - val_accuracy: 0.4500\n","Epoch 6/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.8280 - accuracy: 0.4264 - val_loss: 3.2773 - val_accuracy: 0.4500\n","Epoch 7/100\n","3/3 [==============================] - 0s 29ms/step - loss: 6.3878 - accuracy: 0.3891 - val_loss: 3.2619 - val_accuracy: 0.4500\n","Epoch 8/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.4550 - accuracy: 0.3330 - val_loss: 3.2712 - val_accuracy: 0.5000\n","Epoch 9/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.5064 - accuracy: 0.3543 - val_loss: 3.2612 - val_accuracy: 0.5000\n","Epoch 10/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.5511 - accuracy: 0.3600 - val_loss: 3.2509 - val_accuracy: 0.4500\n","Epoch 11/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.0188 - accuracy: 0.3923 - val_loss: 3.2557 - val_accuracy: 0.4500\n","Epoch 12/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.2954 - accuracy: 0.3689 - val_loss: 3.2533 - val_accuracy: 0.4500\n","Epoch 13/100\n","3/3 [==============================] - 0s 29ms/step - loss: 5.5818 - accuracy: 0.3845 - val_loss: 3.2690 - val_accuracy: 0.5000\n","Epoch 14/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.4323 - accuracy: 0.3806 - val_loss: 3.2987 - val_accuracy: 0.4500\n","Epoch 15/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.5353 - accuracy: 0.4232 - val_loss: 3.3327 - val_accuracy: 0.4000\n","Epoch 16/100\n","3/3 [==============================] - 0s 26ms/step - loss: 5.1855 - accuracy: 0.3998 - val_loss: 3.2316 - val_accuracy: 0.4500\n","Epoch 17/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.7492 - accuracy: 0.4350 - val_loss: 3.3549 - val_accuracy: 0.4000\n","Epoch 18/100\n","3/3 [==============================] - 0s 29ms/step - loss: 5.1569 - accuracy: 0.4545 - val_loss: 3.7965 - val_accuracy: 0.4000\n","Epoch 19/100\n","3/3 [==============================] - 0s 26ms/step - loss: 4.9007 - accuracy: 0.4360 - val_loss: 3.2968 - val_accuracy: 0.5000\n","Epoch 20/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.0245 - accuracy: 0.4602 - val_loss: 3.8545 - val_accuracy: 0.4000\n","Epoch 21/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.8621 - accuracy: 0.4250 - val_loss: 5.1508 - val_accuracy: 0.3000\n","Epoch 22/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.6018 - accuracy: 0.4311 - val_loss: 3.9096 - val_accuracy: 0.4000\n","Epoch 23/100\n","3/3 [==============================] - 0s 26ms/step - loss: 3.5703 - accuracy: 0.4769 - val_loss: 3.7812 - val_accuracy: 0.3500\n","Epoch 24/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.8583 - accuracy: 0.4602 - val_loss: 3.2315 - val_accuracy: 0.3000\n","Epoch 25/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.5704 - accuracy: 0.4591 - val_loss: 3.4130 - val_accuracy: 0.3000\n","Epoch 26/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.1023 - accuracy: 0.4893 - val_loss: 4.5623 - val_accuracy: 0.3000\n","Epoch 27/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.6582 - accuracy: 0.5565 - val_loss: 4.5360 - val_accuracy: 0.2500\n","Epoch 28/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.4974 - accuracy: 0.5192 - val_loss: 8.3546 - val_accuracy: 0.1500\n","Epoch 29/100\n","3/3 [==============================] - 0s 28ms/step - loss: 8.7744 - accuracy: 0.1951 - val_loss: 6.1958 - val_accuracy: 0.2500\n","Epoch 30/100\n","3/3 [==============================] - 0s 27ms/step - loss: 6.1318 - accuracy: 0.3767 - val_loss: 6.6194 - val_accuracy: 0.3000\n","Epoch 31/100\n","3/3 [==============================] - 0s 31ms/step - loss: 7.2505 - accuracy: 0.3465 - val_loss: 5.4538 - val_accuracy: 0.3000\n","Epoch 32/100\n","3/3 [==============================] - 0s 27ms/step - loss: 5.7116 - accuracy: 0.4108 - val_loss: 5.4662 - val_accuracy: 0.3500\n","Epoch 33/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.9117 - accuracy: 0.4108 - val_loss: 5.9096 - val_accuracy: 0.3000\n","Epoch 34/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.3807 - accuracy: 0.3795 - val_loss: 4.7425 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 137ms/step - loss: 9.7262 - accuracy: 0.2105\n","Epoch 1/100\n","3/3 [==============================] - 1s 104ms/step - loss: 7.5438 - accuracy: 0.3976 - val_loss: 9.7179 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 29ms/step - loss: 6.0705 - accuracy: 0.3624 - val_loss: 9.1166 - val_accuracy: 0.1500\n","Epoch 3/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.8109 - accuracy: 0.3402 - val_loss: 9.0974 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 27ms/step - loss: 4.7422 - accuracy: 0.4043 - val_loss: 9.0666 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.9045 - accuracy: 0.3820 - val_loss: 9.0284 - val_accuracy: 0.1500\n","Epoch 6/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.2153 - accuracy: 0.3491 - val_loss: 8.2168 - val_accuracy: 0.1500\n","Epoch 7/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.5616 - accuracy: 0.3358 - val_loss: 7.5802 - val_accuracy: 0.1500\n","Epoch 8/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.1299 - accuracy: 0.3335 - val_loss: 7.5155 - val_accuracy: 0.1500\n","Epoch 9/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.5912 - accuracy: 0.3480 - val_loss: 6.9353 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.8127 - accuracy: 0.3363 - val_loss: 6.8637 - val_accuracy: 0.1500\n","Epoch 11/100\n","3/3 [==============================] - 0s 28ms/step - loss: 2.9447 - accuracy: 0.3976 - val_loss: 6.8108 - val_accuracy: 0.2000\n","Epoch 12/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.0035 - accuracy: 0.3675 - val_loss: 6.7769 - val_accuracy: 0.2000\n","Epoch 13/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.4776 - accuracy: 0.3546 - val_loss: 7.0156 - val_accuracy: 0.3000\n","Epoch 14/100\n","3/3 [==============================] - 0s 28ms/step - loss: 2.8588 - accuracy: 0.3585 - val_loss: 7.0735 - val_accuracy: 0.3000\n","Epoch 15/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.0300 - accuracy: 0.4031 - val_loss: 6.5675 - val_accuracy: 0.3000\n","Epoch 16/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.2721 - accuracy: 0.3797 - val_loss: 6.4871 - val_accuracy: 0.3000\n","Epoch 17/100\n","3/3 [==============================] - 0s 27ms/step - loss: 2.4888 - accuracy: 0.4015 - val_loss: 6.4721 - val_accuracy: 0.2500\n","Epoch 18/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.6696 - accuracy: 0.3402 - val_loss: 3.9842 - val_accuracy: 0.1500\n","Epoch 19/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.4376 - accuracy: 0.3307 - val_loss: 3.9632 - val_accuracy: 0.1500\n","Epoch 20/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.2402 - accuracy: 0.3018 - val_loss: 4.4421 - val_accuracy: 0.2000\n","Epoch 21/100\n","3/3 [==============================] - 0s 28ms/step - loss: 1.8525 - accuracy: 0.3330 - val_loss: 4.4293 - val_accuracy: 0.2000\n","Epoch 22/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.0392 - accuracy: 0.3174 - val_loss: 3.9678 - val_accuracy: 0.2000\n","Epoch 23/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.0089 - accuracy: 0.3096 - val_loss: 4.0031 - val_accuracy: 0.2000\n","Epoch 24/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.7772 - accuracy: 0.3135 - val_loss: 4.0079 - val_accuracy: 0.2000\n","Epoch 25/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.8531 - accuracy: 0.3018 - val_loss: 4.0161 - val_accuracy: 0.2000\n","Epoch 26/100\n","3/3 [==============================] - 0s 26ms/step - loss: 1.6950 - accuracy: 0.2705 - val_loss: 4.4987 - val_accuracy: 0.2000\n","Epoch 27/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.8345 - accuracy: 0.3369 - val_loss: 3.2500 - val_accuracy: 0.2000\n","Epoch 28/100\n","3/3 [==============================] - 0s 26ms/step - loss: 2.4820 - accuracy: 0.3914 - val_loss: 5.3811 - val_accuracy: 0.2000\n","Epoch 29/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.1189 - accuracy: 0.3797 - val_loss: 5.1294 - val_accuracy: 0.2500\n","Epoch 30/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.6247 - accuracy: 0.4578 - val_loss: 3.9219 - val_accuracy: 0.2500\n","Epoch 31/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.4265 - accuracy: 0.4371 - val_loss: 3.9077 - val_accuracy: 0.2500\n","Epoch 32/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.5399 - accuracy: 0.3864 - val_loss: 3.8862 - val_accuracy: 0.2500\n","Epoch 33/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3663 - accuracy: 0.3942 - val_loss: 2.7062 - val_accuracy: 0.3000\n","Epoch 34/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.3678 - accuracy: 0.4532 - val_loss: 2.7062 - val_accuracy: 0.3000\n","Epoch 35/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.3353 - accuracy: 0.4532 - val_loss: 2.7062 - val_accuracy: 0.3000\n","Epoch 36/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.3353 - accuracy: 0.4376 - val_loss: 2.7062 - val_accuracy: 0.3000\n","Epoch 37/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.3461 - accuracy: 0.4220 - val_loss: 2.7062 - val_accuracy: 0.3000\n","Epoch 38/100\n","3/3 [==============================] - 0s 26ms/step - loss: 1.3516 - accuracy: 0.4610 - val_loss: 2.7062 - val_accuracy: 0.3000\n","Epoch 39/100\n","3/3 [==============================] - 0s 26ms/step - loss: 1.3516 - accuracy: 0.4220 - val_loss: 2.7062 - val_accuracy: 0.3000\n","Epoch 40/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.3461 - accuracy: 0.4376 - val_loss: 2.7062 - val_accuracy: 0.3000\n","Epoch 41/100\n","3/3 [==============================] - 0s 28ms/step - loss: 1.3570 - accuracy: 0.4298 - val_loss: 2.7062 - val_accuracy: 0.3000\n","Epoch 42/100\n","3/3 [==============================] - 0s 29ms/step - loss: 1.3353 - accuracy: 0.4376 - val_loss: 2.7062 - val_accuracy: 0.3000\n","Epoch 43/100\n","3/3 [==============================] - 0s 27ms/step - loss: 1.3461 - accuracy: 0.4493 - val_loss: 2.7062 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 147ms/step - loss: 3.5032 - accuracy: 0.2222\n","Epoch 1/100\n","3/3 [==============================] - 1s 106ms/step - loss: 8.7932 - accuracy: 0.1754 - val_loss: 6.0047 - val_accuracy: 0.4000\n","Epoch 2/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.5486 - accuracy: 0.2857 - val_loss: 4.5456 - val_accuracy: 0.3500\n","Epoch 3/100\n","3/3 [==============================] - 0s 27ms/step - loss: 3.1245 - accuracy: 0.2822 - val_loss: 4.5413 - val_accuracy: 0.3500\n","Epoch 4/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.0520 - accuracy: 0.2861 - val_loss: 4.5161 - val_accuracy: 0.3500\n","Epoch 5/100\n","3/3 [==============================] - 0s 28ms/step - loss: 2.5634 - accuracy: 0.3436 - val_loss: 4.4794 - val_accuracy: 0.3500\n","Epoch 6/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.7505 - accuracy: 0.3319 - val_loss: 4.4555 - val_accuracy: 0.3500\n","Epoch 7/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.6966 - accuracy: 0.3647 - val_loss: 4.4189 - val_accuracy: 0.3500\n","Epoch 8/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.7329 - accuracy: 0.3608 - val_loss: 4.3787 - val_accuracy: 0.3500\n","Epoch 9/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.6564 - accuracy: 0.3335 - val_loss: 4.3291 - val_accuracy: 0.3500\n","Epoch 10/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.5859 - accuracy: 0.3647 - val_loss: 4.2450 - val_accuracy: 0.3500\n","Epoch 11/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.5112 - accuracy: 0.3374 - val_loss: 4.2367 - val_accuracy: 0.3500\n","Epoch 12/100\n","3/3 [==============================] - 0s 26ms/step - loss: 2.3669 - accuracy: 0.3452 - val_loss: 3.7847 - val_accuracy: 0.3000\n","Epoch 13/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.5544 - accuracy: 0.3374 - val_loss: 3.7626 - val_accuracy: 0.3500\n","Epoch 14/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.4131 - accuracy: 0.3491 - val_loss: 3.7651 - val_accuracy: 0.3500\n","Epoch 15/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.8071 - accuracy: 0.3413 - val_loss: 4.6184 - val_accuracy: 0.3000\n","Epoch 16/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.4335 - accuracy: 0.2461 - val_loss: 4.6022 - val_accuracy: 0.3000\n","Epoch 17/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.7271 - accuracy: 0.2227 - val_loss: 5.0917 - val_accuracy: 0.3500\n","Epoch 18/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.2266 - accuracy: 0.2294 - val_loss: 3.0635 - val_accuracy: 0.4500\n","Epoch 19/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.1901 - accuracy: 0.2806 - val_loss: 3.0441 - val_accuracy: 0.4500\n","Epoch 20/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.6832 - accuracy: 0.3096 - val_loss: 3.6536 - val_accuracy: 0.4500\n","Epoch 21/100\n","3/3 [==============================] - 0s 28ms/step - loss: 2.8494 - accuracy: 0.3213 - val_loss: 3.6360 - val_accuracy: 0.3500\n","Epoch 22/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.7202 - accuracy: 0.2712 - val_loss: 3.1184 - val_accuracy: 0.3000\n","Epoch 23/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.4968 - accuracy: 0.2556 - val_loss: 3.0953 - val_accuracy: 0.3000\n","Epoch 24/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.5371 - accuracy: 0.2211 - val_loss: 2.4924 - val_accuracy: 0.1500\n","Epoch 25/100\n","3/3 [==============================] - 0s 28ms/step - loss: 1.9984 - accuracy: 0.1303 - val_loss: 1.9690 - val_accuracy: 0.1500\n","Epoch 26/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.7204 - accuracy: 0.1381 - val_loss: 1.9749 - val_accuracy: 0.1500\n","Epoch 27/100\n","3/3 [==============================] - 0s 29ms/step - loss: 1.7865 - accuracy: 0.1147 - val_loss: 1.9666 - val_accuracy: 0.1500\n","Epoch 28/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.7545 - accuracy: 0.1331 - val_loss: 1.9844 - val_accuracy: 0.1500\n","Epoch 29/100\n","3/3 [==============================] - 0s 29ms/step - loss: 1.5373 - accuracy: 0.1358 - val_loss: 1.9826 - val_accuracy: 0.1500\n","Epoch 30/100\n","3/3 [==============================] - 0s 28ms/step - loss: 1.6465 - accuracy: 0.1241 - val_loss: 1.9806 - val_accuracy: 0.1500\n","Epoch 31/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.6435 - accuracy: 0.1788 - val_loss: 1.9781 - val_accuracy: 0.1500\n","Epoch 32/100\n","3/3 [==============================] - 0s 29ms/step - loss: 1.6390 - accuracy: 0.1397 - val_loss: 1.9748 - val_accuracy: 0.1500\n","Epoch 33/100\n","3/3 [==============================] - 0s 29ms/step - loss: 1.5269 - accuracy: 0.1671 - val_loss: 1.9699 - val_accuracy: 0.1500\n","Epoch 34/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.3863 - accuracy: 0.1554 - val_loss: 1.9699 - val_accuracy: 0.1500\n","Epoch 35/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.3863 - accuracy: 0.1593 - val_loss: 1.9699 - val_accuracy: 0.1500\n","Epoch 36/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3863 - accuracy: 0.1436 - val_loss: 1.9699 - val_accuracy: 0.1500\n","Epoch 37/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3863 - accuracy: 0.1593 - val_loss: 1.9699 - val_accuracy: 0.1500\n","1/1 [==============================] - 0s 140ms/step - loss: 2.0348 - accuracy: 0.0556\n","Epoch 1/100\n","3/3 [==============================] - 0s 100ms/step - loss: 9.3944 - accuracy: 0.2427 - val_loss: 9.3731 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 31ms/step - loss: 9.2267 - accuracy: 0.2583 - val_loss: 9.4451 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 33ms/step - loss: 9.0543 - accuracy: 0.2544 - val_loss: 9.5532 - val_accuracy: 0.2500\n","Epoch 4/100\n","3/3 [==============================] - 0s 30ms/step - loss: 8.8725 - accuracy: 0.2310 - val_loss: 10.7848 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 30ms/step - loss: 8.3649 - accuracy: 0.2417 - val_loss: 10.8106 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 30ms/step - loss: 8.0221 - accuracy: 0.2338 - val_loss: 10.8192 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 27ms/step - loss: 7.8876 - accuracy: 0.2612 - val_loss: 10.8328 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 29ms/step - loss: 7.6184 - accuracy: 0.2758 - val_loss: 10.8363 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 29ms/step - loss: 7.6611 - accuracy: 0.2797 - val_loss: 10.2500 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 32ms/step - loss: 8.1889 - accuracy: 0.2484 - val_loss: 10.2602 - val_accuracy: 0.2500\n","Epoch 11/100\n","3/3 [==============================] - 0s 31ms/step - loss: 8.1963 - accuracy: 0.2562 - val_loss: 10.2663 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 118ms/step - loss: 7.1192 - accuracy: 0.0000e+00\n","Epoch 1/100\n","3/3 [==============================] - 0s 98ms/step - loss: 6.6300 - accuracy: 0.2932 - val_loss: 8.4841 - val_accuracy: 0.1500\n","Epoch 2/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.8274 - accuracy: 0.2776 - val_loss: 8.4587 - val_accuracy: 0.1500\n","Epoch 3/100\n","3/3 [==============================] - 0s 29ms/step - loss: 6.5164 - accuracy: 0.2932 - val_loss: 8.4160 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 29ms/step - loss: 6.0750 - accuracy: 0.3117 - val_loss: 8.3502 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.3047 - accuracy: 0.3351 - val_loss: 7.8173 - val_accuracy: 0.1500\n","Epoch 6/100\n","3/3 [==============================] - 0s 29ms/step - loss: 6.2819 - accuracy: 0.3234 - val_loss: 7.8075 - val_accuracy: 0.1500\n","Epoch 7/100\n","3/3 [==============================] - 0s 26ms/step - loss: 6.4466 - accuracy: 0.3312 - val_loss: 7.7986 - val_accuracy: 0.1500\n","Epoch 8/100\n","3/3 [==============================] - 0s 28ms/step - loss: 6.4794 - accuracy: 0.3174 - val_loss: 7.7828 - val_accuracy: 0.2000\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.7726 - accuracy: 0.3184 - val_loss: 7.1016 - val_accuracy: 0.2000\n","Epoch 10/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.5525 - accuracy: 0.3486 - val_loss: 7.0924 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.6165 - accuracy: 0.3369 - val_loss: 7.0686 - val_accuracy: 0.2000\n","Epoch 12/100\n","3/3 [==============================] - 0s 28ms/step - loss: 5.7281 - accuracy: 0.3525 - val_loss: 7.0391 - val_accuracy: 0.2000\n","Epoch 13/100\n","3/3 [==============================] - 0s 29ms/step - loss: 5.2200 - accuracy: 0.3174 - val_loss: 5.6848 - val_accuracy: 0.2000\n","Epoch 14/100\n","3/3 [==============================] - 0s 28ms/step - loss: 5.4773 - accuracy: 0.3124 - val_loss: 5.6826 - val_accuracy: 0.2000\n","Epoch 15/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.6767 - accuracy: 0.3749 - val_loss: 5.6811 - val_accuracy: 0.2000\n","Epoch 16/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.5852 - accuracy: 0.3476 - val_loss: 5.6785 - val_accuracy: 0.2000\n","Epoch 17/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.8498 - accuracy: 0.3397 - val_loss: 5.6683 - val_accuracy: 0.2500\n","Epoch 18/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.8950 - accuracy: 0.3436 - val_loss: 5.6684 - val_accuracy: 0.2500\n","Epoch 19/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.6095 - accuracy: 0.3280 - val_loss: 5.6634 - val_accuracy: 0.2500\n","Epoch 20/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.6963 - accuracy: 0.3397 - val_loss: 5.6640 - val_accuracy: 0.2500\n","Epoch 21/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.5716 - accuracy: 0.3554 - val_loss: 5.6627 - val_accuracy: 0.2500\n","Epoch 22/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.2863 - accuracy: 0.3603 - val_loss: 5.6596 - val_accuracy: 0.2500\n","Epoch 23/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.6200 - accuracy: 0.3369 - val_loss: 5.6592 - val_accuracy: 0.2500\n","Epoch 24/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.9127 - accuracy: 0.3564 - val_loss: 5.6576 - val_accuracy: 0.2500\n","Epoch 25/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.5405 - accuracy: 0.3252 - val_loss: 5.6514 - val_accuracy: 0.2500\n","Epoch 26/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.6999 - accuracy: 0.3291 - val_loss: 5.6479 - val_accuracy: 0.3000\n","Epoch 27/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.8004 - accuracy: 0.3174 - val_loss: 5.6451 - val_accuracy: 0.3000\n","Epoch 28/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.1605 - accuracy: 0.3174 - val_loss: 5.6395 - val_accuracy: 0.3000\n","Epoch 29/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.1423 - accuracy: 0.3760 - val_loss: 5.6319 - val_accuracy: 0.3000\n","Epoch 30/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.3719 - accuracy: 0.3135 - val_loss: 5.6081 - val_accuracy: 0.3000\n","Epoch 31/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.1295 - accuracy: 0.3145 - val_loss: 5.6065 - val_accuracy: 0.3000\n","Epoch 32/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.0614 - accuracy: 0.3379 - val_loss: 5.6047 - val_accuracy: 0.3000\n","Epoch 33/100\n","3/3 [==============================] - 0s 27ms/step - loss: 4.4523 - accuracy: 0.3028 - val_loss: 5.6055 - val_accuracy: 0.3000\n","Epoch 34/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.3977 - accuracy: 0.3252 - val_loss: 5.6045 - val_accuracy: 0.3000\n","Epoch 35/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.9563 - accuracy: 0.3174 - val_loss: 5.6050 - val_accuracy: 0.3000\n","Epoch 36/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.4188 - accuracy: 0.3056 - val_loss: 5.6058 - val_accuracy: 0.3000\n","Epoch 37/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.3500 - accuracy: 0.3330 - val_loss: 5.6042 - val_accuracy: 0.3000\n","Epoch 38/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.7697 - accuracy: 0.3330 - val_loss: 5.6045 - val_accuracy: 0.3000\n","Epoch 39/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.9570 - accuracy: 0.3614 - val_loss: 5.6041 - val_accuracy: 0.3000\n","Epoch 40/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.3689 - accuracy: 0.3184 - val_loss: 5.6035 - val_accuracy: 0.3000\n","Epoch 41/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.1999 - accuracy: 0.3184 - val_loss: 5.6033 - val_accuracy: 0.3000\n","Epoch 42/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.8408 - accuracy: 0.3145 - val_loss: 5.6024 - val_accuracy: 0.3000\n","Epoch 43/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.1121 - accuracy: 0.3809 - val_loss: 5.6008 - val_accuracy: 0.3000\n","Epoch 44/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.4899 - accuracy: 0.3301 - val_loss: 5.5997 - val_accuracy: 0.3000\n","Epoch 45/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.3246 - accuracy: 0.3184 - val_loss: 5.5996 - val_accuracy: 0.3000\n","Epoch 46/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.3207 - accuracy: 0.3184 - val_loss: 5.5995 - val_accuracy: 0.3000\n","Epoch 47/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.2400 - accuracy: 0.3301 - val_loss: 5.5977 - val_accuracy: 0.3000\n","Epoch 48/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.2987 - accuracy: 0.3379 - val_loss: 5.5969 - val_accuracy: 0.3000\n","Epoch 49/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.2502 - accuracy: 0.3262 - val_loss: 5.5963 - val_accuracy: 0.3000\n","Epoch 50/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.1234 - accuracy: 0.3301 - val_loss: 5.5953 - val_accuracy: 0.3000\n","Epoch 51/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.2395 - accuracy: 0.3301 - val_loss: 5.5951 - val_accuracy: 0.3000\n","Epoch 52/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.4055 - accuracy: 0.3106 - val_loss: 5.5949 - val_accuracy: 0.3000\n","Epoch 53/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.5896 - accuracy: 0.3106 - val_loss: 5.5943 - val_accuracy: 0.3000\n","Epoch 54/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.3768 - accuracy: 0.3028 - val_loss: 5.5935 - val_accuracy: 0.3000\n","Epoch 55/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.9305 - accuracy: 0.3731 - val_loss: 5.5925 - val_accuracy: 0.3000\n","Epoch 56/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.1978 - accuracy: 0.3497 - val_loss: 5.5915 - val_accuracy: 0.3000\n","Epoch 57/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.2411 - accuracy: 0.3223 - val_loss: 5.5913 - val_accuracy: 0.3000\n","Epoch 58/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.3471 - accuracy: 0.3301 - val_loss: 5.5903 - val_accuracy: 0.3000\n","Epoch 59/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.4138 - accuracy: 0.3262 - val_loss: 5.5901 - val_accuracy: 0.3000\n","Epoch 60/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.2475 - accuracy: 0.2911 - val_loss: 5.5890 - val_accuracy: 0.3000\n","Epoch 61/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.2144 - accuracy: 0.3262 - val_loss: 5.5873 - val_accuracy: 0.3000\n","Epoch 62/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.4565 - accuracy: 0.3418 - val_loss: 5.5863 - val_accuracy: 0.3000\n","Epoch 63/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.0804 - accuracy: 0.3497 - val_loss: 5.5850 - val_accuracy: 0.3000\n","Epoch 64/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.1808 - accuracy: 0.3418 - val_loss: 5.5842 - val_accuracy: 0.3000\n","Epoch 65/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.1838 - accuracy: 0.3458 - val_loss: 5.5846 - val_accuracy: 0.3000\n","Epoch 66/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.5243 - accuracy: 0.3067 - val_loss: 5.5837 - val_accuracy: 0.3000\n","Epoch 67/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.1755 - accuracy: 0.3106 - val_loss: 5.5836 - val_accuracy: 0.3000\n","Epoch 68/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.1156 - accuracy: 0.3301 - val_loss: 5.5835 - val_accuracy: 0.3000\n","Epoch 69/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.2312 - accuracy: 0.3536 - val_loss: 5.5820 - val_accuracy: 0.3000\n","Epoch 70/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.9733 - accuracy: 0.3184 - val_loss: 5.5802 - val_accuracy: 0.3000\n","Epoch 71/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.4297 - accuracy: 0.3436 - val_loss: 5.6268 - val_accuracy: 0.3000\n","Epoch 72/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.4917 - accuracy: 0.3621 - val_loss: 5.6258 - val_accuracy: 0.3000\n","Epoch 73/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.7588 - accuracy: 0.3856 - val_loss: 5.6251 - val_accuracy: 0.3000\n","Epoch 74/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.1187 - accuracy: 0.3817 - val_loss: 5.6244 - val_accuracy: 0.3000\n","Epoch 75/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.4530 - accuracy: 0.3387 - val_loss: 5.6238 - val_accuracy: 0.3000\n","Epoch 76/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.1890 - accuracy: 0.3738 - val_loss: 5.6232 - val_accuracy: 0.3000\n","Epoch 77/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.4143 - accuracy: 0.3426 - val_loss: 5.6225 - val_accuracy: 0.3000\n","Epoch 78/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.7249 - accuracy: 0.3728 - val_loss: 5.6224 - val_accuracy: 0.3000\n","Epoch 79/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.1022 - accuracy: 0.3767 - val_loss: 5.6220 - val_accuracy: 0.3000\n","Epoch 80/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.7619 - accuracy: 0.3650 - val_loss: 5.6209 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 127ms/step - loss: 5.0282 - accuracy: 0.3158\n","Epoch 1/100\n","3/3 [==============================] - 0s 96ms/step - loss: 8.0573 - accuracy: 0.2399 - val_loss: 5.8840 - val_accuracy: 0.3500\n","Epoch 2/100\n","3/3 [==============================] - 0s 31ms/step - loss: 7.4964 - accuracy: 0.2232 - val_loss: 5.0637 - val_accuracy: 0.3000\n","Epoch 3/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.1345 - accuracy: 0.2612 - val_loss: 4.5014 - val_accuracy: 0.3000\n","Epoch 4/100\n","3/3 [==============================] - 0s 30ms/step - loss: 7.1243 - accuracy: 0.2417 - val_loss: 4.4887 - val_accuracy: 0.3000\n","Epoch 5/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.3293 - accuracy: 0.2417 - val_loss: 4.3392 - val_accuracy: 0.3000\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.3578 - accuracy: 0.2534 - val_loss: 3.8743 - val_accuracy: 0.3000\n","Epoch 7/100\n","3/3 [==============================] - 0s 30ms/step - loss: 7.1734 - accuracy: 0.2612 - val_loss: 3.8656 - val_accuracy: 0.3000\n","Epoch 8/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.0359 - accuracy: 0.2768 - val_loss: 3.8576 - val_accuracy: 0.4000\n","Epoch 9/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.8789 - accuracy: 0.2562 - val_loss: 3.8510 - val_accuracy: 0.4000\n","Epoch 10/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.2090 - accuracy: 0.2651 - val_loss: 3.8403 - val_accuracy: 0.4000\n","Epoch 11/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.7142 - accuracy: 0.2573 - val_loss: 3.8278 - val_accuracy: 0.4000\n","Epoch 12/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.9064 - accuracy: 0.2729 - val_loss: 3.8231 - val_accuracy: 0.4000\n","Epoch 13/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.2541 - accuracy: 0.2914 - val_loss: 3.8025 - val_accuracy: 0.4000\n","Epoch 14/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.0766 - accuracy: 0.2640 - val_loss: 3.7353 - val_accuracy: 0.3500\n","Epoch 15/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.1458 - accuracy: 0.2523 - val_loss: 3.2380 - val_accuracy: 0.3500\n","Epoch 16/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.7015 - accuracy: 0.2942 - val_loss: 3.2379 - val_accuracy: 0.3500\n","Epoch 17/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.6869 - accuracy: 0.2552 - val_loss: 3.2367 - val_accuracy: 0.3500\n","Epoch 18/100\n","3/3 [==============================] - 0s 28ms/step - loss: 5.0838 - accuracy: 0.3020 - val_loss: 3.2189 - val_accuracy: 0.3000\n","Epoch 19/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.6546 - accuracy: 0.3177 - val_loss: 3.2158 - val_accuracy: 0.3000\n","Epoch 20/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.9907 - accuracy: 0.2786 - val_loss: 3.2131 - val_accuracy: 0.3000\n","Epoch 21/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.6956 - accuracy: 0.3177 - val_loss: 3.2141 - val_accuracy: 0.3000\n","Epoch 22/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.8467 - accuracy: 0.2747 - val_loss: 3.2131 - val_accuracy: 0.3000\n","Epoch 23/100\n","3/3 [==============================] - 0s 29ms/step - loss: 5.0305 - accuracy: 0.2786 - val_loss: 3.2120 - val_accuracy: 0.3000\n","Epoch 24/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.8066 - accuracy: 0.3020 - val_loss: 3.2069 - val_accuracy: 0.3000\n","Epoch 25/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.1925 - accuracy: 0.2864 - val_loss: 3.2082 - val_accuracy: 0.3000\n","Epoch 26/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.5312 - accuracy: 0.2395 - val_loss: 3.2082 - val_accuracy: 0.3000\n","Epoch 27/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.4743 - accuracy: 0.3450 - val_loss: 3.2087 - val_accuracy: 0.3000\n","Epoch 28/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.6829 - accuracy: 0.2601 - val_loss: 3.2101 - val_accuracy: 0.3000\n","Epoch 29/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.6526 - accuracy: 0.2523 - val_loss: 3.2107 - val_accuracy: 0.3000\n","Epoch 30/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.2486 - accuracy: 0.2445 - val_loss: 3.2134 - val_accuracy: 0.3000\n","Epoch 31/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.6952 - accuracy: 0.2328 - val_loss: 3.2164 - val_accuracy: 0.3000\n","Epoch 32/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.5169 - accuracy: 0.2719 - val_loss: 3.2170 - val_accuracy: 0.2500\n","Epoch 33/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.8463 - accuracy: 0.2836 - val_loss: 3.2186 - val_accuracy: 0.2500\n","Epoch 34/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.5574 - accuracy: 0.2797 - val_loss: 3.2189 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 127ms/step - loss: 5.5045 - accuracy: 0.3158\n","Epoch 1/100\n","3/3 [==============================] - 1s 109ms/step - loss: 9.1135 - accuracy: 0.2133 - val_loss: 9.2330 - val_accuracy: 0.1500\n","Epoch 2/100\n","3/3 [==============================] - 0s 29ms/step - loss: 8.3989 - accuracy: 0.2461 - val_loss: 9.8761 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 31ms/step - loss: 8.8766 - accuracy: 0.2149 - val_loss: 9.8717 - val_accuracy: 0.2500\n","Epoch 4/100\n","3/3 [==============================] - 0s 30ms/step - loss: 8.3580 - accuracy: 0.2149 - val_loss: 9.8658 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 32ms/step - loss: 8.9104 - accuracy: 0.2305 - val_loss: 9.8632 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 30ms/step - loss: 8.8531 - accuracy: 0.2372 - val_loss: 9.8615 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 30ms/step - loss: 8.2316 - accuracy: 0.2188 - val_loss: 9.8569 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 29ms/step - loss: 8.1878 - accuracy: 0.2121 - val_loss: 9.8481 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 31ms/step - loss: 8.0447 - accuracy: 0.2305 - val_loss: 9.8370 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 30ms/step - loss: 7.8190 - accuracy: 0.2461 - val_loss: 9.8284 - val_accuracy: 0.2500\n","Epoch 11/100\n","3/3 [==============================] - 0s 30ms/step - loss: 7.9283 - accuracy: 0.2461 - val_loss: 9.8210 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 116ms/step - loss: 5.0193 - accuracy: 0.5556\n","Epoch 1/100\n","3/3 [==============================] - 0s 102ms/step - loss: 8.2226 - accuracy: 0.2466 - val_loss: 8.0174 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 29ms/step - loss: 7.2173 - accuracy: 0.2712 - val_loss: 7.9680 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.5429 - accuracy: 0.2321 - val_loss: 7.9194 - val_accuracy: 0.2500\n","Epoch 4/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.4628 - accuracy: 0.2439 - val_loss: 7.2555 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 31ms/step - loss: 7.0569 - accuracy: 0.2595 - val_loss: 7.2467 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 29ms/step - loss: 7.0197 - accuracy: 0.2399 - val_loss: 7.2306 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.7489 - accuracy: 0.2478 - val_loss: 7.2087 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.8694 - accuracy: 0.2751 - val_loss: 7.1930 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.0006 - accuracy: 0.2517 - val_loss: 7.1772 - val_accuracy: 0.3000\n","Epoch 10/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.7719 - accuracy: 0.2779 - val_loss: 7.1903 - val_accuracy: 0.3000\n","Epoch 11/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.3239 - accuracy: 0.3041 - val_loss: 7.2482 - val_accuracy: 0.2000\n","Epoch 12/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.6595 - accuracy: 0.2728 - val_loss: 7.6703 - val_accuracy: 0.2000\n","Epoch 13/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.1093 - accuracy: 0.2779 - val_loss: 7.1802 - val_accuracy: 0.2000\n","Epoch 14/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.4338 - accuracy: 0.2701 - val_loss: 7.1812 - val_accuracy: 0.2000\n","Epoch 15/100\n","3/3 [==============================] - 0s 29ms/step - loss: 6.1694 - accuracy: 0.2544 - val_loss: 7.1714 - val_accuracy: 0.2000\n","Epoch 16/100\n","3/3 [==============================] - 0s 28ms/step - loss: 5.6652 - accuracy: 0.2974 - val_loss: 7.1642 - val_accuracy: 0.2000\n","Epoch 17/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.3657 - accuracy: 0.2544 - val_loss: 7.1612 - val_accuracy: 0.2000\n","Epoch 18/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.8946 - accuracy: 0.2466 - val_loss: 7.1441 - val_accuracy: 0.2000\n","Epoch 19/100\n","3/3 [==============================] - 0s 29ms/step - loss: 6.1156 - accuracy: 0.2310 - val_loss: 7.1343 - val_accuracy: 0.2000\n","Epoch 20/100\n","3/3 [==============================] - 0s 28ms/step - loss: 5.9704 - accuracy: 0.2583 - val_loss: 7.1933 - val_accuracy: 0.2000\n","Epoch 21/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.0949 - accuracy: 0.2622 - val_loss: 7.1879 - val_accuracy: 0.2000\n","Epoch 22/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.8806 - accuracy: 0.2661 - val_loss: 6.5551 - val_accuracy: 0.2000\n","Epoch 23/100\n","3/3 [==============================] - 0s 28ms/step - loss: 6.1114 - accuracy: 0.2388 - val_loss: 6.5306 - val_accuracy: 0.2000\n","Epoch 24/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.5868 - accuracy: 0.2388 - val_loss: 6.5027 - val_accuracy: 0.2000\n","Epoch 25/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.3845 - accuracy: 0.2661 - val_loss: 6.5143 - val_accuracy: 0.2000\n","Epoch 26/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.5343 - accuracy: 0.2779 - val_loss: 6.5198 - val_accuracy: 0.2000\n","Epoch 27/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.9426 - accuracy: 0.2466 - val_loss: 6.4923 - val_accuracy: 0.2000\n","Epoch 28/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.2484 - accuracy: 0.2505 - val_loss: 6.4556 - val_accuracy: 0.2000\n","Epoch 29/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.5549 - accuracy: 0.2740 - val_loss: 6.4393 - val_accuracy: 0.2000\n","Epoch 30/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.9213 - accuracy: 0.2349 - val_loss: 6.3862 - val_accuracy: 0.2000\n","Epoch 31/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.6914 - accuracy: 0.2946 - val_loss: 6.3238 - val_accuracy: 0.2000\n","Epoch 32/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.6445 - accuracy: 0.2478 - val_loss: 7.0230 - val_accuracy: 0.2000\n","Epoch 33/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.4910 - accuracy: 0.2701 - val_loss: 6.4580 - val_accuracy: 0.2000\n","Epoch 34/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.3276 - accuracy: 0.2857 - val_loss: 6.3767 - val_accuracy: 0.2000\n","Epoch 35/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.7861 - accuracy: 0.2806 - val_loss: 6.3771 - val_accuracy: 0.2500\n","Epoch 36/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.0239 - accuracy: 0.2544 - val_loss: 6.3715 - val_accuracy: 0.2000\n","Epoch 37/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.9726 - accuracy: 0.2572 - val_loss: 6.3657 - val_accuracy: 0.2000\n","Epoch 38/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.4159 - accuracy: 0.2494 - val_loss: 5.7871 - val_accuracy: 0.2500\n","Epoch 39/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.9578 - accuracy: 0.3236 - val_loss: 5.1430 - val_accuracy: 0.2500\n","Epoch 40/100\n","3/3 [==============================] - 0s 29ms/step - loss: 5.0320 - accuracy: 0.2923 - val_loss: 5.1354 - val_accuracy: 0.2500\n","Epoch 41/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.4846 - accuracy: 0.2923 - val_loss: 5.1264 - val_accuracy: 0.2500\n","Epoch 42/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.8440 - accuracy: 0.2845 - val_loss: 4.6832 - val_accuracy: 0.2500\n","Epoch 43/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.4195 - accuracy: 0.2533 - val_loss: 4.7696 - val_accuracy: 0.2500\n","Epoch 44/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.2063 - accuracy: 0.2689 - val_loss: 4.7069 - val_accuracy: 0.2500\n","Epoch 45/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.6642 - accuracy: 0.2728 - val_loss: 4.7703 - val_accuracy: 0.2500\n","Epoch 46/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.4211 - accuracy: 0.2689 - val_loss: 4.5739 - val_accuracy: 0.2500\n","Epoch 47/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.5442 - accuracy: 0.2845 - val_loss: 4.5672 - val_accuracy: 0.2500\n","Epoch 48/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.1280 - accuracy: 0.2795 - val_loss: 4.5546 - val_accuracy: 0.2500\n","Epoch 49/100\n","3/3 [==============================] - 0s 28ms/step - loss: 4.6141 - accuracy: 0.2912 - val_loss: 4.5464 - val_accuracy: 0.2500\n","Epoch 50/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.2518 - accuracy: 0.3224 - val_loss: 4.5356 - val_accuracy: 0.2500\n","Epoch 51/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.1781 - accuracy: 0.3029 - val_loss: 4.5268 - val_accuracy: 0.2500\n","Epoch 52/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.2143 - accuracy: 0.2834 - val_loss: 4.5232 - val_accuracy: 0.2500\n","Epoch 53/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.5974 - accuracy: 0.3068 - val_loss: 4.5122 - val_accuracy: 0.2500\n","Epoch 54/100\n","3/3 [==============================] - 0s 29ms/step - loss: 4.6397 - accuracy: 0.2951 - val_loss: 4.5006 - val_accuracy: 0.2500\n","Epoch 55/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.8381 - accuracy: 0.2873 - val_loss: 4.4856 - val_accuracy: 0.2500\n","Epoch 56/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.4011 - accuracy: 0.2756 - val_loss: 4.4616 - val_accuracy: 0.2500\n","Epoch 57/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.1700 - accuracy: 0.2795 - val_loss: 4.4629 - val_accuracy: 0.2500\n","Epoch 58/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.1272 - accuracy: 0.2990 - val_loss: 4.4637 - val_accuracy: 0.2500\n","Epoch 59/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.3327 - accuracy: 0.2912 - val_loss: 4.4663 - val_accuracy: 0.2000\n","Epoch 60/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.4833 - accuracy: 0.3029 - val_loss: 4.4693 - val_accuracy: 0.2000\n","Epoch 61/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.1937 - accuracy: 0.2717 - val_loss: 4.4723 - val_accuracy: 0.2000\n","Epoch 62/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.4172 - accuracy: 0.2533 - val_loss: 4.4748 - val_accuracy: 0.2000\n","Epoch 63/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.1872 - accuracy: 0.2533 - val_loss: 4.4764 - val_accuracy: 0.2000\n","Epoch 64/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.3386 - accuracy: 0.2533 - val_loss: 4.4799 - val_accuracy: 0.2000\n","Epoch 65/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.2923 - accuracy: 0.2923 - val_loss: 4.4822 - val_accuracy: 0.2000\n","Epoch 66/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.7583 - accuracy: 0.3158 - val_loss: 4.4847 - val_accuracy: 0.2000\n","1/1 [==============================] - 0s 123ms/step - loss: 5.4192 - accuracy: 0.2778\n","Epoch 1/100\n","3/3 [==============================] - 0s 100ms/step - loss: 9.3953 - accuracy: 0.2495 - val_loss: 5.5013 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.0729 - accuracy: 0.4126 - val_loss: 2.7184 - val_accuracy: 0.3000\n","Epoch 3/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.8886 - accuracy: 0.4417 - val_loss: 3.9885 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.4386 - accuracy: 0.4691 - val_loss: 2.8346 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.8207 - accuracy: 0.4211 - val_loss: 2.8093 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.3396 - accuracy: 0.4350 - val_loss: 4.2296 - val_accuracy: 0.2000\n","Epoch 7/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.9163 - accuracy: 0.4019 - val_loss: 4.2268 - val_accuracy: 0.1500\n","Epoch 8/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.1047 - accuracy: 0.4019 - val_loss: 4.2218 - val_accuracy: 0.1500\n","Epoch 9/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.2292 - accuracy: 0.3785 - val_loss: 4.2149 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.2476 - accuracy: 0.3874 - val_loss: 4.2128 - val_accuracy: 0.1500\n","Epoch 11/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.0930 - accuracy: 0.3913 - val_loss: 4.2102 - val_accuracy: 0.1500\n","Epoch 12/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.1943 - accuracy: 0.3756 - val_loss: 4.2048 - val_accuracy: 0.1500\n","1/1 [==============================] - 0s 114ms/step - loss: 3.6185 - accuracy: 0.0526\n","Epoch 1/100\n","3/3 [==============================] - 1s 109ms/step - loss: 7.1939 - accuracy: 0.2271 - val_loss: 6.1857 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.9896 - accuracy: 0.3241 - val_loss: 4.8492 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.6405 - accuracy: 0.3486 - val_loss: 3.5507 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.4848 - accuracy: 0.3379 - val_loss: 4.0549 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.9728 - accuracy: 0.2950 - val_loss: 3.4995 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.6897 - accuracy: 0.3223 - val_loss: 3.5113 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.9057 - accuracy: 0.3458 - val_loss: 3.5290 - val_accuracy: 0.3500\n","Epoch 8/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.8106 - accuracy: 0.3301 - val_loss: 4.0025 - val_accuracy: 0.3500\n","Epoch 9/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.6062 - accuracy: 0.3497 - val_loss: 4.0586 - val_accuracy: 0.3500\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.6290 - accuracy: 0.3067 - val_loss: 4.0842 - val_accuracy: 0.3500\n","Epoch 11/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.6747 - accuracy: 0.3106 - val_loss: 4.0993 - val_accuracy: 0.3500\n","Epoch 12/100\n","3/3 [==============================] - 0s 29ms/step - loss: 1.5885 - accuracy: 0.3223 - val_loss: 4.1352 - val_accuracy: 0.3500\n","Epoch 13/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.7839 - accuracy: 0.3184 - val_loss: 4.1385 - val_accuracy: 0.3500\n","Epoch 14/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.4035 - accuracy: 0.3340 - val_loss: 4.1530 - val_accuracy: 0.3500\n","Epoch 15/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.7978 - accuracy: 0.3106 - val_loss: 4.1616 - val_accuracy: 0.3500\n","1/1 [==============================] - 0s 118ms/step - loss: 4.5334 - accuracy: 0.3684\n","Epoch 1/100\n","3/3 [==============================] - 0s 97ms/step - loss: 7.1569 - accuracy: 0.3554 - val_loss: 6.6269 - val_accuracy: 0.4000\n","Epoch 2/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.3833 - accuracy: 0.3525 - val_loss: 3.2883 - val_accuracy: 0.1500\n","Epoch 3/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.1332 - accuracy: 0.2836 - val_loss: 2.6316 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.8037 - accuracy: 0.2409 - val_loss: 3.2381 - val_accuracy: 0.3000\n","Epoch 5/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.3518 - accuracy: 0.2185 - val_loss: 2.5770 - val_accuracy: 0.4000\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.9946 - accuracy: 0.2981 - val_loss: 2.5639 - val_accuracy: 0.4000\n","Epoch 7/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.6490 - accuracy: 0.2758 - val_loss: 1.8462 - val_accuracy: 0.4000\n","Epoch 8/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.2867 - accuracy: 0.3106 - val_loss: 1.8456 - val_accuracy: 0.4000\n","Epoch 9/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.0564 - accuracy: 0.3273 - val_loss: 1.8456 - val_accuracy: 0.4000\n","Epoch 10/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.2462 - accuracy: 0.2960 - val_loss: 1.8456 - val_accuracy: 0.4000\n","Epoch 11/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.0397 - accuracy: 0.3262 - val_loss: 1.8456 - val_accuracy: 0.4000\n","Epoch 12/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.3927 - accuracy: 0.4012 - val_loss: 3.2238 - val_accuracy: 0.4000\n","Epoch 13/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.7059 - accuracy: 0.3117 - val_loss: 2.5129 - val_accuracy: 0.4000\n","Epoch 14/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.8573 - accuracy: 0.3138 - val_loss: 6.9945 - val_accuracy: 0.3000\n","Epoch 15/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.0404 - accuracy: 0.1980 - val_loss: 6.9948 - val_accuracy: 0.3000\n","Epoch 16/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.6594 - accuracy: 0.2409 - val_loss: 6.9950 - val_accuracy: 0.3000\n","Epoch 17/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.9594 - accuracy: 0.2058 - val_loss: 6.9953 - val_accuracy: 0.3000\n","Epoch 18/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.9131 - accuracy: 0.1980 - val_loss: 6.9951 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 130ms/step - loss: 7.4827 - accuracy: 0.1579\n","Epoch 1/100\n","3/3 [==============================] - 1s 103ms/step - loss: 8.6703 - accuracy: 0.1715 - val_loss: 4.0784 - val_accuracy: 0.3500\n","Epoch 2/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.7876 - accuracy: 0.2556 - val_loss: 4.2071 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.1346 - accuracy: 0.3229 - val_loss: 4.2168 - val_accuracy: 0.2500\n","Epoch 4/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.5319 - accuracy: 0.3402 - val_loss: 4.2094 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.1240 - accuracy: 0.4183 - val_loss: 4.2015 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.0671 - accuracy: 0.3937 - val_loss: 4.1787 - val_accuracy: 0.2000\n","Epoch 7/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.1270 - accuracy: 0.3675 - val_loss: 3.5085 - val_accuracy: 0.3000\n","Epoch 8/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.1589 - accuracy: 0.3992 - val_loss: 3.5040 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.1081 - accuracy: 0.4109 - val_loss: 3.5016 - val_accuracy: 0.3000\n","Epoch 10/100\n","3/3 [==============================] - 0s 40ms/step - loss: 2.8749 - accuracy: 0.4293 - val_loss: 4.0543 - val_accuracy: 0.3500\n","Epoch 11/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.0622 - accuracy: 0.3864 - val_loss: 4.0856 - val_accuracy: 0.3000\n","Epoch 12/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.0484 - accuracy: 0.4438 - val_loss: 4.1050 - val_accuracy: 0.3000\n","Epoch 13/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.9001 - accuracy: 0.4098 - val_loss: 6.3628 - val_accuracy: 0.3000\n","Epoch 14/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.1322 - accuracy: 0.3742 - val_loss: 4.1334 - val_accuracy: 0.3500\n","Epoch 15/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.6311 - accuracy: 0.3452 - val_loss: 4.1337 - val_accuracy: 0.3000\n","Epoch 16/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.0812 - accuracy: 0.4043 - val_loss: 4.1657 - val_accuracy: 0.2500\n","Epoch 17/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.6642 - accuracy: 0.4137 - val_loss: 4.1633 - val_accuracy: 0.3000\n","Epoch 18/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.4908 - accuracy: 0.4438 - val_loss: 4.1659 - val_accuracy: 0.3000\n","Epoch 19/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.1639 - accuracy: 0.4516 - val_loss: 4.1680 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 116ms/step - loss: 1.4417 - accuracy: 0.1111\n","Epoch 1/100\n","3/3 [==============================] - 1s 113ms/step - loss: 7.7808 - accuracy: 0.3057 - val_loss: 8.6531 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.5068 - accuracy: 0.4109 - val_loss: 6.9912 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.4288 - accuracy: 0.3464 - val_loss: 6.0749 - val_accuracy: 0.4500\n","Epoch 4/100\n","3/3 [==============================] - 0s 39ms/step - loss: 5.1233 - accuracy: 0.3937 - val_loss: 4.7737 - val_accuracy: 0.4500\n","Epoch 5/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.7489 - accuracy: 0.3942 - val_loss: 4.7774 - val_accuracy: 0.4000\n","Epoch 6/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.1417 - accuracy: 0.4126 - val_loss: 4.8025 - val_accuracy: 0.4000\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.5154 - accuracy: 0.4148 - val_loss: 4.8683 - val_accuracy: 0.1000\n","Epoch 8/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.8350 - accuracy: 0.3659 - val_loss: 4.8672 - val_accuracy: 0.1000\n","Epoch 9/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.4147 - accuracy: 0.3335 - val_loss: 4.8704 - val_accuracy: 0.1000\n","Epoch 10/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.2654 - accuracy: 0.3245 - val_loss: 3.5592 - val_accuracy: 0.1000\n","Epoch 11/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.4677 - accuracy: 0.3061 - val_loss: 3.5653 - val_accuracy: 0.0500\n","Epoch 12/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.2051 - accuracy: 0.3061 - val_loss: 3.5747 - val_accuracy: 0.0500\n","Epoch 13/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.6647 - accuracy: 0.3808 - val_loss: 6.2451 - val_accuracy: 0.1000\n","Epoch 14/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.7696 - accuracy: 0.3112 - val_loss: 2.7982 - val_accuracy: 0.1500\n","Epoch 15/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.3981 - accuracy: 0.3898 - val_loss: 2.6797 - val_accuracy: 0.1500\n","Epoch 16/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.8316 - accuracy: 0.3468 - val_loss: 2.0593 - val_accuracy: 0.1500\n","Epoch 17/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.1132 - accuracy: 0.3624 - val_loss: 2.0638 - val_accuracy: 0.1000\n","Epoch 18/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.5254 - accuracy: 0.3808 - val_loss: 2.0644 - val_accuracy: 0.1000\n","Epoch 19/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.4163 - accuracy: 0.3585 - val_loss: 2.0688 - val_accuracy: 0.1000\n","Epoch 20/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.3240 - accuracy: 0.3742 - val_loss: 2.0814 - val_accuracy: 0.1000\n","Epoch 21/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.1016 - accuracy: 0.4070 - val_loss: 2.0971 - val_accuracy: 0.1000\n","Epoch 22/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.9348 - accuracy: 0.4344 - val_loss: 2.0906 - val_accuracy: 0.1000\n","Epoch 23/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.9954 - accuracy: 0.4070 - val_loss: 2.0933 - val_accuracy: 0.1000\n","Epoch 24/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.9368 - accuracy: 0.4227 - val_loss: 2.0986 - val_accuracy: 0.1000\n","Epoch 25/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.1290 - accuracy: 0.3875 - val_loss: 2.0993 - val_accuracy: 0.1500\n","Epoch 26/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.0768 - accuracy: 0.4070 - val_loss: 2.1032 - val_accuracy: 0.1500\n","1/1 [==============================] - 0s 122ms/step - loss: 3.7897 - accuracy: 0.1111\n","Epoch 1/100\n","3/3 [==============================] - 1s 106ms/step - loss: 7.6155 - accuracy: 0.2658 - val_loss: 3.3588 - val_accuracy: 0.3000\n","Epoch 2/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.1152 - accuracy: 0.4254 - val_loss: 3.1534 - val_accuracy: 0.4500\n","Epoch 3/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.1730 - accuracy: 0.5242 - val_loss: 2.9642 - val_accuracy: 0.4500\n","Epoch 4/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.0703 - accuracy: 0.5632 - val_loss: 1.7601 - val_accuracy: 0.5000\n","Epoch 5/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.6903 - accuracy: 0.4300 - val_loss: 2.6469 - val_accuracy: 0.4000\n","Epoch 6/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.2292 - accuracy: 0.3582 - val_loss: 2.0179 - val_accuracy: 0.3500\n","Epoch 7/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.9608 - accuracy: 0.3543 - val_loss: 1.9734 - val_accuracy: 0.4000\n","Epoch 8/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.8821 - accuracy: 0.3436 - val_loss: 1.9620 - val_accuracy: 0.4000\n","Epoch 9/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.8028 - accuracy: 0.3436 - val_loss: 1.9383 - val_accuracy: 0.4500\n","Epoch 10/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.7664 - accuracy: 0.3944 - val_loss: 1.9442 - val_accuracy: 0.5000\n","Epoch 11/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.7242 - accuracy: 0.3291 - val_loss: 1.9421 - val_accuracy: 0.5000\n","Epoch 12/100\n","3/3 [==============================] - 0s 29ms/step - loss: 1.6002 - accuracy: 0.3358 - val_loss: 1.9477 - val_accuracy: 0.4000\n","Epoch 13/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.5050 - accuracy: 0.3379 - val_loss: 1.9255 - val_accuracy: 0.4000\n","Epoch 14/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.7510 - accuracy: 0.3319 - val_loss: 1.8969 - val_accuracy: 0.5500\n","1/1 [==============================] - 0s 134ms/step - loss: 3.5233 - accuracy: 0.2632\n","Epoch 1/100\n","3/3 [==============================] - 1s 101ms/step - loss: 7.4898 - accuracy: 0.1514 - val_loss: 6.4385 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.8805 - accuracy: 0.2999 - val_loss: 3.9994 - val_accuracy: 0.3000\n","Epoch 3/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.1649 - accuracy: 0.3397 - val_loss: 4.0257 - val_accuracy: 0.4500\n","Epoch 4/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.5713 - accuracy: 0.3252 - val_loss: 3.4825 - val_accuracy: 0.4000\n","Epoch 5/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.9255 - accuracy: 0.3319 - val_loss: 3.4843 - val_accuracy: 0.4000\n","Epoch 6/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.5052 - accuracy: 0.3436 - val_loss: 3.4869 - val_accuracy: 0.4500\n","Epoch 7/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.8976 - accuracy: 0.3465 - val_loss: 5.5937 - val_accuracy: 0.3500\n","Epoch 8/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.5912 - accuracy: 0.4350 - val_loss: 3.5793 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.3052 - accuracy: 0.4126 - val_loss: 5.6208 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.3727 - accuracy: 0.4311 - val_loss: 4.2550 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.9829 - accuracy: 0.4115 - val_loss: 5.5480 - val_accuracy: 0.2500\n","Epoch 12/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.9715 - accuracy: 0.4865 - val_loss: 4.1443 - val_accuracy: 0.2000\n","Epoch 13/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.7584 - accuracy: 0.5273 - val_loss: 4.6693 - val_accuracy: 0.1500\n","Epoch 14/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.5994 - accuracy: 0.4826 - val_loss: 5.4067 - val_accuracy: 0.2000\n","1/1 [==============================] - 0s 121ms/step - loss: 4.1658 - accuracy: 0.2632\n","Epoch 1/100\n","3/3 [==============================] - 1s 108ms/step - loss: 6.0678 - accuracy: 0.2953 - val_loss: 10.2616 - val_accuracy: 0.1500\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.0214 - accuracy: 0.4254 - val_loss: 10.1912 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.6213 - accuracy: 0.4058 - val_loss: 7.8936 - val_accuracy: 0.3000\n","Epoch 4/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.7999 - accuracy: 0.4467 - val_loss: 7.8427 - val_accuracy: 0.3500\n","Epoch 5/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.6945 - accuracy: 0.4524 - val_loss: 7.1404 - val_accuracy: 0.3500\n","Epoch 6/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.8206 - accuracy: 0.4971 - val_loss: 7.1257 - val_accuracy: 0.3500\n","Epoch 7/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.2395 - accuracy: 0.4670 - val_loss: 7.1302 - val_accuracy: 0.3500\n","Epoch 8/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.1477 - accuracy: 0.4670 - val_loss: 7.0777 - val_accuracy: 0.4000\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.8867 - accuracy: 0.5128 - val_loss: 6.3715 - val_accuracy: 0.4000\n","Epoch 10/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.5734 - accuracy: 0.4865 - val_loss: 6.3715 - val_accuracy: 0.4000\n","Epoch 11/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.7354 - accuracy: 0.5138 - val_loss: 6.3677 - val_accuracy: 0.4000\n","Epoch 12/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.5213 - accuracy: 0.4776 - val_loss: 6.3561 - val_accuracy: 0.4000\n","Epoch 13/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.5424 - accuracy: 0.4854 - val_loss: 6.3514 - val_accuracy: 0.4000\n","Epoch 14/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.7239 - accuracy: 0.4854 - val_loss: 6.3529 - val_accuracy: 0.4000\n","Epoch 15/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.4323 - accuracy: 0.5128 - val_loss: 6.3483 - val_accuracy: 0.4000\n","Epoch 16/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.7300 - accuracy: 0.4854 - val_loss: 6.3447 - val_accuracy: 0.4000\n","Epoch 17/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.4961 - accuracy: 0.5050 - val_loss: 6.3442 - val_accuracy: 0.4000\n","Epoch 18/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.4186 - accuracy: 0.4893 - val_loss: 6.3357 - val_accuracy: 0.4000\n","Epoch 19/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.7414 - accuracy: 0.4670 - val_loss: 6.3293 - val_accuracy: 0.4000\n","Epoch 20/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.7406 - accuracy: 0.4826 - val_loss: 6.3229 - val_accuracy: 0.4000\n","Epoch 21/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.6066 - accuracy: 0.4709 - val_loss: 6.3191 - val_accuracy: 0.4000\n","Epoch 22/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.4317 - accuracy: 0.4630 - val_loss: 6.3224 - val_accuracy: 0.4000\n","Epoch 23/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.5538 - accuracy: 0.4630 - val_loss: 6.3165 - val_accuracy: 0.4000\n","Epoch 24/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.7176 - accuracy: 0.4865 - val_loss: 6.3137 - val_accuracy: 0.4000\n","Epoch 25/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.5655 - accuracy: 0.4670 - val_loss: 6.3079 - val_accuracy: 0.4000\n","Epoch 26/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.5137 - accuracy: 0.4865 - val_loss: 6.3059 - val_accuracy: 0.4000\n","Epoch 27/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.5684 - accuracy: 0.4748 - val_loss: 6.3079 - val_accuracy: 0.4000\n","Epoch 28/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.8341 - accuracy: 0.5050 - val_loss: 6.3107 - val_accuracy: 0.4000\n","Epoch 29/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.5676 - accuracy: 0.5234 - val_loss: 6.3124 - val_accuracy: 0.4000\n","Epoch 30/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.5687 - accuracy: 0.4737 - val_loss: 6.3122 - val_accuracy: 0.4000\n","Epoch 31/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.4501 - accuracy: 0.5011 - val_loss: 6.3120 - val_accuracy: 0.4000\n","Epoch 32/100\n","3/3 [==============================] - 0s 43ms/step - loss: 1.6382 - accuracy: 0.5050 - val_loss: 6.3099 - val_accuracy: 0.4000\n","Epoch 33/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.4979 - accuracy: 0.4776 - val_loss: 6.3105 - val_accuracy: 0.4000\n","Epoch 34/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.6910 - accuracy: 0.5245 - val_loss: 6.3077 - val_accuracy: 0.4000\n","Epoch 35/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.5001 - accuracy: 0.4815 - val_loss: 6.3123 - val_accuracy: 0.4000\n","Epoch 36/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.5452 - accuracy: 0.4542 - val_loss: 6.3137 - val_accuracy: 0.4000\n","1/1 [==============================] - 0s 135ms/step - loss: 7.4894 - accuracy: 0.3684\n","Epoch 1/100\n","3/3 [==============================] - 1s 105ms/step - loss: 6.8763 - accuracy: 0.3296 - val_loss: 3.3540 - val_accuracy: 0.4000\n","Epoch 2/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.4907 - accuracy: 0.3542 - val_loss: 3.2909 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.1791 - accuracy: 0.3514 - val_loss: 3.2927 - val_accuracy: 0.2500\n","Epoch 4/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.3826 - accuracy: 0.3241 - val_loss: 3.2977 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.0463 - accuracy: 0.3358 - val_loss: 3.2878 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.2581 - accuracy: 0.3190 - val_loss: 3.2824 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.8870 - accuracy: 0.3112 - val_loss: 3.2758 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.0018 - accuracy: 0.3229 - val_loss: 3.2757 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.7426 - accuracy: 0.3358 - val_loss: 3.2754 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.0022 - accuracy: 0.3358 - val_loss: 3.2744 - val_accuracy: 0.2500\n","Epoch 11/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.6636 - accuracy: 0.2811 - val_loss: 3.2793 - val_accuracy: 0.2500\n","Epoch 12/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.7380 - accuracy: 0.3358 - val_loss: 3.2926 - val_accuracy: 0.2500\n","Epoch 13/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.6195 - accuracy: 0.3346 - val_loss: 3.3344 - val_accuracy: 0.2500\n","Epoch 14/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.9737 - accuracy: 0.3424 - val_loss: 3.9809 - val_accuracy: 0.2500\n","Epoch 15/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.7097 - accuracy: 0.3686 - val_loss: 3.9713 - val_accuracy: 0.2500\n","Epoch 16/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.9683 - accuracy: 0.3123 - val_loss: 3.9567 - val_accuracy: 0.2500\n","Epoch 17/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.6693 - accuracy: 0.3475 - val_loss: 3.9520 - val_accuracy: 0.2500\n","Epoch 18/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.6673 - accuracy: 0.2967 - val_loss: 3.9524 - val_accuracy: 0.2500\n","Epoch 19/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.9524 - accuracy: 0.3280 - val_loss: 3.9370 - val_accuracy: 0.2500\n","Epoch 20/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.7233 - accuracy: 0.2967 - val_loss: 3.9300 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 123ms/step - loss: 1.8846 - accuracy: 0.2222\n","Epoch 1/100\n","3/3 [==============================] - 1s 104ms/step - loss: 3.7025 - accuracy: 0.3491 - val_loss: 2.2927 - val_accuracy: 0.5500\n","Epoch 2/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.8087 - accuracy: 0.3335 - val_loss: 2.2475 - val_accuracy: 0.5500\n","Epoch 3/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.9030 - accuracy: 0.3608 - val_loss: 2.2846 - val_accuracy: 0.5500\n","Epoch 4/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.2068 - accuracy: 0.3597 - val_loss: 2.3480 - val_accuracy: 0.5500\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.2689 - accuracy: 0.3965 - val_loss: 1.0715 - val_accuracy: 0.3000\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.2910 - accuracy: 0.3335 - val_loss: 1.0911 - val_accuracy: 0.3000\n","Epoch 7/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.2642 - accuracy: 0.3558 - val_loss: 1.1091 - val_accuracy: 0.3000\n","Epoch 8/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.0227 - accuracy: 0.3636 - val_loss: 1.1459 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.8944 - accuracy: 0.3675 - val_loss: 1.1410 - val_accuracy: 0.3000\n","Epoch 10/100\n","3/3 [==============================] - 0s 40ms/step - loss: 1.7031 - accuracy: 0.3675 - val_loss: 1.1365 - val_accuracy: 0.3000\n","Epoch 11/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.0945 - accuracy: 0.3792 - val_loss: 1.1368 - val_accuracy: 0.3000\n","Epoch 12/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.9537 - accuracy: 0.3441 - val_loss: 1.1381 - val_accuracy: 0.3000\n","Epoch 13/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.9378 - accuracy: 0.3636 - val_loss: 1.1592 - val_accuracy: 0.3000\n","Epoch 14/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.9309 - accuracy: 0.3753 - val_loss: 1.1608 - val_accuracy: 0.3000\n","Epoch 15/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.9387 - accuracy: 0.3402 - val_loss: 1.2087 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 128ms/step - loss: 4.4785 - accuracy: 0.0556\n","Epoch 1/100\n","3/3 [==============================] - 1s 112ms/step - loss: 14.7711 - accuracy: 0.0000e+00 - val_loss: 11.7968 - val_accuracy: 0.1000\n","Epoch 2/100\n","3/3 [==============================] - 0s 33ms/step - loss: 12.0815 - accuracy: 0.0000e+00 - val_loss: 11.7037 - val_accuracy: 0.1000\n","Epoch 3/100\n","3/3 [==============================] - 0s 32ms/step - loss: 10.8066 - accuracy: 0.0174 - val_loss: 7.7602 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 31ms/step - loss: 9.4953 - accuracy: 0.1059 - val_loss: 5.8848 - val_accuracy: 0.2000\n","Epoch 5/100\n","3/3 [==============================] - 0s 35ms/step - loss: 8.4985 - accuracy: 0.0942 - val_loss: 7.6684 - val_accuracy: 0.2000\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.9792 - accuracy: 0.1855 - val_loss: 5.8545 - val_accuracy: 0.1500\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 7.2233 - accuracy: 0.1766 - val_loss: 5.8381 - val_accuracy: 0.1500\n","Epoch 8/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.3757 - accuracy: 0.1962 - val_loss: 5.8254 - val_accuracy: 0.1500\n","Epoch 9/100\n","3/3 [==============================] - 0s 31ms/step - loss: 7.1913 - accuracy: 0.2040 - val_loss: 5.8142 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 42ms/step - loss: 7.6248 - accuracy: 0.1766 - val_loss: 5.8045 - val_accuracy: 0.1500\n","Epoch 11/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.3728 - accuracy: 0.2235 - val_loss: 5.7997 - val_accuracy: 0.2500\n","Epoch 12/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.5118 - accuracy: 0.1862 - val_loss: 5.7925 - val_accuracy: 0.2500\n","Epoch 13/100\n","3/3 [==============================] - 0s 31ms/step - loss: 7.1154 - accuracy: 0.2058 - val_loss: 5.7857 - val_accuracy: 0.2500\n","Epoch 14/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.2160 - accuracy: 0.2487 - val_loss: 5.7801 - val_accuracy: 0.2500\n","Epoch 15/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.0288 - accuracy: 0.1901 - val_loss: 5.7723 - val_accuracy: 0.2500\n","Epoch 16/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.8390 - accuracy: 0.2175 - val_loss: 5.7661 - val_accuracy: 0.2500\n","Epoch 17/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.8091 - accuracy: 0.1901 - val_loss: 5.7610 - val_accuracy: 0.2500\n","Epoch 18/100\n","3/3 [==============================] - 0s 36ms/step - loss: 6.5144 - accuracy: 0.1980 - val_loss: 5.7552 - val_accuracy: 0.2500\n","Epoch 19/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.6004 - accuracy: 0.2136 - val_loss: 5.7499 - val_accuracy: 0.2500\n","Epoch 20/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.1854 - accuracy: 0.2136 - val_loss: 5.7426 - val_accuracy: 0.2500\n","Epoch 21/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.6615 - accuracy: 0.2331 - val_loss: 5.7367 - val_accuracy: 0.2500\n","Epoch 22/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.5786 - accuracy: 0.2370 - val_loss: 5.7316 - val_accuracy: 0.2500\n","Epoch 23/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.5339 - accuracy: 0.2253 - val_loss: 5.7265 - val_accuracy: 0.2500\n","Epoch 24/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.4567 - accuracy: 0.2214 - val_loss: 5.7209 - val_accuracy: 0.2500\n","Epoch 25/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.9663 - accuracy: 0.2321 - val_loss: 5.7087 - val_accuracy: 0.2500\n","Epoch 26/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.0066 - accuracy: 0.2544 - val_loss: 5.6985 - val_accuracy: 0.2500\n","Epoch 27/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.3761 - accuracy: 0.2037 - val_loss: 5.6933 - val_accuracy: 0.2500\n","Epoch 28/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.4035 - accuracy: 0.2260 - val_loss: 5.6875 - val_accuracy: 0.2500\n","Epoch 29/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.6669 - accuracy: 0.2456 - val_loss: 5.6779 - val_accuracy: 0.2500\n","Epoch 30/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.6529 - accuracy: 0.2690 - val_loss: 5.6698 - val_accuracy: 0.2500\n","Epoch 31/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.6066 - accuracy: 0.2573 - val_loss: 5.6646 - val_accuracy: 0.3000\n","Epoch 32/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.2285 - accuracy: 0.2583 - val_loss: 5.6599 - val_accuracy: 0.3000\n","Epoch 33/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.1984 - accuracy: 0.2115 - val_loss: 5.6572 - val_accuracy: 0.3000\n","Epoch 34/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.0307 - accuracy: 0.2456 - val_loss: 5.6540 - val_accuracy: 0.3000\n","Epoch 35/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.1794 - accuracy: 0.2573 - val_loss: 5.6527 - val_accuracy: 0.3000\n","Epoch 36/100\n","3/3 [==============================] - 0s 44ms/step - loss: 5.4070 - accuracy: 0.2573 - val_loss: 5.6514 - val_accuracy: 0.3000\n","Epoch 37/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.1467 - accuracy: 0.2825 - val_loss: 5.6472 - val_accuracy: 0.3000\n","Epoch 38/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.8265 - accuracy: 0.2747 - val_loss: 5.6417 - val_accuracy: 0.3000\n","Epoch 39/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.0029 - accuracy: 0.2903 - val_loss: 5.6321 - val_accuracy: 0.3000\n","Epoch 40/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.4160 - accuracy: 0.2815 - val_loss: 5.6256 - val_accuracy: 0.3000\n","Epoch 41/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.7529 - accuracy: 0.2893 - val_loss: 5.6216 - val_accuracy: 0.3000\n","Epoch 42/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.7872 - accuracy: 0.2971 - val_loss: 5.6170 - val_accuracy: 0.3000\n","Epoch 43/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.1145 - accuracy: 0.2619 - val_loss: 5.6098 - val_accuracy: 0.3000\n","Epoch 44/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.6773 - accuracy: 0.2971 - val_loss: 5.6039 - val_accuracy: 0.3000\n","Epoch 45/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.6969 - accuracy: 0.2815 - val_loss: 5.5974 - val_accuracy: 0.3000\n","Epoch 46/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.6745 - accuracy: 0.3195 - val_loss: 5.5908 - val_accuracy: 0.3000\n","Epoch 47/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.7103 - accuracy: 0.3077 - val_loss: 5.5820 - val_accuracy: 0.3000\n","Epoch 48/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.1491 - accuracy: 0.3077 - val_loss: 5.5734 - val_accuracy: 0.3000\n","Epoch 49/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.5775 - accuracy: 0.3195 - val_loss: 5.5657 - val_accuracy: 0.3000\n","Epoch 50/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.4599 - accuracy: 0.3312 - val_loss: 5.5531 - val_accuracy: 0.3000\n","Epoch 51/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.9401 - accuracy: 0.3156 - val_loss: 5.5441 - val_accuracy: 0.3000\n","Epoch 52/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.1201 - accuracy: 0.2960 - val_loss: 5.5321 - val_accuracy: 0.3000\n","Epoch 53/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.6046 - accuracy: 0.3234 - val_loss: 5.5266 - val_accuracy: 0.3000\n","Epoch 54/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.7804 - accuracy: 0.2999 - val_loss: 5.5298 - val_accuracy: 0.3000\n","Epoch 55/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.2948 - accuracy: 0.3273 - val_loss: 5.5306 - val_accuracy: 0.3000\n","Epoch 56/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.7616 - accuracy: 0.3390 - val_loss: 5.5287 - val_accuracy: 0.3000\n","Epoch 57/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.4866 - accuracy: 0.3301 - val_loss: 5.5303 - val_accuracy: 0.3000\n","Epoch 58/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.4537 - accuracy: 0.3106 - val_loss: 5.5319 - val_accuracy: 0.3000\n","Epoch 59/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.6987 - accuracy: 0.2950 - val_loss: 5.5323 - val_accuracy: 0.3000\n","Epoch 60/100\n","3/3 [==============================] - 0s 44ms/step - loss: 4.3294 - accuracy: 0.3010 - val_loss: 7.1674 - val_accuracy: 0.2000\n","Epoch 61/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.4132 - accuracy: 0.2281 - val_loss: 3.3901 - val_accuracy: 0.4500\n","Epoch 62/100\n","3/3 [==============================] - 0s 36ms/step - loss: 7.0047 - accuracy: 0.2164 - val_loss: 3.3692 - val_accuracy: 0.5000\n","Epoch 63/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.6482 - accuracy: 0.2321 - val_loss: 3.3709 - val_accuracy: 0.5000\n","Epoch 64/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.3139 - accuracy: 0.2253 - val_loss: 3.4044 - val_accuracy: 0.4500\n","Epoch 65/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.9227 - accuracy: 0.2409 - val_loss: 3.4801 - val_accuracy: 0.4500\n","Epoch 66/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.9194 - accuracy: 0.1980 - val_loss: 3.9961 - val_accuracy: 0.4500\n","Epoch 67/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.7656 - accuracy: 0.2136 - val_loss: 3.9778 - val_accuracy: 0.5000\n","Epoch 68/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.5353 - accuracy: 0.2331 - val_loss: 3.9664 - val_accuracy: 0.5000\n","Epoch 69/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.0111 - accuracy: 0.2136 - val_loss: 3.9604 - val_accuracy: 0.5000\n","Epoch 70/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.0477 - accuracy: 0.2047 - val_loss: 3.9533 - val_accuracy: 0.5000\n","Epoch 71/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.8590 - accuracy: 0.2281 - val_loss: 3.9390 - val_accuracy: 0.5000\n","Epoch 72/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.4480 - accuracy: 0.2360 - val_loss: 3.9329 - val_accuracy: 0.5000\n","1/1 [==============================] - 0s 137ms/step - loss: 1.9972 - accuracy: 0.2632\n","Epoch 1/100\n","3/3 [==============================] - 1s 104ms/step - loss: 9.4928 - accuracy: 0.1844 - val_loss: 9.1347 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 35ms/step - loss: 8.1292 - accuracy: 0.2466 - val_loss: 8.3208 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 35ms/step - loss: 7.6091 - accuracy: 0.2388 - val_loss: 8.2522 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.5664 - accuracy: 0.2719 - val_loss: 8.1744 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.1614 - accuracy: 0.2669 - val_loss: 6.9414 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.1300 - accuracy: 0.2825 - val_loss: 6.2503 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.6657 - accuracy: 0.2981 - val_loss: 7.3764 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.7238 - accuracy: 0.2776 - val_loss: 7.2890 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 38ms/step - loss: 6.5668 - accuracy: 0.2843 - val_loss: 5.9774 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 37ms/step - loss: 6.2819 - accuracy: 0.2932 - val_loss: 5.8445 - val_accuracy: 0.3500\n","Epoch 11/100\n","3/3 [==============================] - 0s 36ms/step - loss: 6.2435 - accuracy: 0.2562 - val_loss: 4.8123 - val_accuracy: 0.3500\n","Epoch 12/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.9110 - accuracy: 0.2552 - val_loss: 4.8111 - val_accuracy: 0.3500\n","Epoch 13/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.2735 - accuracy: 0.2786 - val_loss: 4.8197 - val_accuracy: 0.3500\n","Epoch 14/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.9240 - accuracy: 0.2893 - val_loss: 4.8720 - val_accuracy: 0.4000\n","Epoch 15/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.9349 - accuracy: 0.2697 - val_loss: 4.9089 - val_accuracy: 0.4000\n","Epoch 16/100\n","3/3 [==============================] - 0s 42ms/step - loss: 5.5295 - accuracy: 0.3166 - val_loss: 5.4241 - val_accuracy: 0.4000\n","Epoch 17/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.5915 - accuracy: 0.2960 - val_loss: 5.3881 - val_accuracy: 0.3500\n","Epoch 18/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.4126 - accuracy: 0.3010 - val_loss: 4.9147 - val_accuracy: 0.3000\n","Epoch 19/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.2862 - accuracy: 0.3106 - val_loss: 4.8456 - val_accuracy: 0.3000\n","Epoch 20/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.1042 - accuracy: 0.3653 - val_loss: 4.1870 - val_accuracy: 0.3000\n","Epoch 21/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.0934 - accuracy: 0.2825 - val_loss: 4.7508 - val_accuracy: 0.3000\n","Epoch 22/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.5267 - accuracy: 0.3301 - val_loss: 4.7424 - val_accuracy: 0.3500\n","Epoch 23/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.6629 - accuracy: 0.3330 - val_loss: 4.6915 - val_accuracy: 0.4000\n","Epoch 24/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.0422 - accuracy: 0.3681 - val_loss: 4.7499 - val_accuracy: 0.4000\n","Epoch 25/100\n","3/3 [==============================] - 0s 39ms/step - loss: 3.9719 - accuracy: 0.3330 - val_loss: 4.7273 - val_accuracy: 0.4000\n","Epoch 26/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.2606 - accuracy: 0.3358 - val_loss: 4.7177 - val_accuracy: 0.4000\n","Epoch 27/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.5208 - accuracy: 0.3504 - val_loss: 4.7088 - val_accuracy: 0.4000\n","Epoch 28/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.6327 - accuracy: 0.3934 - val_loss: 4.6954 - val_accuracy: 0.4000\n","Epoch 29/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.2617 - accuracy: 0.3806 - val_loss: 4.6862 - val_accuracy: 0.4000\n","Epoch 30/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.1930 - accuracy: 0.3738 - val_loss: 4.6921 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 435ms/step - loss: 8.5042 - accuracy: 0.2105\n","Epoch 1/100\n","3/3 [==============================] - 1s 110ms/step - loss: 3.2577 - accuracy: 0.3543 - val_loss: 1.6625 - val_accuracy: 0.6000\n","Epoch 2/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.8535 - accuracy: 0.3777 - val_loss: 1.6622 - val_accuracy: 0.6000\n","Epoch 3/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.6016 - accuracy: 0.3465 - val_loss: 2.3245 - val_accuracy: 0.3000\n","Epoch 4/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.0592 - accuracy: 0.4719 - val_loss: 1.8212 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.8943 - accuracy: 0.4691 - val_loss: 1.8879 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.1105 - accuracy: 0.4183 - val_loss: 1.8783 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.5028 - accuracy: 0.4172 - val_loss: 1.8704 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.5195 - accuracy: 0.4524 - val_loss: 1.8635 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.3956 - accuracy: 0.4329 - val_loss: 1.8576 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.0600 - accuracy: 0.4776 - val_loss: 1.8507 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.9364 - accuracy: 0.4399 - val_loss: 1.8519 - val_accuracy: 0.1500\n","Epoch 12/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.7712 - accuracy: 0.4556 - val_loss: 1.8534 - val_accuracy: 0.1500\n","1/1 [==============================] - 0s 137ms/step - loss: 2.3061 - accuracy: 0.4737\n","Epoch 1/100\n","3/3 [==============================] - 1s 113ms/step - loss: 8.4962 - accuracy: 0.2861 - val_loss: 5.9047 - val_accuracy: 0.3500\n","Epoch 2/100\n","3/3 [==============================] - 0s 38ms/step - loss: 8.4186 - accuracy: 0.2372 - val_loss: 5.8333 - val_accuracy: 0.3500\n","Epoch 3/100\n","3/3 [==============================] - 0s 37ms/step - loss: 8.2748 - accuracy: 0.2556 - val_loss: 5.3229 - val_accuracy: 0.3500\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 8.3216 - accuracy: 0.2622 - val_loss: 5.3572 - val_accuracy: 0.3500\n","Epoch 5/100\n","3/3 [==============================] - 0s 35ms/step - loss: 8.0671 - accuracy: 0.2779 - val_loss: 5.3257 - val_accuracy: 0.3500\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.0620 - accuracy: 0.2634 - val_loss: 5.8342 - val_accuracy: 0.3500\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 7.4301 - accuracy: 0.2411 - val_loss: 5.9242 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 38ms/step - loss: 6.7944 - accuracy: 0.2422 - val_loss: 5.2236 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.8423 - accuracy: 0.2661 - val_loss: 5.2495 - val_accuracy: 0.3000\n","Epoch 10/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.9885 - accuracy: 0.2583 - val_loss: 5.2208 - val_accuracy: 0.3000\n","Epoch 11/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.4104 - accuracy: 0.2126 - val_loss: 4.9493 - val_accuracy: 0.3000\n","Epoch 12/100\n","3/3 [==============================] - 0s 45ms/step - loss: 5.7488 - accuracy: 0.2701 - val_loss: 4.5573 - val_accuracy: 0.3500\n","Epoch 13/100\n","3/3 [==============================] - 0s 40ms/step - loss: 5.6774 - accuracy: 0.2990 - val_loss: 4.5493 - val_accuracy: 0.3500\n","Epoch 14/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.4417 - accuracy: 0.2599 - val_loss: 4.7022 - val_accuracy: 0.2000\n","Epoch 15/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.2083 - accuracy: 0.2818 - val_loss: 4.6921 - val_accuracy: 0.2500\n","Epoch 16/100\n","3/3 [==============================] - 0s 41ms/step - loss: 4.8949 - accuracy: 0.3080 - val_loss: 4.6883 - val_accuracy: 0.2500\n","Epoch 17/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.0210 - accuracy: 0.2767 - val_loss: 4.6719 - val_accuracy: 0.2500\n","Epoch 18/100\n","3/3 [==============================] - 0s 39ms/step - loss: 5.0116 - accuracy: 0.2639 - val_loss: 4.6708 - val_accuracy: 0.2500\n","Epoch 19/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.7923 - accuracy: 0.2979 - val_loss: 4.6706 - val_accuracy: 0.2500\n","Epoch 20/100\n","3/3 [==============================] - 0s 41ms/step - loss: 4.5299 - accuracy: 0.3241 - val_loss: 4.6697 - val_accuracy: 0.2500\n","Epoch 21/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.5453 - accuracy: 0.3241 - val_loss: 4.6690 - val_accuracy: 0.3000\n","Epoch 22/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.6899 - accuracy: 0.2744 - val_loss: 4.6664 - val_accuracy: 0.3000\n","Epoch 23/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.3925 - accuracy: 0.2967 - val_loss: 4.6655 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 135ms/step - loss: 3.9942 - accuracy: 0.2222\n","Epoch 1/100\n","3/3 [==============================] - 1s 114ms/step - loss: 8.8356 - accuracy: 0.2239 - val_loss: 8.7357 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.3485 - accuracy: 0.2004 - val_loss: 8.5858 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 38ms/step - loss: 5.8373 - accuracy: 0.2333 - val_loss: 8.2904 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.8946 - accuracy: 0.2857 - val_loss: 7.0323 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.5743 - accuracy: 0.3123 - val_loss: 6.4491 - val_accuracy: 0.2000\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.3370 - accuracy: 0.3229 - val_loss: 5.8013 - val_accuracy: 0.2000\n","Epoch 7/100\n","3/3 [==============================] - 0s 44ms/step - loss: 4.3694 - accuracy: 0.3229 - val_loss: 5.7841 - val_accuracy: 0.2000\n","Epoch 8/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.5162 - accuracy: 0.2983 - val_loss: 5.6855 - val_accuracy: 0.2000\n","Epoch 9/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.7625 - accuracy: 0.3413 - val_loss: 5.0081 - val_accuracy: 0.2000\n","Epoch 10/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.7965 - accuracy: 0.3179 - val_loss: 4.5900 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.5872 - accuracy: 0.3569 - val_loss: 4.6423 - val_accuracy: 0.2000\n","Epoch 12/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.7575 - accuracy: 0.4093 - val_loss: 4.6396 - val_accuracy: 0.2000\n","Epoch 13/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.3435 - accuracy: 0.3691 - val_loss: 4.6381 - val_accuracy: 0.2000\n","Epoch 14/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.2284 - accuracy: 0.3418 - val_loss: 4.6431 - val_accuracy: 0.2000\n","Epoch 15/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.5438 - accuracy: 0.3965 - val_loss: 4.6627 - val_accuracy: 0.2000\n","Epoch 16/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.5472 - accuracy: 0.4410 - val_loss: 4.7385 - val_accuracy: 0.2000\n","Epoch 17/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.8713 - accuracy: 0.4126 - val_loss: 4.6349 - val_accuracy: 0.2000\n","Epoch 18/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.8389 - accuracy: 0.4344 - val_loss: 4.5286 - val_accuracy: 0.3000\n","Epoch 19/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.0515 - accuracy: 0.3797 - val_loss: 4.5163 - val_accuracy: 0.3000\n","Epoch 20/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.7663 - accuracy: 0.4109 - val_loss: 4.5157 - val_accuracy: 0.3000\n","Epoch 21/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.4131 - accuracy: 0.4148 - val_loss: 4.5188 - val_accuracy: 0.3500\n","Epoch 22/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.6983 - accuracy: 0.3914 - val_loss: 4.5011 - val_accuracy: 0.3500\n","Epoch 23/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.6222 - accuracy: 0.3965 - val_loss: 4.4762 - val_accuracy: 0.3500\n","Epoch 24/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.6066 - accuracy: 0.3535 - val_loss: 4.4531 - val_accuracy: 0.3500\n","Epoch 25/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.4051 - accuracy: 0.3891 - val_loss: 4.4477 - val_accuracy: 0.3500\n","Epoch 26/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.5287 - accuracy: 0.4348 - val_loss: 4.4484 - val_accuracy: 0.3500\n","Epoch 27/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.4424 - accuracy: 0.4427 - val_loss: 4.5438 - val_accuracy: 0.3500\n","Epoch 28/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.2177 - accuracy: 0.4544 - val_loss: 4.5364 - val_accuracy: 0.3500\n","Epoch 29/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.2708 - accuracy: 0.4728 - val_loss: 4.5332 - val_accuracy: 0.3500\n","Epoch 30/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.1538 - accuracy: 0.4700 - val_loss: 4.5378 - val_accuracy: 0.3500\n","Epoch 31/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.1760 - accuracy: 0.4962 - val_loss: 4.5407 - val_accuracy: 0.4000\n","Epoch 32/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.9378 - accuracy: 0.4505 - val_loss: 4.5399 - val_accuracy: 0.4000\n","Epoch 33/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.9389 - accuracy: 0.4817 - val_loss: 4.5384 - val_accuracy: 0.4000\n","Epoch 34/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.8811 - accuracy: 0.5256 - val_loss: 4.5214 - val_accuracy: 0.2500\n","Epoch 35/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.3096 - accuracy: 0.4493 - val_loss: 4.5083 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 152ms/step - loss: 4.8379 - accuracy: 0.5556\n","Epoch 1/100\n","3/3 [==============================] - 1s 115ms/step - loss: 5.5180 - accuracy: 0.4737 - val_loss: 5.1093 - val_accuracy: 0.5500\n","Epoch 2/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.3222 - accuracy: 0.4748 - val_loss: 5.1283 - val_accuracy: 0.5500\n","Epoch 3/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.2928 - accuracy: 0.5146 - val_loss: 5.1208 - val_accuracy: 0.5500\n","Epoch 4/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.7271 - accuracy: 0.5448 - val_loss: 5.1461 - val_accuracy: 0.5500\n","Epoch 5/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.0791 - accuracy: 0.5252 - val_loss: 5.2107 - val_accuracy: 0.5000\n","Epoch 6/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.0415 - accuracy: 0.5018 - val_loss: 5.1983 - val_accuracy: 0.4000\n","Epoch 7/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.3050 - accuracy: 0.4097 - val_loss: 5.1536 - val_accuracy: 0.4000\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.8535 - accuracy: 0.4282 - val_loss: 5.1558 - val_accuracy: 0.4000\n","Epoch 9/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.2204 - accuracy: 0.4399 - val_loss: 5.7058 - val_accuracy: 0.4000\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.8037 - accuracy: 0.4165 - val_loss: 5.6515 - val_accuracy: 0.4000\n","Epoch 11/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.0603 - accuracy: 0.4417 - val_loss: 5.9013 - val_accuracy: 0.4500\n","1/1 [==============================] - 0s 137ms/step - loss: 11.8378 - accuracy: 0.0000e+00\n","Epoch 1/100\n","3/3 [==============================] - 1s 112ms/step - loss: 7.4210 - accuracy: 0.2456 - val_loss: 6.1862 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.2308 - accuracy: 0.2601 - val_loss: 6.1394 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 35ms/step - loss: 7.2028 - accuracy: 0.2981 - val_loss: 6.1215 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 36ms/step - loss: 6.6065 - accuracy: 0.3234 - val_loss: 6.7137 - val_accuracy: 0.3500\n","Epoch 5/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.7082 - accuracy: 0.3145 - val_loss: 7.5423 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.2127 - accuracy: 0.3575 - val_loss: 6.1851 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.7247 - accuracy: 0.2854 - val_loss: 6.7080 - val_accuracy: 0.3000\n","Epoch 8/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.9728 - accuracy: 0.3447 - val_loss: 6.6837 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.0313 - accuracy: 0.3262 - val_loss: 6.0087 - val_accuracy: 0.2000\n","Epoch 10/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.7511 - accuracy: 0.3330 - val_loss: 5.9264 - val_accuracy: 0.2500\n","Epoch 11/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.0145 - accuracy: 0.3749 - val_loss: 5.8628 - val_accuracy: 0.2500\n","Epoch 12/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.6850 - accuracy: 0.3671 - val_loss: 6.3776 - val_accuracy: 0.2500\n","Epoch 13/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.2611 - accuracy: 0.3426 - val_loss: 6.2964 - val_accuracy: 0.2500\n","Epoch 14/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.2781 - accuracy: 0.3611 - val_loss: 6.2479 - val_accuracy: 0.3000\n","Epoch 15/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.0270 - accuracy: 0.3738 - val_loss: 5.7685 - val_accuracy: 0.3500\n","Epoch 16/100\n","3/3 [==============================] - 0s 42ms/step - loss: 4.5476 - accuracy: 0.4097 - val_loss: 5.6333 - val_accuracy: 0.3500\n","Epoch 17/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.5274 - accuracy: 0.4058 - val_loss: 5.5026 - val_accuracy: 0.3500\n","Epoch 18/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.4029 - accuracy: 0.4097 - val_loss: 4.9030 - val_accuracy: 0.3000\n","Epoch 19/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.1256 - accuracy: 0.3902 - val_loss: 4.8517 - val_accuracy: 0.3000\n","Epoch 20/100\n","3/3 [==============================] - 0s 39ms/step - loss: 4.2352 - accuracy: 0.3902 - val_loss: 5.6732 - val_accuracy: 0.4000\n","Epoch 21/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.6365 - accuracy: 0.3312 - val_loss: 5.5785 - val_accuracy: 0.4000\n","Epoch 22/100\n","3/3 [==============================] - 0s 40ms/step - loss: 3.5062 - accuracy: 0.3436 - val_loss: 5.7668 - val_accuracy: 0.3500\n","Epoch 23/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.9865 - accuracy: 0.3767 - val_loss: 5.0502 - val_accuracy: 0.3500\n","Epoch 24/100\n","3/3 [==============================] - 0s 40ms/step - loss: 4.2100 - accuracy: 0.3806 - val_loss: 5.6881 - val_accuracy: 0.3000\n","Epoch 25/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.7815 - accuracy: 0.4136 - val_loss: 6.2614 - val_accuracy: 0.3500\n","Epoch 26/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.9664 - accuracy: 0.4293 - val_loss: 4.8917 - val_accuracy: 0.3500\n","Epoch 27/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.9049 - accuracy: 0.3991 - val_loss: 4.3725 - val_accuracy: 0.4000\n","Epoch 28/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.4259 - accuracy: 0.3856 - val_loss: 6.5212 - val_accuracy: 0.3000\n","Epoch 29/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.4731 - accuracy: 0.3845 - val_loss: 5.1171 - val_accuracy: 0.3000\n","Epoch 30/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.5601 - accuracy: 0.3991 - val_loss: 4.5333 - val_accuracy: 0.3000\n","Epoch 31/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.1913 - accuracy: 0.4058 - val_loss: 4.9975 - val_accuracy: 0.3000\n","Epoch 32/100\n","3/3 [==============================] - 0s 40ms/step - loss: 2.4536 - accuracy: 0.4136 - val_loss: 4.6017 - val_accuracy: 0.2500\n","Epoch 33/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.8851 - accuracy: 0.4147 - val_loss: 4.5434 - val_accuracy: 0.3000\n","Epoch 34/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.9343 - accuracy: 0.4243 - val_loss: 4.5248 - val_accuracy: 0.3000\n","Epoch 35/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.0977 - accuracy: 0.4232 - val_loss: 4.4245 - val_accuracy: 0.3000\n","Epoch 36/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.9013 - accuracy: 0.4154 - val_loss: 3.8601 - val_accuracy: 0.3000\n","Epoch 37/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.6651 - accuracy: 0.4613 - val_loss: 3.8262 - val_accuracy: 0.3500\n","Epoch 38/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.9364 - accuracy: 0.4339 - val_loss: 3.8049 - val_accuracy: 0.3500\n","Epoch 39/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.7176 - accuracy: 0.4407 - val_loss: 3.7953 - val_accuracy: 0.3000\n","Epoch 40/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.5200 - accuracy: 0.4914 - val_loss: 3.7728 - val_accuracy: 0.3500\n","Epoch 41/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.8032 - accuracy: 0.4719 - val_loss: 9.6992 - val_accuracy: 0.4000\n","Epoch 42/100\n","3/3 [==============================] - 0s 39ms/step - loss: 9.3139 - accuracy: 0.2726 - val_loss: 9.7030 - val_accuracy: 0.4000\n","Epoch 43/100\n","3/3 [==============================] - 0s 38ms/step - loss: 8.5989 - accuracy: 0.3195 - val_loss: 9.7013 - val_accuracy: 0.4000\n","Epoch 44/100\n","3/3 [==============================] - 0s 38ms/step - loss: 8.1331 - accuracy: 0.3809 - val_loss: 9.6991 - val_accuracy: 0.4000\n","Epoch 45/100\n","3/3 [==============================] - 0s 36ms/step - loss: 8.2883 - accuracy: 0.3223 - val_loss: 9.6987 - val_accuracy: 0.4000\n","Epoch 46/100\n","3/3 [==============================] - 0s 36ms/step - loss: 8.9023 - accuracy: 0.2872 - val_loss: 9.6950 - val_accuracy: 0.4000\n","Epoch 47/100\n","3/3 [==============================] - 0s 34ms/step - loss: 8.0790 - accuracy: 0.3614 - val_loss: 9.6923 - val_accuracy: 0.4000\n","Epoch 48/100\n","3/3 [==============================] - 0s 37ms/step - loss: 8.3092 - accuracy: 0.3536 - val_loss: 9.6889 - val_accuracy: 0.4000\n","Epoch 49/100\n","3/3 [==============================] - 0s 37ms/step - loss: 8.6634 - accuracy: 0.3301 - val_loss: 9.6811 - val_accuracy: 0.4000\n","Epoch 50/100\n","3/3 [==============================] - 0s 39ms/step - loss: 8.5145 - accuracy: 0.2950 - val_loss: 9.6741 - val_accuracy: 0.4000\n","1/1 [==============================] - 0s 141ms/step - loss: 12.9905 - accuracy: 0.1579\n","Epoch 1/100\n","3/3 [==============================] - 1s 119ms/step - loss: 8.6855 - accuracy: 0.1428 - val_loss: 6.3796 - val_accuracy: 0.3500\n","Epoch 2/100\n","3/3 [==============================] - 0s 37ms/step - loss: 7.9213 - accuracy: 0.1564 - val_loss: 5.6171 - val_accuracy: 0.3500\n","Epoch 3/100\n","3/3 [==============================] - 0s 41ms/step - loss: 6.9301 - accuracy: 0.1524 - val_loss: 6.1138 - val_accuracy: 0.3000\n","Epoch 4/100\n","3/3 [==============================] - 0s 43ms/step - loss: 6.5104 - accuracy: 0.1990 - val_loss: 6.8323 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.1161 - accuracy: 0.1969 - val_loss: 6.2331 - val_accuracy: 0.2000\n","Epoch 6/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.5450 - accuracy: 0.3138 - val_loss: 6.2394 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.6923 - accuracy: 0.2903 - val_loss: 6.8392 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.3829 - accuracy: 0.2658 - val_loss: 6.8385 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 41ms/step - loss: 4.9063 - accuracy: 0.2932 - val_loss: 6.8467 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.8175 - accuracy: 0.2932 - val_loss: 6.8353 - val_accuracy: 0.2500\n","Epoch 11/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.0715 - accuracy: 0.3077 - val_loss: 6.8438 - val_accuracy: 0.2500\n","Epoch 12/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.0210 - accuracy: 0.3088 - val_loss: 6.8482 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 163ms/step - loss: 6.5470 - accuracy: 0.2105\n","Epoch 1/100\n","3/3 [==============================] - 1s 126ms/step - loss: 4.3766 - accuracy: 0.4399 - val_loss: 3.7596 - val_accuracy: 0.4500\n","Epoch 2/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.9322 - accuracy: 0.4399 - val_loss: 5.8927 - val_accuracy: 0.4500\n","Epoch 3/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.8119 - accuracy: 0.4571 - val_loss: 3.8239 - val_accuracy: 0.4500\n","Epoch 4/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.0177 - accuracy: 0.3590 - val_loss: 3.8648 - val_accuracy: 0.4500\n","Epoch 5/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.4162 - accuracy: 0.4610 - val_loss: 5.2916 - val_accuracy: 0.5000\n","Epoch 6/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.3596 - accuracy: 0.4493 - val_loss: 5.9109 - val_accuracy: 0.4500\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.0791 - accuracy: 0.4728 - val_loss: 5.8906 - val_accuracy: 0.4500\n","Epoch 8/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.2348 - accuracy: 0.4716 - val_loss: 6.7116 - val_accuracy: 0.4500\n","Epoch 9/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.2889 - accuracy: 0.4889 - val_loss: 6.0696 - val_accuracy: 0.4500\n","Epoch 10/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.2650 - accuracy: 0.4983 - val_loss: 6.1055 - val_accuracy: 0.4500\n","Epoch 11/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.1555 - accuracy: 0.5100 - val_loss: 6.6567 - val_accuracy: 0.4500\n","1/1 [==============================] - 0s 145ms/step - loss: 1.4856 - accuracy: 0.6667\n","Epoch 1/100\n","3/3 [==============================] - 1s 116ms/step - loss: 7.8702 - accuracy: 0.2395 - val_loss: 8.0109 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.7908 - accuracy: 0.2227 - val_loss: 8.6104 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.0955 - accuracy: 0.1754 - val_loss: 7.8018 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.5686 - accuracy: 0.2783 - val_loss: 7.6787 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 39ms/step - loss: 4.0251 - accuracy: 0.3475 - val_loss: 7.0406 - val_accuracy: 0.3000\n","Epoch 6/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.0912 - accuracy: 0.3190 - val_loss: 5.9565 - val_accuracy: 0.4000\n","Epoch 7/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.4661 - accuracy: 0.3742 - val_loss: 5.9764 - val_accuracy: 0.4000\n","Epoch 8/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.4561 - accuracy: 0.3781 - val_loss: 5.8847 - val_accuracy: 0.4000\n","Epoch 9/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.3809 - accuracy: 0.3691 - val_loss: 5.3613 - val_accuracy: 0.4000\n","Epoch 10/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.0140 - accuracy: 0.3730 - val_loss: 5.3045 - val_accuracy: 0.4000\n","Epoch 11/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.2757 - accuracy: 0.3496 - val_loss: 5.2382 - val_accuracy: 0.4000\n","Epoch 12/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.2613 - accuracy: 0.3730 - val_loss: 5.2198 - val_accuracy: 0.4000\n","Epoch 13/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.0056 - accuracy: 0.3847 - val_loss: 5.1777 - val_accuracy: 0.4000\n","Epoch 14/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.1208 - accuracy: 0.4199 - val_loss: 4.7292 - val_accuracy: 0.4000\n","Epoch 15/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.2137 - accuracy: 0.3769 - val_loss: 4.7169 - val_accuracy: 0.4000\n","Epoch 16/100\n","3/3 [==============================] - 0s 41ms/step - loss: 2.0141 - accuracy: 0.3926 - val_loss: 4.6938 - val_accuracy: 0.4000\n","Epoch 17/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.7558 - accuracy: 0.4109 - val_loss: 4.6653 - val_accuracy: 0.4000\n","Epoch 18/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.8094 - accuracy: 0.3769 - val_loss: 4.6427 - val_accuracy: 0.4000\n","Epoch 19/100\n","3/3 [==============================] - 0s 40ms/step - loss: 1.6834 - accuracy: 0.4031 - val_loss: 4.6327 - val_accuracy: 0.4000\n","Epoch 20/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.6170 - accuracy: 0.3730 - val_loss: 4.6360 - val_accuracy: 0.4000\n","Epoch 21/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.5332 - accuracy: 0.3390 - val_loss: 4.6257 - val_accuracy: 0.4000\n","Epoch 22/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.5371 - accuracy: 0.3820 - val_loss: 4.5967 - val_accuracy: 0.4000\n","Epoch 23/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.8052 - accuracy: 0.3742 - val_loss: 4.5847 - val_accuracy: 0.4000\n","Epoch 24/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.6386 - accuracy: 0.3742 - val_loss: 4.0359 - val_accuracy: 0.4000\n","Epoch 25/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.4585 - accuracy: 0.3703 - val_loss: 4.0262 - val_accuracy: 0.4000\n","Epoch 26/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.5449 - accuracy: 0.3624 - val_loss: 4.0332 - val_accuracy: 0.4000\n","Epoch 27/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.5494 - accuracy: 0.4015 - val_loss: 4.0317 - val_accuracy: 0.4000\n","Epoch 28/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.4236 - accuracy: 0.3624 - val_loss: 4.0306 - val_accuracy: 0.4000\n","Epoch 29/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.4823 - accuracy: 0.3859 - val_loss: 4.5160 - val_accuracy: 0.3000\n","Epoch 30/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.4202 - accuracy: 0.4399 - val_loss: 4.0303 - val_accuracy: 0.2500\n","Epoch 31/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.2722 - accuracy: 0.3468 - val_loss: 4.0301 - val_accuracy: 0.2500\n","Epoch 32/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.2851 - accuracy: 0.3859 - val_loss: 4.0297 - val_accuracy: 0.2500\n","Epoch 33/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.2470 - accuracy: 0.4132 - val_loss: 4.0293 - val_accuracy: 0.2500\n","Epoch 34/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.2763 - accuracy: 0.3664 - val_loss: 4.0288 - val_accuracy: 0.2500\n","Epoch 35/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.2848 - accuracy: 0.3624 - val_loss: 4.0282 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 178ms/step - loss: 1.9640 - accuracy: 0.3889\n","Epoch 1/100\n","3/3 [==============================] - 1s 113ms/step - loss: 6.5515 - accuracy: 0.3145 - val_loss: 5.8959 - val_accuracy: 0.4000\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.9263 - accuracy: 0.5117 - val_loss: 2.3491 - val_accuracy: 0.3000\n","Epoch 3/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.7981 - accuracy: 0.5089 - val_loss: 3.1206 - val_accuracy: 0.4000\n","Epoch 4/100\n","3/3 [==============================] - 0s 42ms/step - loss: 1.8956 - accuracy: 0.5107 - val_loss: 2.6515 - val_accuracy: 0.4500\n","Epoch 5/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.1531 - accuracy: 0.5011 - val_loss: 2.6515 - val_accuracy: 0.4500\n","Epoch 6/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.0246 - accuracy: 0.5156 - val_loss: 2.6515 - val_accuracy: 0.4500\n","Epoch 7/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.0230 - accuracy: 0.5497 - val_loss: 2.6515 - val_accuracy: 0.4500\n","Epoch 8/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.0495 - accuracy: 0.5341 - val_loss: 2.6515 - val_accuracy: 0.4500\n","Epoch 9/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.1739 - accuracy: 0.4776 - val_loss: 2.6515 - val_accuracy: 0.4000\n","Epoch 10/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.1578 - accuracy: 0.4542 - val_loss: 2.6515 - val_accuracy: 0.4000\n","Epoch 11/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.0277 - accuracy: 0.4737 - val_loss: 2.6515 - val_accuracy: 0.4500\n","Epoch 12/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.0574 - accuracy: 0.4755 - val_loss: 2.6515 - val_accuracy: 0.4000\n","1/1 [==============================] - 0s 144ms/step - loss: 10.8459 - accuracy: 0.1053\n","Epoch 1/100\n","3/3 [==============================] - 1s 113ms/step - loss: 7.5214 - accuracy: 0.3067 - val_loss: 8.5397 - val_accuracy: 0.1500\n","Epoch 2/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.6999 - accuracy: 0.3689 - val_loss: 11.2995 - val_accuracy: 0.1000\n","Epoch 3/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.8034 - accuracy: 0.3611 - val_loss: 11.3411 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 7.1762 - accuracy: 0.4175 - val_loss: 11.3360 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 37ms/step - loss: 6.8253 - accuracy: 0.4350 - val_loss: 11.0336 - val_accuracy: 0.1500\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.7802 - accuracy: 0.4417 - val_loss: 8.3915 - val_accuracy: 0.1000\n","Epoch 7/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.5967 - accuracy: 0.4467 - val_loss: 8.3741 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.6148 - accuracy: 0.4300 - val_loss: 7.9730 - val_accuracy: 0.1000\n","Epoch 9/100\n","3/3 [==============================] - 0s 38ms/step - loss: 6.0806 - accuracy: 0.3294 - val_loss: 3.9127 - val_accuracy: 0.5000\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.3153 - accuracy: 0.3099 - val_loss: 4.5895 - val_accuracy: 0.4500\n","Epoch 11/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.7350 - accuracy: 0.3077 - val_loss: 4.1165 - val_accuracy: 0.3000\n","Epoch 12/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.0745 - accuracy: 0.3785 - val_loss: 4.1048 - val_accuracy: 0.2500\n","Epoch 13/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.8776 - accuracy: 0.4158 - val_loss: 4.7477 - val_accuracy: 0.2500\n","Epoch 14/100\n","3/3 [==============================] - 0s 43ms/step - loss: 2.9874 - accuracy: 0.3717 - val_loss: 4.7561 - val_accuracy: 0.2500\n","Epoch 15/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.1432 - accuracy: 0.3795 - val_loss: 4.7459 - val_accuracy: 0.2500\n","Epoch 16/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.0443 - accuracy: 0.3834 - val_loss: 4.7503 - val_accuracy: 0.2500\n","Epoch 17/100\n","3/3 [==============================] - 0s 139ms/step - loss: 3.4349 - accuracy: 0.3717 - val_loss: 4.7610 - val_accuracy: 0.2500\n","Epoch 18/100\n","3/3 [==============================] - 0s 63ms/step - loss: 3.4235 - accuracy: 0.3717 - val_loss: 4.7653 - val_accuracy: 0.2500\n","Epoch 19/100\n","3/3 [==============================] - 0s 56ms/step - loss: 3.0073 - accuracy: 0.3728 - val_loss: 4.7719 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 129ms/step - loss: 0.8331 - accuracy: 0.5263\n","Epoch 1/100\n","3/3 [==============================] - 1s 116ms/step - loss: 10.1511 - accuracy: 0.1639 - val_loss: 4.9268 - val_accuracy: 0.4500\n","Epoch 2/100\n","3/3 [==============================] - 0s 40ms/step - loss: 2.5067 - accuracy: 0.4456 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 3/100\n","3/3 [==============================] - 0s 39ms/step - loss: 1.8488 - accuracy: 0.3962 - val_loss: 1.3863 - val_accuracy: 0.3500\n","Epoch 4/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.8624 - accuracy: 0.3767 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.7323 - accuracy: 0.3632 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.4828 - accuracy: 0.3777 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 7/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.4774 - accuracy: 0.3348 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 8/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.4828 - accuracy: 0.3699 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.5099 - accuracy: 0.3817 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.6250 - accuracy: 0.3817 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 11/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.6087 - accuracy: 0.3543 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 12/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.6033 - accuracy: 0.3817 - val_loss: 1.3863 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 189ms/step - loss: 1.3863 - accuracy: 0.3684\n","Epoch 1/100\n","3/3 [==============================] - 1s 111ms/step - loss: 8.3072 - accuracy: 0.2923 - val_loss: 2.7247 - val_accuracy: 0.6500\n","Epoch 2/100\n","3/3 [==============================] - 0s 41ms/step - loss: 3.4161 - accuracy: 0.4227 - val_loss: 2.7259 - val_accuracy: 0.6500\n","Epoch 3/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.7751 - accuracy: 0.4070 - val_loss: 2.7261 - val_accuracy: 0.6500\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.9672 - accuracy: 0.3875 - val_loss: 2.7262 - val_accuracy: 0.6500\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.3401 - accuracy: 0.4148 - val_loss: 2.7267 - val_accuracy: 0.6500\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.0869 - accuracy: 0.4031 - val_loss: 2.7261 - val_accuracy: 0.6500\n","Epoch 7/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.2682 - accuracy: 0.4227 - val_loss: 2.7263 - val_accuracy: 0.6500\n","Epoch 8/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.6499 - accuracy: 0.4227 - val_loss: 2.7273 - val_accuracy: 0.6500\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.5808 - accuracy: 0.4109 - val_loss: 2.7275 - val_accuracy: 0.6500\n","Epoch 10/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.5120 - accuracy: 0.4148 - val_loss: 2.7284 - val_accuracy: 0.6500\n","Epoch 11/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.2676 - accuracy: 0.4109 - val_loss: 2.7367 - val_accuracy: 0.6500\n","1/1 [==============================] - 0s 146ms/step - loss: 1.0272 - accuracy: 0.8333\n","Epoch 1/100\n","3/3 [==============================] - 1s 115ms/step - loss: 5.8212 - accuracy: 0.2940 - val_loss: 1.4902 - val_accuracy: 0.5500\n","Epoch 2/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.1587 - accuracy: 0.5006 - val_loss: 3.6212 - val_accuracy: 0.5500\n","Epoch 3/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.8236 - accuracy: 0.5992 - val_loss: 2.1787 - val_accuracy: 0.5000\n","Epoch 4/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.7030 - accuracy: 0.6035 - val_loss: 2.2624 - val_accuracy: 0.5000\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.9864 - accuracy: 0.6470 - val_loss: 3.5533 - val_accuracy: 0.5000\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.9061 - accuracy: 0.6509 - val_loss: 2.7796 - val_accuracy: 0.5500\n","Epoch 7/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.4558 - accuracy: 0.6838 - val_loss: 2.5620 - val_accuracy: 0.5000\n","Epoch 8/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.2748 - accuracy: 0.6481 - val_loss: 3.4075 - val_accuracy: 0.5500\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.2708 - accuracy: 0.6904 - val_loss: 2.9423 - val_accuracy: 0.5500\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3609 - accuracy: 0.6670 - val_loss: 2.8944 - val_accuracy: 0.5500\n","Epoch 11/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3396 - accuracy: 0.6943 - val_loss: 2.9204 - val_accuracy: 0.5500\n","1/1 [==============================] - 0s 186ms/step - loss: 8.8677 - accuracy: 0.1111\n","Epoch 1/100\n","3/3 [==============================] - 1s 110ms/step - loss: 9.2175 - accuracy: 0.1844 - val_loss: 6.2305 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.1657 - accuracy: 0.3038 - val_loss: 7.7776 - val_accuracy: 0.3000\n","Epoch 3/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.1984 - accuracy: 0.3611 - val_loss: 5.4552 - val_accuracy: 0.4000\n","Epoch 4/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.2456 - accuracy: 0.3710 - val_loss: 5.3343 - val_accuracy: 0.3500\n","Epoch 5/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.7918 - accuracy: 0.3220 - val_loss: 3.9108 - val_accuracy: 0.3500\n","Epoch 6/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.9395 - accuracy: 0.3717 - val_loss: 3.9128 - val_accuracy: 0.3500\n","Epoch 7/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.0530 - accuracy: 0.3572 - val_loss: 3.9133 - val_accuracy: 0.3500\n","Epoch 8/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.7381 - accuracy: 0.3611 - val_loss: 3.9831 - val_accuracy: 0.3500\n","Epoch 9/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.5231 - accuracy: 0.3728 - val_loss: 3.9698 - val_accuracy: 0.3500\n","Epoch 10/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.2271 - accuracy: 0.3493 - val_loss: 3.9684 - val_accuracy: 0.3500\n","Epoch 11/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.1598 - accuracy: 0.3611 - val_loss: 3.9696 - val_accuracy: 0.3500\n","Epoch 12/100\n","3/3 [==============================] - 0s 40ms/step - loss: 2.0883 - accuracy: 0.3660 - val_loss: 3.2495 - val_accuracy: 0.5500\n","Epoch 13/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.8826 - accuracy: 0.3330 - val_loss: 3.2495 - val_accuracy: 0.5500\n","Epoch 14/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.9580 - accuracy: 0.3941 - val_loss: 2.4782 - val_accuracy: 0.6000\n","Epoch 15/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.5522 - accuracy: 0.4272 - val_loss: 2.5129 - val_accuracy: 0.6000\n","Epoch 16/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3878 - accuracy: 0.4648 - val_loss: 2.5129 - val_accuracy: 0.6000\n","Epoch 17/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.1809 - accuracy: 0.4883 - val_loss: 2.5129 - val_accuracy: 0.6000\n","Epoch 18/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3684 - accuracy: 0.5352 - val_loss: 2.5129 - val_accuracy: 0.6000\n","Epoch 19/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3590 - accuracy: 0.5195 - val_loss: 2.5129 - val_accuracy: 0.6000\n","Epoch 20/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3506 - accuracy: 0.5195 - val_loss: 2.5129 - val_accuracy: 0.6000\n","Epoch 21/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.2275 - accuracy: 0.5117 - val_loss: 2.5129 - val_accuracy: 0.6000\n","Epoch 22/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.1753 - accuracy: 0.5156 - val_loss: 2.5129 - val_accuracy: 0.6000\n","Epoch 23/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3676 - accuracy: 0.5039 - val_loss: 2.5129 - val_accuracy: 0.6000\n","Epoch 24/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.2938 - accuracy: 0.5078 - val_loss: 2.5129 - val_accuracy: 0.6000\n","1/1 [==============================] - 0s 191ms/step - loss: 10.2051 - accuracy: 0.1579\n","Epoch 1/100\n","3/3 [==============================] - 1s 116ms/step - loss: 8.8320 - accuracy: 0.2029 - val_loss: 5.2118 - val_accuracy: 0.3500\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.4395 - accuracy: 0.3244 - val_loss: 4.4690 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.4454 - accuracy: 0.3127 - val_loss: 3.3912 - val_accuracy: 0.3000\n","Epoch 4/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.0281 - accuracy: 0.2932 - val_loss: 4.7186 - val_accuracy: 0.3000\n","Epoch 5/100\n","3/3 [==============================] - 0s 46ms/step - loss: 2.8491 - accuracy: 0.3710 - val_loss: 4.0911 - val_accuracy: 0.3000\n","Epoch 6/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.3444 - accuracy: 0.3632 - val_loss: 4.0951 - val_accuracy: 0.3000\n","Epoch 7/100\n","3/3 [==============================] - 0s 40ms/step - loss: 2.5134 - accuracy: 0.3436 - val_loss: 4.0982 - val_accuracy: 0.3000\n","Epoch 8/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.2808 - accuracy: 0.3554 - val_loss: 4.0368 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.4016 - accuracy: 0.3280 - val_loss: 4.0371 - val_accuracy: 0.3000\n","Epoch 10/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.0510 - accuracy: 0.3515 - val_loss: 4.0416 - val_accuracy: 0.3000\n","Epoch 11/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.2035 - accuracy: 0.3358 - val_loss: 4.0417 - val_accuracy: 0.3000\n","Epoch 12/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.2751 - accuracy: 0.3319 - val_loss: 4.0392 - val_accuracy: 0.3000\n","Epoch 13/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.3843 - accuracy: 0.3593 - val_loss: 4.0394 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 171ms/step - loss: 6.4927 - accuracy: 0.2105\n","Epoch 1/100\n","3/3 [==============================] - 1s 110ms/step - loss: 9.2648 - accuracy: 0.2370 - val_loss: 12.5193 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 39ms/step - loss: 9.4040 - accuracy: 0.2214 - val_loss: 12.6885 - val_accuracy: 0.1000\n","Epoch 3/100\n","3/3 [==============================] - 0s 37ms/step - loss: 8.9130 - accuracy: 0.2299 - val_loss: 12.6420 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 35ms/step - loss: 8.0398 - accuracy: 0.3234 - val_loss: 12.5635 - val_accuracy: 0.2000\n","Epoch 5/100\n","3/3 [==============================] - 0s 36ms/step - loss: 7.8998 - accuracy: 0.2942 - val_loss: 13.2170 - val_accuracy: 0.2000\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 10.6155 - accuracy: 0.1368 - val_loss: 13.2187 - val_accuracy: 0.2000\n","Epoch 7/100\n","3/3 [==============================] - 0s 32ms/step - loss: 8.8478 - accuracy: 0.2619 - val_loss: 11.2539 - val_accuracy: 0.1500\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.4139 - accuracy: 0.3515 - val_loss: 11.2263 - val_accuracy: 0.1500\n","Epoch 9/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.9493 - accuracy: 0.3593 - val_loss: 11.2214 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 31ms/step - loss: 7.2069 - accuracy: 0.3554 - val_loss: 11.2671 - val_accuracy: 0.1500\n","Epoch 11/100\n","3/3 [==============================] - 0s 36ms/step - loss: 7.6066 - accuracy: 0.3593 - val_loss: 11.2266 - val_accuracy: 0.1500\n","Epoch 12/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.3284 - accuracy: 0.3436 - val_loss: 11.2249 - val_accuracy: 0.1500\n","Epoch 13/100\n","3/3 [==============================] - 0s 38ms/step - loss: 7.3417 - accuracy: 0.3163 - val_loss: 11.2352 - val_accuracy: 0.1500\n","Epoch 14/100\n","3/3 [==============================] - 0s 38ms/step - loss: 7.2772 - accuracy: 0.3554 - val_loss: 11.2209 - val_accuracy: 0.1500\n","Epoch 15/100\n","3/3 [==============================] - 0s 38ms/step - loss: 7.1902 - accuracy: 0.3671 - val_loss: 11.2206 - val_accuracy: 0.1500\n","Epoch 16/100\n","3/3 [==============================] - 0s 30ms/step - loss: 7.3826 - accuracy: 0.3476 - val_loss: 10.5417 - val_accuracy: 0.1500\n","Epoch 17/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.5650 - accuracy: 0.3436 - val_loss: 8.8993 - val_accuracy: 0.1500\n","Epoch 18/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.8318 - accuracy: 0.3436 - val_loss: 8.9074 - val_accuracy: 0.1500\n","Epoch 19/100\n","3/3 [==============================] - 0s 30ms/step - loss: 5.3644 - accuracy: 0.3436 - val_loss: 8.9067 - val_accuracy: 0.1500\n","Epoch 20/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.6192 - accuracy: 0.3163 - val_loss: 8.9061 - val_accuracy: 0.1500\n","Epoch 21/100\n","3/3 [==============================] - 0s 39ms/step - loss: 5.2133 - accuracy: 0.3632 - val_loss: 8.9064 - val_accuracy: 0.1500\n","Epoch 22/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.2473 - accuracy: 0.3515 - val_loss: 8.9064 - val_accuracy: 0.1500\n","Epoch 23/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.0052 - accuracy: 0.3671 - val_loss: 8.9064 - val_accuracy: 0.1500\n","Epoch 24/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.1085 - accuracy: 0.3710 - val_loss: 8.9072 - val_accuracy: 0.1500\n","Epoch 25/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.1052 - accuracy: 0.3788 - val_loss: 8.9069 - val_accuracy: 0.1500\n","Epoch 26/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.3648 - accuracy: 0.3319 - val_loss: 8.9063 - val_accuracy: 0.1500\n","Epoch 27/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.7283 - accuracy: 0.3358 - val_loss: 8.9061 - val_accuracy: 0.1500\n","1/1 [==============================] - 0s 187ms/step - loss: 7.6369 - accuracy: 0.2105\n","Epoch 1/100\n","3/3 [==============================] - 1s 107ms/step - loss: 8.4703 - accuracy: 0.2121 - val_loss: 5.4930 - val_accuracy: 0.4000\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.8914 - accuracy: 0.3080 - val_loss: 4.5097 - val_accuracy: 0.4500\n","Epoch 3/100\n","3/3 [==============================] - 0s 42ms/step - loss: 6.3654 - accuracy: 0.3224 - val_loss: 7.6046 - val_accuracy: 0.1000\n","Epoch 4/100\n","3/3 [==============================] - 0s 34ms/step - loss: 8.0635 - accuracy: 0.2845 - val_loss: 6.9370 - val_accuracy: 0.1000\n","Epoch 5/100\n","3/3 [==============================] - 0s 38ms/step - loss: 7.5559 - accuracy: 0.2756 - val_loss: 6.9182 - val_accuracy: 0.1000\n","Epoch 6/100\n","3/3 [==============================] - 0s 37ms/step - loss: 8.0922 - accuracy: 0.2767 - val_loss: 6.8671 - val_accuracy: 0.1000\n","Epoch 7/100\n","3/3 [==============================] - 0s 39ms/step - loss: 7.7877 - accuracy: 0.2963 - val_loss: 6.7933 - val_accuracy: 0.1000\n","Epoch 8/100\n","3/3 [==============================] - 0s 36ms/step - loss: 7.2252 - accuracy: 0.2806 - val_loss: 6.2563 - val_accuracy: 0.1500\n","Epoch 9/100\n","3/3 [==============================] - 0s 36ms/step - loss: 6.4711 - accuracy: 0.3146 - val_loss: 6.2265 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.1447 - accuracy: 0.2873 - val_loss: 6.2969 - val_accuracy: 0.1500\n","Epoch 11/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.7399 - accuracy: 0.3179 - val_loss: 5.4907 - val_accuracy: 0.2500\n","Epoch 12/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.7943 - accuracy: 0.4399 - val_loss: 5.4824 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 151ms/step - loss: 8.4378 - accuracy: 0.1667\n","Epoch 1/100\n","3/3 [==============================] - 1s 107ms/step - loss: 5.8071 - accuracy: 0.3146 - val_loss: 5.4818 - val_accuracy: 0.4500\n","Epoch 2/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.5387 - accuracy: 0.4070 - val_loss: 4.0861 - val_accuracy: 0.5000\n","Epoch 3/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.2985 - accuracy: 0.3546 - val_loss: 4.4527 - val_accuracy: 0.5000\n","Epoch 4/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.9009 - accuracy: 0.4070 - val_loss: 3.9062 - val_accuracy: 0.5000\n","Epoch 5/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.1494 - accuracy: 0.4031 - val_loss: 3.9624 - val_accuracy: 0.4500\n","Epoch 6/100\n","3/3 [==============================] - 0s 43ms/step - loss: 2.0451 - accuracy: 0.4204 - val_loss: 4.5872 - val_accuracy: 0.4500\n","Epoch 7/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.9237 - accuracy: 0.4266 - val_loss: 3.9700 - val_accuracy: 0.4500\n","Epoch 8/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.1361 - accuracy: 0.4332 - val_loss: 3.8035 - val_accuracy: 0.5000\n","Epoch 9/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.1998 - accuracy: 0.3264 - val_loss: 4.6724 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 38ms/step - loss: 5.4505 - accuracy: 0.2411 - val_loss: 4.4601 - val_accuracy: 0.5000\n","Epoch 11/100\n","3/3 [==============================] - 0s 37ms/step - loss: 6.9038 - accuracy: 0.2266 - val_loss: 4.4543 - val_accuracy: 0.5000\n","Epoch 12/100\n","3/3 [==============================] - 0s 38ms/step - loss: 5.5829 - accuracy: 0.2383 - val_loss: 3.7623 - val_accuracy: 0.5000\n","Epoch 13/100\n","3/3 [==============================] - 0s 36ms/step - loss: 6.0605 - accuracy: 0.2266 - val_loss: 4.4546 - val_accuracy: 0.5000\n","Epoch 14/100\n","3/3 [==============================] - 0s 38ms/step - loss: 5.3934 - accuracy: 0.2071 - val_loss: 4.4546 - val_accuracy: 0.5000\n","Epoch 15/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.6137 - accuracy: 0.2227 - val_loss: 4.4536 - val_accuracy: 0.5000\n","Epoch 16/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.9627 - accuracy: 0.2383 - val_loss: 4.4539 - val_accuracy: 0.5000\n","Epoch 17/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.9646 - accuracy: 0.2383 - val_loss: 4.4542 - val_accuracy: 0.5000\n","Epoch 18/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.6713 - accuracy: 0.2344 - val_loss: 4.4548 - val_accuracy: 0.5000\n","Epoch 19/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.6348 - accuracy: 0.2657 - val_loss: 4.4552 - val_accuracy: 0.5000\n","Epoch 20/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.7578 - accuracy: 0.2618 - val_loss: 4.4555 - val_accuracy: 0.5000\n","Epoch 21/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.2349 - accuracy: 0.2149 - val_loss: 4.4559 - val_accuracy: 0.5000\n","Epoch 22/100\n","3/3 [==============================] - 0s 39ms/step - loss: 5.3935 - accuracy: 0.2266 - val_loss: 4.4563 - val_accuracy: 0.5000\n","1/1 [==============================] - 0s 183ms/step - loss: 11.9823 - accuracy: 0.1111\n","Epoch 1/100\n","3/3 [==============================] - 1s 116ms/step - loss: 6.4726 - accuracy: 0.3717 - val_loss: 3.8980 - val_accuracy: 0.4000\n","Epoch 2/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.8023 - accuracy: 0.3554 - val_loss: 4.0243 - val_accuracy: 0.4500\n","Epoch 3/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.8312 - accuracy: 0.3671 - val_loss: 3.9799 - val_accuracy: 0.4500\n","Epoch 4/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.1861 - accuracy: 0.3436 - val_loss: 5.2444 - val_accuracy: 0.4500\n","Epoch 5/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.5051 - accuracy: 0.3767 - val_loss: 4.5908 - val_accuracy: 0.5000\n","Epoch 6/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.0904 - accuracy: 0.4399 - val_loss: 4.5962 - val_accuracy: 0.5000\n","Epoch 7/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.1934 - accuracy: 0.3852 - val_loss: 4.6012 - val_accuracy: 0.5000\n","Epoch 8/100\n","3/3 [==============================] - 0s 43ms/step - loss: 3.2521 - accuracy: 0.3774 - val_loss: 4.6102 - val_accuracy: 0.5000\n","Epoch 9/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.9880 - accuracy: 0.4282 - val_loss: 5.3331 - val_accuracy: 0.4500\n","Epoch 10/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.7971 - accuracy: 0.4232 - val_loss: 5.2854 - val_accuracy: 0.4000\n","Epoch 11/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.4775 - accuracy: 0.4019 - val_loss: 5.2835 - val_accuracy: 0.4000\n","1/1 [==============================] - 0s 134ms/step - loss: 15.4503 - accuracy: 0.0000e+00\n","Epoch 1/100\n","3/3 [==============================] - 1s 102ms/step - loss: 10.3553 - accuracy: 0.1009 - val_loss: 5.0571 - val_accuracy: 0.4000\n","Epoch 2/100\n","3/3 [==============================] - 0s 56ms/step - loss: 6.2447 - accuracy: 0.2719 - val_loss: 5.1342 - val_accuracy: 0.3500\n","Epoch 3/100\n","3/3 [==============================] - 0s 36ms/step - loss: 6.4951 - accuracy: 0.2836 - val_loss: 6.5484 - val_accuracy: 0.3500\n","Epoch 4/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.2636 - accuracy: 0.3070 - val_loss: 6.5330 - val_accuracy: 0.3500\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.4661 - accuracy: 0.2640 - val_loss: 6.5338 - val_accuracy: 0.3500\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.3179 - accuracy: 0.2914 - val_loss: 6.5284 - val_accuracy: 0.3500\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.0364 - accuracy: 0.2690 - val_loss: 6.5018 - val_accuracy: 0.3500\n","Epoch 8/100\n","3/3 [==============================] - 0s 41ms/step - loss: 5.7420 - accuracy: 0.2573 - val_loss: 6.4566 - val_accuracy: 0.3500\n","Epoch 9/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.7584 - accuracy: 0.2523 - val_loss: 6.3915 - val_accuracy: 0.3500\n","Epoch 10/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.8904 - accuracy: 0.2601 - val_loss: 6.3864 - val_accuracy: 0.3500\n","Epoch 11/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.4406 - accuracy: 0.2679 - val_loss: 5.8844 - val_accuracy: 0.3500\n","1/1 [==============================] - 0s 171ms/step - loss: 10.0495 - accuracy: 0.2632\n","Epoch 1/100\n","3/3 [==============================] - 1s 110ms/step - loss: 8.8877 - accuracy: 0.2388 - val_loss: 9.9336 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 9.7563 - accuracy: 0.2719 - val_loss: 7.9637 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 40ms/step - loss: 7.5716 - accuracy: 0.3010 - val_loss: 7.9425 - val_accuracy: 0.2500\n","Epoch 4/100\n","3/3 [==============================] - 0s 36ms/step - loss: 7.3136 - accuracy: 0.2932 - val_loss: 9.3375 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.6868 - accuracy: 0.2854 - val_loss: 9.3274 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.9855 - accuracy: 0.2932 - val_loss: 9.3230 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 7.6846 - accuracy: 0.2893 - val_loss: 9.3293 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.4373 - accuracy: 0.3205 - val_loss: 9.4088 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 35ms/step - loss: 7.7610 - accuracy: 0.3088 - val_loss: 9.3332 - val_accuracy: 0.2000\n","Epoch 10/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.2734 - accuracy: 0.3273 - val_loss: 8.7070 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.1524 - accuracy: 0.3223 - val_loss: 8.7799 - val_accuracy: 0.2500\n","Epoch 12/100\n","3/3 [==============================] - 0s 41ms/step - loss: 5.4869 - accuracy: 0.3486 - val_loss: 8.7109 - val_accuracy: 0.2500\n","Epoch 13/100\n","3/3 [==============================] - 0s 39ms/step - loss: 7.2799 - accuracy: 0.3244 - val_loss: 7.1273 - val_accuracy: 0.1500\n","Epoch 14/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.8095 - accuracy: 0.3262 - val_loss: 2.1229 - val_accuracy: 0.3500\n","Epoch 15/100\n","3/3 [==============================] - 0s 51ms/step - loss: 1.3203 - accuracy: 0.3895 - val_loss: 2.1229 - val_accuracy: 0.3500\n","Epoch 16/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.3474 - accuracy: 0.3504 - val_loss: 2.1229 - val_accuracy: 0.3500\n","Epoch 17/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.3203 - accuracy: 0.3738 - val_loss: 2.1229 - val_accuracy: 0.3500\n","Epoch 18/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3095 - accuracy: 0.3738 - val_loss: 2.1229 - val_accuracy: 0.3500\n","Epoch 19/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3203 - accuracy: 0.3817 - val_loss: 2.1229 - val_accuracy: 0.3500\n","Epoch 20/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3095 - accuracy: 0.3582 - val_loss: 2.1229 - val_accuracy: 0.3500\n","Epoch 21/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3203 - accuracy: 0.3660 - val_loss: 2.1229 - val_accuracy: 0.3500\n","Epoch 22/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3311 - accuracy: 0.3465 - val_loss: 2.1229 - val_accuracy: 0.3500\n","Epoch 23/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3203 - accuracy: 0.3738 - val_loss: 2.1229 - val_accuracy: 0.3500\n","Epoch 24/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3203 - accuracy: 0.3856 - val_loss: 2.1229 - val_accuracy: 0.3500\n","1/1 [==============================] - 0s 191ms/step - loss: 2.6348 - accuracy: 0.3684\n","Epoch 1/100\n","3/3 [==============================] - 1s 107ms/step - loss: 7.7821 - accuracy: 0.2211 - val_loss: 5.9637 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.8471 - accuracy: 0.3190 - val_loss: 7.7275 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.9132 - accuracy: 0.3151 - val_loss: 7.3045 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.1061 - accuracy: 0.2661 - val_loss: 8.3158 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 44ms/step - loss: 6.1381 - accuracy: 0.2689 - val_loss: 8.3779 - val_accuracy: 0.1500\n","Epoch 6/100\n","3/3 [==============================] - 0s 39ms/step - loss: 4.8036 - accuracy: 0.3358 - val_loss: 6.9174 - val_accuracy: 0.1500\n","Epoch 7/100\n","3/3 [==============================] - 0s 39ms/step - loss: 3.9651 - accuracy: 0.3291 - val_loss: 4.6803 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.5960 - accuracy: 0.3820 - val_loss: 7.1109 - val_accuracy: 0.2000\n","Epoch 9/100\n","3/3 [==============================] - 0s 40ms/step - loss: 4.7452 - accuracy: 0.3146 - val_loss: 7.0935 - val_accuracy: 0.2000\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.0350 - accuracy: 0.3029 - val_loss: 7.0206 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.4912 - accuracy: 0.3280 - val_loss: 6.9378 - val_accuracy: 0.2000\n","Epoch 12/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.4878 - accuracy: 0.3330 - val_loss: 6.3511 - val_accuracy: 0.2000\n","Epoch 13/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.2475 - accuracy: 0.2979 - val_loss: 6.3519 - val_accuracy: 0.2000\n","Epoch 14/100\n","3/3 [==============================] - 0s 40ms/step - loss: 4.0917 - accuracy: 0.3057 - val_loss: 6.3519 - val_accuracy: 0.2000\n","Epoch 15/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.1526 - accuracy: 0.3408 - val_loss: 6.3519 - val_accuracy: 0.2000\n","Epoch 16/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.0754 - accuracy: 0.3096 - val_loss: 6.3519 - val_accuracy: 0.2000\n","Epoch 17/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.1025 - accuracy: 0.3174 - val_loss: 6.3519 - val_accuracy: 0.2000\n","1/1 [==============================] - 0s 189ms/step - loss: 6.9228 - accuracy: 0.1667\n","Epoch 1/100\n","3/3 [==============================] - 1s 108ms/step - loss: 7.4354 - accuracy: 0.2211 - val_loss: 5.5266 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 44ms/step - loss: 4.0992 - accuracy: 0.3057 - val_loss: 5.5403 - val_accuracy: 0.3500\n","Epoch 3/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.9301 - accuracy: 0.3402 - val_loss: 7.0495 - val_accuracy: 0.1000\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.1316 - accuracy: 0.2767 - val_loss: 7.7228 - val_accuracy: 0.1000\n","Epoch 5/100\n","3/3 [==============================] - 0s 40ms/step - loss: 3.8556 - accuracy: 0.2963 - val_loss: 6.2774 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 42ms/step - loss: 5.4774 - accuracy: 0.3363 - val_loss: 7.9409 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 36ms/step - loss: 7.4082 - accuracy: 0.3624 - val_loss: 8.5616 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.0715 - accuracy: 0.4293 - val_loss: 8.5446 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.0087 - accuracy: 0.3898 - val_loss: 8.5343 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.9474 - accuracy: 0.3480 - val_loss: 8.5166 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 38ms/step - loss: 5.6771 - accuracy: 0.3992 - val_loss: 8.4910 - val_accuracy: 0.2000\n","1/1 [==============================] - 0s 164ms/step - loss: 3.5166 - accuracy: 0.3889\n","Epoch 1/100\n","3/3 [==============================] - 1s 112ms/step - loss: 10.0948 - accuracy: 0.0281 - val_loss: 12.1361 - val_accuracy: 0.1500\n","Epoch 2/100\n","3/3 [==============================] - 0s 35ms/step - loss: 10.1959 - accuracy: 0.0213 - val_loss: 10.7648 - val_accuracy: 0.1500\n","Epoch 3/100\n","3/3 [==============================] - 0s 39ms/step - loss: 9.9918 - accuracy: 0.0291 - val_loss: 10.0071 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 9.3766 - accuracy: 0.0572 - val_loss: 9.3125 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 41ms/step - loss: 7.8129 - accuracy: 0.0370 - val_loss: 9.3609 - val_accuracy: 0.1000\n","Epoch 6/100\n","3/3 [==============================] - 0s 38ms/step - loss: 7.5859 - accuracy: 0.0000e+00 - val_loss: 9.3571 - val_accuracy: 0.1000\n","Epoch 7/100\n","3/3 [==============================] - 0s 40ms/step - loss: 7.3203 - accuracy: 0.0000e+00 - val_loss: 9.3520 - val_accuracy: 0.1000\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.1949 - accuracy: 0.0000e+00 - val_loss: 9.3484 - val_accuracy: 0.1000\n","Epoch 9/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.9709 - accuracy: 0.0000e+00 - val_loss: 9.3459 - val_accuracy: 0.1000\n","Epoch 10/100\n","3/3 [==============================] - 0s 32ms/step - loss: 6.5675 - accuracy: 0.0000e+00 - val_loss: 9.3392 - val_accuracy: 0.1000\n","Epoch 11/100\n","3/3 [==============================] - 0s 39ms/step - loss: 6.8472 - accuracy: 0.0000e+00 - val_loss: 9.3143 - val_accuracy: 0.1000\n","Epoch 12/100\n","3/3 [==============================] - 0s 38ms/step - loss: 6.6539 - accuracy: 0.0000e+00 - val_loss: 9.3043 - val_accuracy: 0.1000\n","Epoch 13/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.1920 - accuracy: 0.0000e+00 - val_loss: 9.2832 - val_accuracy: 0.1000\n","Epoch 14/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.0513 - accuracy: 0.0000e+00 - val_loss: 9.2702 - val_accuracy: 0.1000\n","Epoch 15/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.4085 - accuracy: 0.0000e+00 - val_loss: 9.2230 - val_accuracy: 0.1000\n","Epoch 16/100\n","3/3 [==============================] - 0s 66ms/step - loss: 6.8041 - accuracy: 0.0000e+00 - val_loss: 8.6681 - val_accuracy: 0.1000\n","Epoch 17/100\n","3/3 [==============================] - 0s 37ms/step - loss: 6.2809 - accuracy: 0.0107 - val_loss: 8.6516 - val_accuracy: 0.1000\n","Epoch 18/100\n","3/3 [==============================] - 0s 48ms/step - loss: 6.4299 - accuracy: 0.0135 - val_loss: 8.6377 - val_accuracy: 0.1000\n","Epoch 19/100\n","3/3 [==============================] - 0s 38ms/step - loss: 6.3134 - accuracy: 0.0213 - val_loss: 2.0521 - val_accuracy: 0.1500\n","Epoch 20/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.4517 - accuracy: 0.0370 - val_loss: 1.3863 - val_accuracy: 0.1500\n","Epoch 21/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.7601 - accuracy: 0.0252 - val_loss: 1.3863 - val_accuracy: 0.1000\n","Epoch 22/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.6469 - accuracy: 0.0252 - val_loss: 1.3863 - val_accuracy: 0.1000\n","Epoch 23/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.5337 - accuracy: 0.0291 - val_loss: 1.3863 - val_accuracy: 0.1000\n","Epoch 24/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.6309 - accuracy: 0.0252 - val_loss: 1.3863 - val_accuracy: 0.1000\n","Epoch 25/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3863 - accuracy: 0.0213 - val_loss: 1.3863 - val_accuracy: 0.1000\n","Epoch 26/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.3863 - accuracy: 0.0370 - val_loss: 1.3863 - val_accuracy: 0.1000\n","Epoch 27/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3863 - accuracy: 0.0174 - val_loss: 1.3863 - val_accuracy: 0.1000\n","Epoch 28/100\n","3/3 [==============================] - 0s 39ms/step - loss: 1.3863 - accuracy: 0.0291 - val_loss: 1.3863 - val_accuracy: 0.1000\n","Epoch 29/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.3863 - accuracy: 0.0291 - val_loss: 1.3863 - val_accuracy: 0.1000\n","Epoch 30/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3863 - accuracy: 0.0291 - val_loss: 1.3863 - val_accuracy: 0.1000\n","1/1 [==============================] - 0s 188ms/step - loss: 1.3710 - accuracy: 0.5263\n","Epoch 1/100\n","3/3 [==============================] - 1s 117ms/step - loss: 3.6503 - accuracy: 0.3777 - val_loss: 3.4049 - val_accuracy: 0.4000\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.4002 - accuracy: 0.3436 - val_loss: 3.4013 - val_accuracy: 0.4000\n","Epoch 3/100\n","3/3 [==============================] - 0s 40ms/step - loss: 3.3382 - accuracy: 0.3720 - val_loss: 3.4042 - val_accuracy: 0.4000\n","Epoch 4/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.4013 - accuracy: 0.3213 - val_loss: 3.4086 - val_accuracy: 0.4000\n","Epoch 5/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.3873 - accuracy: 0.3369 - val_loss: 3.4087 - val_accuracy: 0.4000\n","Epoch 6/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.6142 - accuracy: 0.3252 - val_loss: 3.4056 - val_accuracy: 0.4000\n","Epoch 7/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.7941 - accuracy: 0.3252 - val_loss: 3.4070 - val_accuracy: 0.4000\n","Epoch 8/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.7246 - accuracy: 0.3095 - val_loss: 3.4034 - val_accuracy: 0.4000\n","Epoch 9/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.4262 - accuracy: 0.3213 - val_loss: 3.4013 - val_accuracy: 0.4000\n","Epoch 10/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.7141 - accuracy: 0.2978 - val_loss: 3.4004 - val_accuracy: 0.4500\n","Epoch 11/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.6458 - accuracy: 0.3369 - val_loss: 3.4059 - val_accuracy: 0.4500\n","Epoch 12/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.2509 - accuracy: 0.3671 - val_loss: 3.4080 - val_accuracy: 0.4500\n","Epoch 13/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.4984 - accuracy: 0.3554 - val_loss: 3.4082 - val_accuracy: 0.4500\n","Epoch 14/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.4136 - accuracy: 0.3515 - val_loss: 3.4111 - val_accuracy: 0.4500\n","Epoch 15/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.3002 - accuracy: 0.3554 - val_loss: 3.4091 - val_accuracy: 0.4500\n","Epoch 16/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.5367 - accuracy: 0.3397 - val_loss: 3.4055 - val_accuracy: 0.4500\n","Epoch 17/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.7699 - accuracy: 0.3309 - val_loss: 3.4026 - val_accuracy: 0.4500\n","Epoch 18/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.5629 - accuracy: 0.3777 - val_loss: 3.4034 - val_accuracy: 0.4500\n","Epoch 19/100\n","3/3 [==============================] - 0s 39ms/step - loss: 3.7230 - accuracy: 0.3436 - val_loss: 3.4018 - val_accuracy: 0.4500\n","Epoch 20/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.6437 - accuracy: 0.3543 - val_loss: 3.4042 - val_accuracy: 0.4500\n","1/1 [==============================] - 0s 188ms/step - loss: 2.6565 - accuracy: 0.3158\n","Epoch 1/100\n","3/3 [==============================] - 1s 114ms/step - loss: 7.7395 - accuracy: 0.2313 - val_loss: 6.1754 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 38ms/step - loss: 6.2847 - accuracy: 0.2253 - val_loss: 6.1058 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.1242 - accuracy: 0.1436 - val_loss: 6.0708 - val_accuracy: 0.2500\n","Epoch 4/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.8048 - accuracy: 0.1816 - val_loss: 6.0427 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 40ms/step - loss: 5.9467 - accuracy: 0.1660 - val_loss: 6.6841 - val_accuracy: 0.1500\n","Epoch 6/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.1589 - accuracy: 0.1631 - val_loss: 6.6753 - val_accuracy: 0.1500\n","Epoch 7/100\n","3/3 [==============================] - 0s 42ms/step - loss: 5.1558 - accuracy: 0.2136 - val_loss: 6.7723 - val_accuracy: 0.1500\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.9124 - accuracy: 0.2505 - val_loss: 7.2452 - val_accuracy: 0.1000\n","Epoch 9/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.2041 - accuracy: 0.2612 - val_loss: 6.7035 - val_accuracy: 0.1000\n","Epoch 10/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.4288 - accuracy: 0.2864 - val_loss: 5.8805 - val_accuracy: 0.1000\n","Epoch 11/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.1789 - accuracy: 0.2719 - val_loss: 6.4713 - val_accuracy: 0.2000\n","Epoch 12/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.5442 - accuracy: 0.3010 - val_loss: 6.4485 - val_accuracy: 0.1500\n","Epoch 13/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.1391 - accuracy: 0.2893 - val_loss: 6.3883 - val_accuracy: 0.1500\n","Epoch 14/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.8018 - accuracy: 0.3010 - val_loss: 6.2618 - val_accuracy: 0.1500\n","Epoch 15/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.4520 - accuracy: 0.2971 - val_loss: 6.2909 - val_accuracy: 0.1500\n","Epoch 16/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.5803 - accuracy: 0.3283 - val_loss: 6.3085 - val_accuracy: 0.1500\n","Epoch 17/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.7270 - accuracy: 0.2971 - val_loss: 6.3221 - val_accuracy: 0.1500\n","Epoch 18/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.5061 - accuracy: 0.3010 - val_loss: 6.3679 - val_accuracy: 0.1500\n","Epoch 19/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.5089 - accuracy: 0.2747 - val_loss: 6.3715 - val_accuracy: 0.1500\n","Epoch 20/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.5759 - accuracy: 0.3088 - val_loss: 6.7302 - val_accuracy: 0.1500\n","1/1 [==============================] - 0s 198ms/step - loss: 5.5853 - accuracy: 0.2632\n","Epoch 1/100\n","3/3 [==============================] - 1s 115ms/step - loss: 8.0936 - accuracy: 0.1687 - val_loss: 8.8296 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 31ms/step - loss: 6.8736 - accuracy: 0.1531 - val_loss: 8.6759 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.6922 - accuracy: 0.1726 - val_loss: 8.3350 - val_accuracy: 0.3000\n","Epoch 4/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.1071 - accuracy: 0.1938 - val_loss: 6.0595 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.5694 - accuracy: 0.2094 - val_loss: 6.9702 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.1857 - accuracy: 0.2583 - val_loss: 6.3007 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.2558 - accuracy: 0.2740 - val_loss: 4.5487 - val_accuracy: 0.3500\n","Epoch 8/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.5213 - accuracy: 0.2767 - val_loss: 3.9762 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.0002 - accuracy: 0.2661 - val_loss: 3.9637 - val_accuracy: 0.3000\n","Epoch 10/100\n","3/3 [==============================] - 0s 42ms/step - loss: 2.9907 - accuracy: 0.2583 - val_loss: 3.9386 - val_accuracy: 0.3500\n","Epoch 11/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.7979 - accuracy: 0.3002 - val_loss: 3.2843 - val_accuracy: 0.3500\n","Epoch 12/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.3296 - accuracy: 0.2661 - val_loss: 3.2796 - val_accuracy: 0.3500\n","Epoch 13/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.5245 - accuracy: 0.2740 - val_loss: 3.2723 - val_accuracy: 0.3500\n","Epoch 14/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.3032 - accuracy: 0.2923 - val_loss: 3.2688 - val_accuracy: 0.3500\n","Epoch 15/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.2964 - accuracy: 0.2611 - val_loss: 3.2648 - val_accuracy: 0.3500\n","Epoch 16/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.2953 - accuracy: 0.2611 - val_loss: 3.2604 - val_accuracy: 0.3500\n","Epoch 17/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.9543 - accuracy: 0.2767 - val_loss: 3.2478 - val_accuracy: 0.3500\n","Epoch 18/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.1534 - accuracy: 0.2767 - val_loss: 3.2441 - val_accuracy: 0.3500\n","Epoch 19/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.1336 - accuracy: 0.2650 - val_loss: 3.2399 - val_accuracy: 0.3500\n","Epoch 20/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.0229 - accuracy: 0.3041 - val_loss: 3.2351 - val_accuracy: 0.3500\n","Epoch 21/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.7465 - accuracy: 0.3197 - val_loss: 3.2259 - val_accuracy: 0.3500\n","Epoch 22/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.0102 - accuracy: 0.2923 - val_loss: 3.2179 - val_accuracy: 0.3000\n","Epoch 23/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.8068 - accuracy: 0.2923 - val_loss: 3.2078 - val_accuracy: 0.3000\n","Epoch 24/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.8418 - accuracy: 0.2963 - val_loss: 3.1873 - val_accuracy: 0.3000\n","Epoch 25/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.9028 - accuracy: 0.2806 - val_loss: 3.1339 - val_accuracy: 0.3000\n","Epoch 26/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.5831 - accuracy: 0.2834 - val_loss: 3.1128 - val_accuracy: 0.3000\n","Epoch 27/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3771 - accuracy: 0.2756 - val_loss: 3.1128 - val_accuracy: 0.3000\n","Epoch 28/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.3608 - accuracy: 0.2834 - val_loss: 3.1128 - val_accuracy: 0.3000\n","Epoch 29/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3608 - accuracy: 0.3146 - val_loss: 3.1128 - val_accuracy: 0.3000\n","Epoch 30/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3716 - accuracy: 0.2873 - val_loss: 3.1128 - val_accuracy: 0.3000\n","Epoch 31/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.3608 - accuracy: 0.2873 - val_loss: 3.1128 - val_accuracy: 0.3000\n","Epoch 32/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.3771 - accuracy: 0.2599 - val_loss: 3.1128 - val_accuracy: 0.3000\n","Epoch 33/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3608 - accuracy: 0.2834 - val_loss: 3.1128 - val_accuracy: 0.3000\n","Epoch 34/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3716 - accuracy: 0.2990 - val_loss: 3.1128 - val_accuracy: 0.3000\n","Epoch 35/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3716 - accuracy: 0.2639 - val_loss: 3.1128 - val_accuracy: 0.3000\n","Epoch 36/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.3608 - accuracy: 0.2717 - val_loss: 3.1128 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 228ms/step - loss: 2.0934 - accuracy: 0.3333\n","Epoch 1/100\n","3/3 [==============================] - 1s 155ms/step - loss: 3.6549 - accuracy: 0.4254 - val_loss: 1.1441 - val_accuracy: 0.6000\n","Epoch 2/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.1892 - accuracy: 0.4309 - val_loss: 1.1243 - val_accuracy: 0.5500\n","Epoch 3/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.0222 - accuracy: 0.4454 - val_loss: 1.1474 - val_accuracy: 0.5500\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.9654 - accuracy: 0.4516 - val_loss: 1.9050 - val_accuracy: 0.4500\n","Epoch 5/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.9351 - accuracy: 0.4454 - val_loss: 1.7100 - val_accuracy: 0.5000\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.8084 - accuracy: 0.4760 - val_loss: 1.6989 - val_accuracy: 0.5000\n","Epoch 7/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.4633 - accuracy: 0.4760 - val_loss: 1.6614 - val_accuracy: 0.5000\n","Epoch 8/100\n","3/3 [==============================] - 0s 40ms/step - loss: 2.6579 - accuracy: 0.5440 - val_loss: 1.6333 - val_accuracy: 0.5000\n","Epoch 9/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.5541 - accuracy: 0.5167 - val_loss: 1.6252 - val_accuracy: 0.5000\n","Epoch 10/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.2853 - accuracy: 0.5585 - val_loss: 1.6347 - val_accuracy: 0.5000\n","Epoch 11/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.0645 - accuracy: 0.5206 - val_loss: 1.6416 - val_accuracy: 0.5000\n","Epoch 12/100\n","3/3 [==============================] - 0s 41ms/step - loss: 2.5876 - accuracy: 0.5167 - val_loss: 1.5977 - val_accuracy: 0.5000\n","1/1 [==============================] - 0s 196ms/step - loss: 7.1413 - accuracy: 0.1667\n","Epoch 1/100\n","3/3 [==============================] - 1s 119ms/step - loss: 1.8983 - accuracy: 0.4670 - val_loss: 2.5489 - val_accuracy: 0.4000\n","Epoch 2/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.2179 - accuracy: 0.5391 - val_loss: 2.5735 - val_accuracy: 0.4000\n","Epoch 3/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.0970 - accuracy: 0.5195 - val_loss: 2.7074 - val_accuracy: 0.3500\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.2337 - accuracy: 0.5370 - val_loss: 3.2880 - val_accuracy: 0.3500\n","Epoch 5/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.1847 - accuracy: 0.5224 - val_loss: 3.4099 - val_accuracy: 0.3000\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 0.9839 - accuracy: 0.5057 - val_loss: 4.0049 - val_accuracy: 0.3000\n","Epoch 7/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.2631 - accuracy: 0.5689 - val_loss: 4.0088 - val_accuracy: 0.3500\n","Epoch 8/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.0943 - accuracy: 0.5299 - val_loss: 4.0256 - val_accuracy: 0.3500\n","Epoch 9/100\n","3/3 [==============================] - 0s 34ms/step - loss: 0.8994 - accuracy: 0.6155 - val_loss: 4.0390 - val_accuracy: 0.3500\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.0367 - accuracy: 0.6585 - val_loss: 4.1273 - val_accuracy: 0.3500\n","Epoch 11/100\n","3/3 [==============================] - 0s 34ms/step - loss: 0.9234 - accuracy: 0.6251 - val_loss: 4.6766 - val_accuracy: 0.4000\n","1/1 [==============================] - 0s 203ms/step - loss: 12.1127 - accuracy: 0.0000e+00\n","Epoch 1/100\n","3/3 [==============================] - 1s 110ms/step - loss: 7.9721 - accuracy: 0.2214 - val_loss: 7.2469 - val_accuracy: 0.1500\n","Epoch 2/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.1781 - accuracy: 0.2360 - val_loss: 3.7811 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.2892 - accuracy: 0.2164 - val_loss: 3.7167 - val_accuracy: 0.2500\n","Epoch 4/100\n","3/3 [==============================] - 0s 40ms/step - loss: 3.0908 - accuracy: 0.2882 - val_loss: 4.1918 - val_accuracy: 0.2500\n","Epoch 5/100\n","3/3 [==============================] - 0s 41ms/step - loss: 2.2035 - accuracy: 0.3077 - val_loss: 3.4712 - val_accuracy: 0.3500\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.6491 - accuracy: 0.2747 - val_loss: 3.4214 - val_accuracy: 0.3500\n","Epoch 7/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.4986 - accuracy: 0.2776 - val_loss: 3.5562 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3284 - accuracy: 0.3650 - val_loss: 3.5519 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3302 - accuracy: 0.3777 - val_loss: 3.5475 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3344 - accuracy: 0.4040 - val_loss: 3.5425 - val_accuracy: 0.2500\n","Epoch 11/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3118 - accuracy: 0.3572 - val_loss: 3.5369 - val_accuracy: 0.2500\n","Epoch 12/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3144 - accuracy: 0.3962 - val_loss: 3.5199 - val_accuracy: 0.2500\n","Epoch 13/100\n","3/3 [==============================] - 0s 44ms/step - loss: 1.2887 - accuracy: 0.3767 - val_loss: 3.5146 - val_accuracy: 0.2500\n","Epoch 14/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.3182 - accuracy: 0.3728 - val_loss: 3.5074 - val_accuracy: 0.2500\n","Epoch 15/100\n","3/3 [==============================] - 0s 42ms/step - loss: 1.3063 - accuracy: 0.3884 - val_loss: 3.5007 - val_accuracy: 0.2500\n","Epoch 16/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.2947 - accuracy: 0.4392 - val_loss: 3.5007 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 218ms/step - loss: 5.7173 - accuracy: 0.3684\n","Epoch 1/100\n","3/3 [==============================] - 1s 266ms/step - loss: 9.2392 - accuracy: 0.0931 - val_loss: 7.5568 - val_accuracy: 0.1000\n","Epoch 2/100\n","3/3 [==============================] - 0s 40ms/step - loss: 7.9938 - accuracy: 0.1379 - val_loss: 7.4979 - val_accuracy: 0.1000\n","Epoch 3/100\n","3/3 [==============================] - 0s 35ms/step - loss: 7.8739 - accuracy: 0.1592 - val_loss: 7.6037 - val_accuracy: 0.1000\n","Epoch 4/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.9628 - accuracy: 0.1816 - val_loss: 9.2947 - val_accuracy: 0.1000\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 8.8623 - accuracy: 0.2214 - val_loss: 11.3755 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 36ms/step - loss: 10.3125 - accuracy: 0.2573 - val_loss: 10.6482 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 9.8049 - accuracy: 0.2601 - val_loss: 11.2888 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 9.8107 - accuracy: 0.2758 - val_loss: 10.4330 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 38ms/step - loss: 9.1792 - accuracy: 0.2068 - val_loss: 10.0400 - val_accuracy: 0.2000\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 9.2699 - accuracy: 0.1962 - val_loss: 10.0349 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 35ms/step - loss: 8.8295 - accuracy: 0.2118 - val_loss: 10.0282 - val_accuracy: 0.2000\n","Epoch 12/100\n","3/3 [==============================] - 0s 33ms/step - loss: 8.8139 - accuracy: 0.1883 - val_loss: 10.0214 - val_accuracy: 0.2000\n","1/1 [==============================] - 0s 200ms/step - loss: 10.6054 - accuracy: 0.1053\n","Epoch 1/100\n","3/3 [==============================] - 1s 117ms/step - loss: 7.1661 - accuracy: 0.2250 - val_loss: 5.1583 - val_accuracy: 0.1000\n","Epoch 2/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.0845 - accuracy: 0.2172 - val_loss: 2.7386 - val_accuracy: 0.1000\n","Epoch 3/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.2268 - accuracy: 0.2094 - val_loss: 2.6434 - val_accuracy: 0.1000\n","Epoch 4/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.1412 - accuracy: 0.2333 - val_loss: 1.3863 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.9456 - accuracy: 0.3436 - val_loss: 1.3863 - val_accuracy: 0.1500\n","Epoch 6/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.7148 - accuracy: 0.3123 - val_loss: 1.3863 - val_accuracy: 0.1500\n","Epoch 7/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.3863 - accuracy: 0.3319 - val_loss: 1.3863 - val_accuracy: 0.1500\n","Epoch 8/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3863 - accuracy: 0.3202 - val_loss: 1.3863 - val_accuracy: 0.1500\n","Epoch 9/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3863 - accuracy: 0.2889 - val_loss: 1.3863 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.3863 - accuracy: 0.3319 - val_loss: 1.3863 - val_accuracy: 0.1500\n","Epoch 11/100\n","3/3 [==============================] - 0s 40ms/step - loss: 1.3863 - accuracy: 0.2967 - val_loss: 1.3863 - val_accuracy: 0.1500\n","Epoch 12/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.3863 - accuracy: 0.3006 - val_loss: 1.3863 - val_accuracy: 0.1500\n","Epoch 13/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.3863 - accuracy: 0.3006 - val_loss: 1.3863 - val_accuracy: 0.1500\n","Epoch 14/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.3863 - accuracy: 0.3319 - val_loss: 1.3863 - val_accuracy: 0.1500\n","1/1 [==============================] - 0s 207ms/step - loss: 1.3863 - accuracy: 0.1667\n","Epoch 1/100\n","3/3 [==============================] - 1s 118ms/step - loss: 4.3001 - accuracy: 0.4387 - val_loss: 3.0741 - val_accuracy: 0.5000\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.4449 - accuracy: 0.5624 - val_loss: 3.0579 - val_accuracy: 0.6000\n","Epoch 3/100\n","3/3 [==============================] - 0s 39ms/step - loss: 3.6152 - accuracy: 0.5178 - val_loss: 3.0494 - val_accuracy: 0.6000\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.9719 - accuracy: 0.4737 - val_loss: 3.0152 - val_accuracy: 0.6000\n","Epoch 5/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.9129 - accuracy: 0.5663 - val_loss: 2.9818 - val_accuracy: 0.6000\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.8198 - accuracy: 0.5300 - val_loss: 2.9667 - val_accuracy: 0.6500\n","Epoch 7/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.1480 - accuracy: 0.5914 - val_loss: 2.9406 - val_accuracy: 0.6500\n","Epoch 8/100\n","3/3 [==============================] - 0s 39ms/step - loss: 3.0166 - accuracy: 0.5835 - val_loss: 2.9860 - val_accuracy: 0.6000\n","Epoch 9/100\n","3/3 [==============================] - 0s 44ms/step - loss: 2.8916 - accuracy: 0.6293 - val_loss: 2.9440 - val_accuracy: 0.6000\n","Epoch 10/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.4457 - accuracy: 0.6019 - val_loss: 2.9259 - val_accuracy: 0.6500\n","Epoch 11/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.0417 - accuracy: 0.5406 - val_loss: 2.9252 - val_accuracy: 0.6500\n","Epoch 12/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.6055 - accuracy: 0.5679 - val_loss: 2.9115 - val_accuracy: 0.6500\n","Epoch 13/100\n","3/3 [==============================] - 0s 40ms/step - loss: 3.2405 - accuracy: 0.5874 - val_loss: 2.9058 - val_accuracy: 0.6500\n","Epoch 14/100\n","3/3 [==============================] - 0s 40ms/step - loss: 2.9419 - accuracy: 0.6008 - val_loss: 2.9021 - val_accuracy: 0.6500\n","Epoch 15/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.5549 - accuracy: 0.6281 - val_loss: 2.9154 - val_accuracy: 0.6500\n","Epoch 16/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.2439 - accuracy: 0.5879 - val_loss: 2.9420 - val_accuracy: 0.6500\n","Epoch 17/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.0590 - accuracy: 0.5930 - val_loss: 2.9440 - val_accuracy: 0.6500\n","Epoch 18/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.7845 - accuracy: 0.6047 - val_loss: 2.9509 - val_accuracy: 0.6500\n","Epoch 19/100\n","3/3 [==============================] - 0s 40ms/step - loss: 2.8295 - accuracy: 0.5930 - val_loss: 2.9620 - val_accuracy: 0.6500\n","Epoch 20/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.5550 - accuracy: 0.6164 - val_loss: 3.3043 - val_accuracy: 0.6500\n","Epoch 21/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.0554 - accuracy: 0.6024 - val_loss: 3.6344 - val_accuracy: 0.6500\n","Epoch 22/100\n","3/3 [==============================] - 0s 39ms/step - loss: 3.0811 - accuracy: 0.6035 - val_loss: 3.6247 - val_accuracy: 0.6500\n","Epoch 23/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.8244 - accuracy: 0.6297 - val_loss: 3.6234 - val_accuracy: 0.6500\n","Epoch 24/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.8373 - accuracy: 0.6403 - val_loss: 3.6230 - val_accuracy: 0.6500\n","1/1 [==============================] - 0s 197ms/step - loss: 4.3722 - accuracy: 0.1111\n","Epoch 1/100\n","3/3 [==============================] - 1s 116ms/step - loss: 11.8660 - accuracy: 0.0174 - val_loss: 6.9754 - val_accuracy: 0.1000\n","Epoch 2/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.2620 - accuracy: 0.2182 - val_loss: 2.6679 - val_accuracy: 0.1500\n","Epoch 3/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.0613 - accuracy: 0.2378 - val_loss: 2.6340 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.6241 - accuracy: 0.2942 - val_loss: 2.0078 - val_accuracy: 0.2000\n","Epoch 5/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.4255 - accuracy: 0.3390 - val_loss: 2.0076 - val_accuracy: 0.2000\n","Epoch 6/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.4426 - accuracy: 0.2989 - val_loss: 2.0075 - val_accuracy: 0.2000\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.2872 - accuracy: 0.3877 - val_loss: 1.9973 - val_accuracy: 0.2000\n","Epoch 8/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.4899 - accuracy: 0.3262 - val_loss: 1.9847 - val_accuracy: 0.1500\n","Epoch 9/100\n","3/3 [==============================] - 0s 41ms/step - loss: 1.2961 - accuracy: 0.3408 - val_loss: 1.9838 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 41ms/step - loss: 1.2880 - accuracy: 0.3369 - val_loss: 1.9833 - val_accuracy: 0.1500\n","Epoch 11/100\n","3/3 [==============================] - 0s 39ms/step - loss: 1.2766 - accuracy: 0.3369 - val_loss: 1.9829 - val_accuracy: 0.1500\n","Epoch 12/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.2797 - accuracy: 0.3174 - val_loss: 1.9823 - val_accuracy: 0.1500\n","Epoch 13/100\n","3/3 [==============================] - 0s 39ms/step - loss: 1.2922 - accuracy: 0.3330 - val_loss: 1.9817 - val_accuracy: 0.2000\n","Epoch 14/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.2884 - accuracy: 0.3291 - val_loss: 1.9802 - val_accuracy: 0.2000\n","Epoch 15/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.2657 - accuracy: 0.3408 - val_loss: 1.9798 - val_accuracy: 0.2000\n","Epoch 16/100\n","3/3 [==============================] - 0s 39ms/step - loss: 1.2922 - accuracy: 0.3252 - val_loss: 1.9795 - val_accuracy: 0.2000\n","Epoch 17/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.2673 - accuracy: 0.3213 - val_loss: 1.9792 - val_accuracy: 0.2000\n","Epoch 18/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.2637 - accuracy: 0.3330 - val_loss: 1.9790 - val_accuracy: 0.2000\n","Epoch 19/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.2930 - accuracy: 0.3358 - val_loss: 1.9787 - val_accuracy: 0.2000\n","Epoch 20/100\n","3/3 [==============================] - 0s 41ms/step - loss: 1.2819 - accuracy: 0.3280 - val_loss: 1.9785 - val_accuracy: 0.2000\n","Epoch 21/100\n","3/3 [==============================] - 0s 39ms/step - loss: 1.2723 - accuracy: 0.3476 - val_loss: 1.9777 - val_accuracy: 0.2000\n","Epoch 22/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.2771 - accuracy: 0.3554 - val_loss: 1.9773 - val_accuracy: 0.2000\n","Epoch 23/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.2561 - accuracy: 0.3476 - val_loss: 1.9769 - val_accuracy: 0.2000\n","Epoch 24/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.2967 - accuracy: 0.3397 - val_loss: 1.9765 - val_accuracy: 0.2000\n","Epoch 25/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.2801 - accuracy: 0.3554 - val_loss: 1.9761 - val_accuracy: 0.2000\n","Epoch 26/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3068 - accuracy: 0.3046 - val_loss: 1.9756 - val_accuracy: 0.2000\n","Epoch 27/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.2617 - accuracy: 0.3593 - val_loss: 1.9751 - val_accuracy: 0.2000\n","Epoch 28/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.2697 - accuracy: 0.3699 - val_loss: 1.9746 - val_accuracy: 0.2000\n","Epoch 29/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.2916 - accuracy: 0.3387 - val_loss: 1.9741 - val_accuracy: 0.2000\n","Epoch 30/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.2713 - accuracy: 0.3738 - val_loss: 1.9724 - val_accuracy: 0.2000\n","Epoch 31/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.2735 - accuracy: 0.3621 - val_loss: 1.9717 - val_accuracy: 0.2000\n","Epoch 32/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.2620 - accuracy: 0.3845 - val_loss: 1.9708 - val_accuracy: 0.2000\n","Epoch 33/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.2709 - accuracy: 0.3689 - val_loss: 1.9704 - val_accuracy: 0.2000\n","Epoch 34/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.2616 - accuracy: 0.3806 - val_loss: 1.9702 - val_accuracy: 0.2000\n","Epoch 35/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.2614 - accuracy: 0.4001 - val_loss: 1.9698 - val_accuracy: 0.2000\n","Epoch 36/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.2613 - accuracy: 0.3845 - val_loss: 1.9695 - val_accuracy: 0.2000\n","Epoch 37/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.2543 - accuracy: 0.3845 - val_loss: 1.9692 - val_accuracy: 0.2000\n","Epoch 38/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.2664 - accuracy: 0.3806 - val_loss: 1.9688 - val_accuracy: 0.2000\n","Epoch 39/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.2622 - accuracy: 0.3923 - val_loss: 1.9684 - val_accuracy: 0.2000\n","Epoch 40/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.2606 - accuracy: 0.3806 - val_loss: 1.9680 - val_accuracy: 0.2000\n","Epoch 41/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.2755 - accuracy: 0.3845 - val_loss: 1.9675 - val_accuracy: 0.2000\n","Epoch 42/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.2591 - accuracy: 0.3611 - val_loss: 1.9670 - val_accuracy: 0.2000\n","Epoch 43/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.2964 - accuracy: 0.3884 - val_loss: 1.9653 - val_accuracy: 0.2000\n","Epoch 44/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.2807 - accuracy: 0.3348 - val_loss: 1.9646 - val_accuracy: 0.2000\n","Epoch 45/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.2797 - accuracy: 0.3543 - val_loss: 1.9628 - val_accuracy: 0.2000\n","Epoch 46/100\n","3/3 [==============================] - 0s 41ms/step - loss: 1.2821 - accuracy: 0.3817 - val_loss: 1.9628 - val_accuracy: 0.2000\n","Epoch 47/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.2631 - accuracy: 0.3817 - val_loss: 1.9628 - val_accuracy: 0.2000\n","Epoch 48/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.2821 - accuracy: 0.3699 - val_loss: 1.9628 - val_accuracy: 0.2000\n","Epoch 49/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.2767 - accuracy: 0.3621 - val_loss: 1.9628 - val_accuracy: 0.2000\n","Epoch 50/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.2740 - accuracy: 0.3309 - val_loss: 1.9628 - val_accuracy: 0.2000\n","Epoch 51/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.2713 - accuracy: 0.3582 - val_loss: 1.9628 - val_accuracy: 0.2000\n","Epoch 52/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.2848 - accuracy: 0.3504 - val_loss: 1.9628 - val_accuracy: 0.2000\n","Epoch 53/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.2577 - accuracy: 0.3738 - val_loss: 1.9628 - val_accuracy: 0.2000\n","Epoch 54/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.2577 - accuracy: 0.3543 - val_loss: 1.9628 - val_accuracy: 0.2000\n","Epoch 55/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.2686 - accuracy: 0.3543 - val_loss: 1.9628 - val_accuracy: 0.2000\n","1/1 [==============================] - 0s 208ms/step - loss: 2.5981 - accuracy: 0.1053\n","Epoch 1/100\n","3/3 [==============================] - 1s 162ms/step - loss: 8.4094 - accuracy: 0.1514 - val_loss: 5.5589 - val_accuracy: 0.3500\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.5857 - accuracy: 0.1823 - val_loss: 2.6427 - val_accuracy: 0.5000\n","Epoch 3/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.7989 - accuracy: 0.3543 - val_loss: 9.2560 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.2163 - accuracy: 0.2456 - val_loss: 7.0383 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.3424 - accuracy: 0.2825 - val_loss: 6.2529 - val_accuracy: 0.1000\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.8043 - accuracy: 0.3017 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3863 - accuracy: 0.1980 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 8/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3863 - accuracy: 0.1940 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3863 - accuracy: 0.2175 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3863 - accuracy: 0.2175 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 11/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3863 - accuracy: 0.2214 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 12/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.3863 - accuracy: 0.2175 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 13/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.3863 - accuracy: 0.2019 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 14/100\n","3/3 [==============================] - 0s 43ms/step - loss: 1.3863 - accuracy: 0.2175 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 15/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.3863 - accuracy: 0.2058 - val_loss: 1.3863 - val_accuracy: 0.3000\n","Epoch 16/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3863 - accuracy: 0.2448 - val_loss: 1.3863 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 203ms/step - loss: 1.3863 - accuracy: 0.0526\n","Epoch 1/100\n","3/3 [==============================] - 1s 163ms/step - loss: 5.0765 - accuracy: 0.2555 - val_loss: 2.8380 - val_accuracy: 0.1500\n","Epoch 2/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.4464 - accuracy: 0.3593 - val_loss: 2.0755 - val_accuracy: 0.1500\n","Epoch 3/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.4504 - accuracy: 0.3671 - val_loss: 2.0856 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.3958 - accuracy: 0.3163 - val_loss: 2.1471 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.4215 - accuracy: 0.3593 - val_loss: 2.1483 - val_accuracy: 0.1500\n","Epoch 6/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.3951 - accuracy: 0.3163 - val_loss: 2.1509 - val_accuracy: 0.1500\n","Epoch 7/100\n","3/3 [==============================] - 0s 40ms/step - loss: 2.1947 - accuracy: 0.3632 - val_loss: 2.8043 - val_accuracy: 0.1500\n","Epoch 8/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.9983 - accuracy: 0.3710 - val_loss: 2.8399 - val_accuracy: 0.1500\n","Epoch 9/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.1871 - accuracy: 0.3476 - val_loss: 3.5905 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.3553 - accuracy: 0.3593 - val_loss: 2.9471 - val_accuracy: 0.1500\n","Epoch 11/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.2984 - accuracy: 0.3476 - val_loss: 3.5971 - val_accuracy: 0.1500\n","Epoch 12/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.0126 - accuracy: 0.3710 - val_loss: 3.6099 - val_accuracy: 0.1500\n","1/1 [==============================] - 0s 199ms/step - loss: 1.1978 - accuracy: 0.2105\n","Epoch 1/100\n","3/3 [==============================] - 1s 123ms/step - loss: 8.1256 - accuracy: 0.2717 - val_loss: 8.0571 - val_accuracy: 0.3000\n","Epoch 2/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.8936 - accuracy: 0.3346 - val_loss: 5.1625 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.7250 - accuracy: 0.2979 - val_loss: 4.5976 - val_accuracy: 0.3000\n","Epoch 4/100\n","3/3 [==============================] - 0s 30ms/step - loss: 6.0718 - accuracy: 0.3424 - val_loss: 4.5961 - val_accuracy: 0.3000\n","Epoch 5/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.5159 - accuracy: 0.3229 - val_loss: 4.5943 - val_accuracy: 0.3000\n","Epoch 6/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.8646 - accuracy: 0.3112 - val_loss: 4.5837 - val_accuracy: 0.3000\n","Epoch 7/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.6644 - accuracy: 0.3162 - val_loss: 4.5837 - val_accuracy: 0.3000\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.9001 - accuracy: 0.3358 - val_loss: 4.5837 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.5513 - accuracy: 0.2889 - val_loss: 4.5837 - val_accuracy: 0.3000\n","Epoch 10/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.5168 - accuracy: 0.3397 - val_loss: 4.5837 - val_accuracy: 0.3000\n","Epoch 11/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.3462 - accuracy: 0.3084 - val_loss: 4.5837 - val_accuracy: 0.3000\n","Epoch 12/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.5547 - accuracy: 0.3319 - val_loss: 4.5837 - val_accuracy: 0.3000\n","Epoch 13/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.2562 - accuracy: 0.3514 - val_loss: 4.5837 - val_accuracy: 0.3000\n","Epoch 14/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.4342 - accuracy: 0.3162 - val_loss: 4.5837 - val_accuracy: 0.3000\n","Epoch 15/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.4613 - accuracy: 0.3045 - val_loss: 4.5837 - val_accuracy: 0.3000\n","Epoch 16/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.5188 - accuracy: 0.3084 - val_loss: 4.5837 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 196ms/step - loss: 2.1055 - accuracy: 0.5556\n","Epoch 1/100\n","3/3 [==============================] - 1s 119ms/step - loss: 2.7424 - accuracy: 0.4270 - val_loss: 2.6033 - val_accuracy: 0.5000\n","Epoch 2/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.5485 - accuracy: 0.5640 - val_loss: 1.7930 - val_accuracy: 0.6000\n","Epoch 3/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.1866 - accuracy: 0.6231 - val_loss: 1.7963 - val_accuracy: 0.6000\n","Epoch 4/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.5463 - accuracy: 0.6442 - val_loss: 1.7838 - val_accuracy: 0.6000\n","Epoch 5/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.8132 - accuracy: 0.6849 - val_loss: 2.4326 - val_accuracy: 0.6000\n","Epoch 6/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.2102 - accuracy: 0.6838 - val_loss: 2.3513 - val_accuracy: 0.6000\n","Epoch 7/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.8333 - accuracy: 0.7060 - val_loss: 3.6081 - val_accuracy: 0.6000\n","Epoch 8/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.0989 - accuracy: 0.6709 - val_loss: 3.5705 - val_accuracy: 0.6000\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.8182 - accuracy: 0.6787 - val_loss: 3.5243 - val_accuracy: 0.6000\n","Epoch 10/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.0150 - accuracy: 0.6998 - val_loss: 3.5263 - val_accuracy: 0.5500\n","Epoch 11/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.7276 - accuracy: 0.7695 - val_loss: 4.0646 - val_accuracy: 0.5500\n","Epoch 12/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.5607 - accuracy: 0.7823 - val_loss: 3.9447 - val_accuracy: 0.5500\n","Epoch 13/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.7656 - accuracy: 0.7311 - val_loss: 3.4699 - val_accuracy: 0.5000\n","Epoch 14/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.8536 - accuracy: 0.7378 - val_loss: 2.8989 - val_accuracy: 0.5500\n","1/1 [==============================] - 0s 200ms/step - loss: 5.6046 - accuracy: 0.1111\n","Epoch 1/100\n","3/3 [==============================] - 1s 124ms/step - loss: 6.8356 - accuracy: 0.2950 - val_loss: 5.1356 - val_accuracy: 0.5500\n","Epoch 2/100\n","3/3 [==============================] - 0s 39ms/step - loss: 5.8933 - accuracy: 0.3369 - val_loss: 5.1053 - val_accuracy: 0.5500\n","Epoch 3/100\n","3/3 [==============================] - 0s 39ms/step - loss: 6.0665 - accuracy: 0.3252 - val_loss: 5.0770 - val_accuracy: 0.5500\n","Epoch 4/100\n","3/3 [==============================] - 0s 41ms/step - loss: 5.7022 - accuracy: 0.3291 - val_loss: 5.0321 - val_accuracy: 0.5500\n","Epoch 5/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.8091 - accuracy: 0.3436 - val_loss: 5.0794 - val_accuracy: 0.5500\n","Epoch 6/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.4127 - accuracy: 0.3515 - val_loss: 5.0468 - val_accuracy: 0.5500\n","Epoch 7/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.6484 - accuracy: 0.3621 - val_loss: 5.0000 - val_accuracy: 0.6000\n","Epoch 8/100\n","3/3 [==============================] - 0s 39ms/step - loss: 5.6107 - accuracy: 0.3582 - val_loss: 4.4053 - val_accuracy: 0.6000\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.3908 - accuracy: 0.3348 - val_loss: 4.3946 - val_accuracy: 0.6000\n","Epoch 10/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.2616 - accuracy: 0.3533 - val_loss: 4.3814 - val_accuracy: 0.6000\n","Epoch 11/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.1026 - accuracy: 0.3689 - val_loss: 4.3701 - val_accuracy: 0.6000\n","Epoch 12/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.2595 - accuracy: 0.3415 - val_loss: 4.3594 - val_accuracy: 0.6000\n","Epoch 13/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.2262 - accuracy: 0.3689 - val_loss: 4.3417 - val_accuracy: 0.5500\n","Epoch 14/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.3644 - accuracy: 0.3728 - val_loss: 4.3183 - val_accuracy: 0.5500\n","Epoch 15/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.8899 - accuracy: 0.3845 - val_loss: 4.2911 - val_accuracy: 0.5500\n","Epoch 16/100\n","3/3 [==============================] - 0s 41ms/step - loss: 4.8530 - accuracy: 0.4225 - val_loss: 5.0354 - val_accuracy: 0.4000\n","Epoch 17/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.8730 - accuracy: 0.4069 - val_loss: 4.8924 - val_accuracy: 0.3500\n","Epoch 18/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.2691 - accuracy: 0.4293 - val_loss: 4.3892 - val_accuracy: 0.3500\n","Epoch 19/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.4736 - accuracy: 0.3941 - val_loss: 3.7625 - val_accuracy: 0.3500\n","Epoch 20/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.5322 - accuracy: 0.3340 - val_loss: 6.2667 - val_accuracy: 0.5000\n","Epoch 21/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.7277 - accuracy: 0.2971 - val_loss: 6.2676 - val_accuracy: 0.5000\n","Epoch 22/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.3544 - accuracy: 0.2893 - val_loss: 6.2683 - val_accuracy: 0.5000\n","Epoch 23/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.9883 - accuracy: 0.2815 - val_loss: 6.2697 - val_accuracy: 0.5000\n","Epoch 24/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.5004 - accuracy: 0.2854 - val_loss: 6.2704 - val_accuracy: 0.5000\n","Epoch 25/100\n","3/3 [==============================] - 0s 36ms/step - loss: 7.7432 - accuracy: 0.3010 - val_loss: 6.2707 - val_accuracy: 0.5000\n","Epoch 26/100\n","3/3 [==============================] - 0s 40ms/step - loss: 8.0927 - accuracy: 0.2658 - val_loss: 6.2712 - val_accuracy: 0.5000\n","Epoch 27/100\n","3/3 [==============================] - 0s 36ms/step - loss: 7.0574 - accuracy: 0.2971 - val_loss: 4.8068 - val_accuracy: 0.5000\n","Epoch 28/100\n","3/3 [==============================] - 0s 37ms/step - loss: 6.0412 - accuracy: 0.3291 - val_loss: 3.3292 - val_accuracy: 0.6000\n","Epoch 29/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.0646 - accuracy: 0.4922 - val_loss: 3.3293 - val_accuracy: 0.6000\n","Epoch 30/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.0883 - accuracy: 0.5000 - val_loss: 3.3293 - val_accuracy: 0.6000\n","Epoch 31/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.1515 - accuracy: 0.4883 - val_loss: 3.3293 - val_accuracy: 0.6000\n","Epoch 32/100\n","3/3 [==============================] - 0s 47ms/step - loss: 3.9540 - accuracy: 0.4727 - val_loss: 3.3293 - val_accuracy: 0.6000\n","Epoch 33/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.6801 - accuracy: 0.4883 - val_loss: 3.3294 - val_accuracy: 0.6000\n","Epoch 34/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.3140 - accuracy: 0.5352 - val_loss: 3.3294 - val_accuracy: 0.6000\n","Epoch 35/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.2059 - accuracy: 0.4688 - val_loss: 3.3294 - val_accuracy: 0.6000\n","Epoch 36/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.8571 - accuracy: 0.5000 - val_loss: 3.3294 - val_accuracy: 0.6000\n","Epoch 37/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.6989 - accuracy: 0.4961 - val_loss: 3.3294 - val_accuracy: 0.6000\n","Epoch 38/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.5211 - accuracy: 0.5312 - val_loss: 3.3294 - val_accuracy: 0.6000\n","1/1 [==============================] - 0s 216ms/step - loss: 1.7749 - accuracy: 0.2632\n","Epoch 1/100\n","3/3 [==============================] - 1s 163ms/step - loss: 6.0905 - accuracy: 0.3280 - val_loss: 5.8470 - val_accuracy: 0.4500\n","Epoch 2/100\n","3/3 [==============================] - 0s 39ms/step - loss: 5.3421 - accuracy: 0.3515 - val_loss: 5.8178 - val_accuracy: 0.4500\n","Epoch 3/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.0477 - accuracy: 0.3319 - val_loss: 5.1762 - val_accuracy: 0.5000\n","Epoch 4/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.3905 - accuracy: 0.3476 - val_loss: 5.8887 - val_accuracy: 0.4500\n","Epoch 5/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.0952 - accuracy: 0.3397 - val_loss: 5.9340 - val_accuracy: 0.4500\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.1033 - accuracy: 0.3465 - val_loss: 5.9352 - val_accuracy: 0.4500\n","Epoch 7/100\n","3/3 [==============================] - 0s 42ms/step - loss: 5.1924 - accuracy: 0.3845 - val_loss: 5.9360 - val_accuracy: 0.4500\n","Epoch 8/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.9020 - accuracy: 0.4499 - val_loss: 5.9342 - val_accuracy: 0.4500\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.3570 - accuracy: 0.3913 - val_loss: 5.9303 - val_accuracy: 0.4500\n","Epoch 10/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.2928 - accuracy: 0.3444 - val_loss: 5.9276 - val_accuracy: 0.4500\n","Epoch 11/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.9879 - accuracy: 0.3991 - val_loss: 5.9246 - val_accuracy: 0.4500\n","Epoch 12/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.6678 - accuracy: 0.3405 - val_loss: 5.9240 - val_accuracy: 0.4500\n","Epoch 13/100\n","3/3 [==============================] - 0s 40ms/step - loss: 5.1600 - accuracy: 0.3884 - val_loss: 5.2653 - val_accuracy: 0.4500\n","1/1 [==============================] - 0s 186ms/step - loss: 2.9609 - accuracy: 0.4211\n","Epoch 1/100\n","3/3 [==============================] - 1s 119ms/step - loss: 4.5780 - accuracy: 0.2679 - val_loss: 6.0323 - val_accuracy: 0.0500\n","Epoch 2/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.4996 - accuracy: 0.2534 - val_loss: 6.0270 - val_accuracy: 0.0500\n","Epoch 3/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.3503 - accuracy: 0.2612 - val_loss: 6.0295 - val_accuracy: 0.0500\n","Epoch 4/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.0609 - accuracy: 0.2456 - val_loss: 6.0154 - val_accuracy: 0.0500\n","Epoch 5/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.9307 - accuracy: 0.2768 - val_loss: 6.0066 - val_accuracy: 0.0500\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.0067 - accuracy: 0.2573 - val_loss: 6.0027 - val_accuracy: 0.0500\n","Epoch 7/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.3160 - accuracy: 0.2495 - val_loss: 5.9996 - val_accuracy: 0.0500\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.1482 - accuracy: 0.2690 - val_loss: 5.9908 - val_accuracy: 0.0500\n","Epoch 9/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.0134 - accuracy: 0.2534 - val_loss: 5.9878 - val_accuracy: 0.0500\n","Epoch 10/100\n","3/3 [==============================] - 0s 40ms/step - loss: 3.8684 - accuracy: 0.2417 - val_loss: 5.9822 - val_accuracy: 0.0500\n","Epoch 11/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.4706 - accuracy: 0.2299 - val_loss: 5.9794 - val_accuracy: 0.0500\n","Epoch 12/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.3192 - accuracy: 0.2260 - val_loss: 5.9784 - val_accuracy: 0.0500\n","Epoch 13/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.0440 - accuracy: 0.2378 - val_loss: 5.9755 - val_accuracy: 0.0500\n","Epoch 14/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.0416 - accuracy: 0.2612 - val_loss: 5.9730 - val_accuracy: 0.0500\n","Epoch 15/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.9154 - accuracy: 0.3081 - val_loss: 5.9709 - val_accuracy: 0.0500\n","Epoch 16/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.4975 - accuracy: 0.2495 - val_loss: 5.9688 - val_accuracy: 0.0500\n","Epoch 17/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.7033 - accuracy: 0.2456 - val_loss: 5.9654 - val_accuracy: 0.0500\n","Epoch 18/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.5137 - accuracy: 0.2875 - val_loss: 5.9615 - val_accuracy: 0.0500\n","Epoch 19/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.3499 - accuracy: 0.2640 - val_loss: 5.9590 - val_accuracy: 0.0500\n","Epoch 20/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.9654 - accuracy: 0.2836 - val_loss: 5.9548 - val_accuracy: 0.0500\n","Epoch 21/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.0223 - accuracy: 0.2445 - val_loss: 5.9531 - val_accuracy: 0.0500\n","Epoch 22/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.8820 - accuracy: 0.2367 - val_loss: 5.9510 - val_accuracy: 0.0500\n","Epoch 23/100\n","3/3 [==============================] - 0s 39ms/step - loss: 4.1760 - accuracy: 0.2523 - val_loss: 5.9487 - val_accuracy: 0.0500\n","Epoch 24/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.7855 - accuracy: 0.2758 - val_loss: 5.9441 - val_accuracy: 0.0500\n","Epoch 25/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.0804 - accuracy: 0.2679 - val_loss: 5.9404 - val_accuracy: 0.0500\n","Epoch 26/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.8293 - accuracy: 0.2758 - val_loss: 5.9374 - val_accuracy: 0.0500\n","Epoch 27/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.0078 - accuracy: 0.2679 - val_loss: 5.9328 - val_accuracy: 0.0500\n","Epoch 28/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.3376 - accuracy: 0.2562 - val_loss: 5.9294 - val_accuracy: 0.0500\n","Epoch 29/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.8286 - accuracy: 0.2679 - val_loss: 5.9284 - val_accuracy: 0.0500\n","Epoch 30/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.2013 - accuracy: 0.2797 - val_loss: 5.9270 - val_accuracy: 0.0500\n","Epoch 31/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.2508 - accuracy: 0.2679 - val_loss: 5.9254 - val_accuracy: 0.0500\n","Epoch 32/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.4758 - accuracy: 0.2562 - val_loss: 5.9229 - val_accuracy: 0.0500\n","Epoch 33/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.9988 - accuracy: 0.2797 - val_loss: 5.9208 - val_accuracy: 0.0500\n","Epoch 34/100\n","3/3 [==============================] - 0s 41ms/step - loss: 3.6365 - accuracy: 0.2601 - val_loss: 5.9185 - val_accuracy: 0.0500\n","Epoch 35/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.0368 - accuracy: 0.2914 - val_loss: 5.9166 - val_accuracy: 0.0500\n","Epoch 36/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.8798 - accuracy: 0.2836 - val_loss: 5.9145 - val_accuracy: 0.0500\n","Epoch 37/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.6380 - accuracy: 0.2640 - val_loss: 5.9123 - val_accuracy: 0.0500\n","Epoch 38/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.3408 - accuracy: 0.2719 - val_loss: 5.9104 - val_accuracy: 0.0500\n","Epoch 39/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.2909 - accuracy: 0.2981 - val_loss: 5.9080 - val_accuracy: 0.0500\n","Epoch 40/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.7026 - accuracy: 0.2903 - val_loss: 5.9065 - val_accuracy: 0.0500\n","Epoch 41/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.7372 - accuracy: 0.2786 - val_loss: 5.9044 - val_accuracy: 0.0500\n","Epoch 42/100\n","3/3 [==============================] - 0s 36ms/step - loss: 4.0311 - accuracy: 0.3020 - val_loss: 5.9027 - val_accuracy: 0.0500\n","Epoch 43/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.6967 - accuracy: 0.3020 - val_loss: 5.9006 - val_accuracy: 0.0500\n","Epoch 44/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.8240 - accuracy: 0.3138 - val_loss: 5.8989 - val_accuracy: 0.0500\n","Epoch 45/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.4406 - accuracy: 0.2825 - val_loss: 5.8979 - val_accuracy: 0.0500\n","Epoch 46/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.8669 - accuracy: 0.2513 - val_loss: 5.8962 - val_accuracy: 0.0500\n","Epoch 47/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.3201 - accuracy: 0.2864 - val_loss: 5.8949 - val_accuracy: 0.1000\n","Epoch 48/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.9584 - accuracy: 0.2981 - val_loss: 5.8940 - val_accuracy: 0.1000\n","Epoch 49/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.9047 - accuracy: 0.2903 - val_loss: 5.8922 - val_accuracy: 0.1000\n","Epoch 50/100\n","3/3 [==============================] - 0s 40ms/step - loss: 3.9297 - accuracy: 0.2719 - val_loss: 5.8901 - val_accuracy: 0.1000\n","Epoch 51/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.8726 - accuracy: 0.2836 - val_loss: 5.8883 - val_accuracy: 0.1000\n","Epoch 52/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.0591 - accuracy: 0.2679 - val_loss: 5.8864 - val_accuracy: 0.1000\n","Epoch 53/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.2330 - accuracy: 0.2797 - val_loss: 5.8830 - val_accuracy: 0.1000\n","Epoch 54/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.8732 - accuracy: 0.2797 - val_loss: 5.8811 - val_accuracy: 0.1000\n","Epoch 55/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.3273 - accuracy: 0.2640 - val_loss: 5.8804 - val_accuracy: 0.1000\n","Epoch 56/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.1687 - accuracy: 0.2758 - val_loss: 5.8774 - val_accuracy: 0.1000\n","Epoch 57/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.1253 - accuracy: 0.2484 - val_loss: 5.8765 - val_accuracy: 0.1000\n","Epoch 58/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.6978 - accuracy: 0.2523 - val_loss: 5.8749 - val_accuracy: 0.1000\n","Epoch 59/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.7575 - accuracy: 0.2914 - val_loss: 5.8733 - val_accuracy: 0.1000\n","Epoch 60/100\n","3/3 [==============================] - 0s 38ms/step - loss: 3.9777 - accuracy: 0.2836 - val_loss: 5.8709 - val_accuracy: 0.1000\n","Epoch 61/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.9366 - accuracy: 0.2445 - val_loss: 5.8696 - val_accuracy: 0.1000\n","Epoch 62/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.9242 - accuracy: 0.2875 - val_loss: 5.8682 - val_accuracy: 0.1000\n","Epoch 63/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.6764 - accuracy: 0.2797 - val_loss: 5.8672 - val_accuracy: 0.1000\n","Epoch 64/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.2326 - accuracy: 0.2640 - val_loss: 5.8656 - val_accuracy: 0.1000\n","Epoch 65/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.0106 - accuracy: 0.2679 - val_loss: 5.8642 - val_accuracy: 0.1000\n","Epoch 66/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.9059 - accuracy: 0.2456 - val_loss: 5.8623 - val_accuracy: 0.1000\n","Epoch 67/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.1689 - accuracy: 0.2601 - val_loss: 5.8617 - val_accuracy: 0.1000\n","Epoch 68/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.1282 - accuracy: 0.2612 - val_loss: 5.8596 - val_accuracy: 0.1000\n","Epoch 69/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.2588 - accuracy: 0.2495 - val_loss: 5.8583 - val_accuracy: 0.1000\n","Epoch 70/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.1803 - accuracy: 0.2719 - val_loss: 5.8565 - val_accuracy: 0.1000\n","Epoch 71/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.7317 - accuracy: 0.2612 - val_loss: 5.8548 - val_accuracy: 0.1000\n","Epoch 72/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.1415 - accuracy: 0.2406 - val_loss: 5.8530 - val_accuracy: 0.1000\n","Epoch 73/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.0249 - accuracy: 0.2719 - val_loss: 5.8522 - val_accuracy: 0.1000\n","Epoch 74/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.6231 - accuracy: 0.2640 - val_loss: 5.8492 - val_accuracy: 0.1000\n","Epoch 75/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.9367 - accuracy: 0.3031 - val_loss: 5.8482 - val_accuracy: 0.1000\n","Epoch 76/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.9388 - accuracy: 0.2758 - val_loss: 5.8460 - val_accuracy: 0.1000\n","Epoch 77/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.8263 - accuracy: 0.2640 - val_loss: 5.8430 - val_accuracy: 0.1000\n","Epoch 78/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.1713 - accuracy: 0.2679 - val_loss: 5.8415 - val_accuracy: 0.1000\n","Epoch 79/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.4749 - accuracy: 0.2679 - val_loss: 5.8399 - val_accuracy: 0.1000\n","Epoch 80/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.2970 - accuracy: 0.2875 - val_loss: 5.8373 - val_accuracy: 0.1000\n","Epoch 81/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.8812 - accuracy: 0.2719 - val_loss: 5.8353 - val_accuracy: 0.1500\n","Epoch 82/100\n","3/3 [==============================] - 0s 39ms/step - loss: 3.8211 - accuracy: 0.2719 - val_loss: 5.8331 - val_accuracy: 0.1500\n","Epoch 83/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.0201 - accuracy: 0.2719 - val_loss: 5.8318 - val_accuracy: 0.1500\n","Epoch 84/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.8725 - accuracy: 0.2562 - val_loss: 5.8306 - val_accuracy: 0.1500\n","Epoch 85/100\n","3/3 [==============================] - 0s 41ms/step - loss: 4.2492 - accuracy: 0.2562 - val_loss: 5.8285 - val_accuracy: 0.1500\n","Epoch 86/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.4641 - accuracy: 0.3283 - val_loss: 5.8259 - val_accuracy: 0.1500\n","Epoch 87/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.1943 - accuracy: 0.2736 - val_loss: 5.8228 - val_accuracy: 0.1500\n","Epoch 88/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.9266 - accuracy: 0.3525 - val_loss: 5.8220 - val_accuracy: 0.1500\n","Epoch 89/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.8766 - accuracy: 0.3408 - val_loss: 5.8190 - val_accuracy: 0.1500\n","Epoch 90/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.8102 - accuracy: 0.3408 - val_loss: 5.8140 - val_accuracy: 0.1500\n","Epoch 91/100\n","3/3 [==============================] - 0s 28ms/step - loss: 3.4980 - accuracy: 0.3827 - val_loss: 5.8106 - val_accuracy: 0.1500\n","Epoch 92/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.8515 - accuracy: 0.3358 - val_loss: 5.8074 - val_accuracy: 0.1500\n","Epoch 93/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.9430 - accuracy: 0.3319 - val_loss: 5.8028 - val_accuracy: 0.1500\n","Epoch 94/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.4558 - accuracy: 0.3554 - val_loss: 5.7977 - val_accuracy: 0.1500\n","Epoch 95/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.1278 - accuracy: 0.3358 - val_loss: 5.7747 - val_accuracy: 0.2000\n","Epoch 96/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.4250 - accuracy: 0.3856 - val_loss: 5.7712 - val_accuracy: 0.2000\n","Epoch 97/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.9797 - accuracy: 0.3660 - val_loss: 5.7678 - val_accuracy: 0.2000\n","Epoch 98/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.9200 - accuracy: 0.3777 - val_loss: 5.7655 - val_accuracy: 0.2000\n","Epoch 99/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.6808 - accuracy: 0.3465 - val_loss: 5.7610 - val_accuracy: 0.2000\n","Epoch 100/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.4395 - accuracy: 0.3817 - val_loss: 5.7551 - val_accuracy: 0.2000\n","1/1 [==============================] - 0s 192ms/step - loss: 2.9560 - accuracy: 0.1579\n","Epoch 1/100\n","3/3 [==============================] - 1s 158ms/step - loss: 5.3632 - accuracy: 0.1687 - val_loss: 1.7795 - val_accuracy: 0.4000\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.5774 - accuracy: 0.1843 - val_loss: 1.9474 - val_accuracy: 0.3500\n","Epoch 3/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.4119 - accuracy: 0.1777 - val_loss: 1.8591 - val_accuracy: 0.3000\n","Epoch 4/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.4799 - accuracy: 0.2250 - val_loss: 1.8450 - val_accuracy: 0.3000\n","Epoch 5/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.4261 - accuracy: 0.2133 - val_loss: 1.8508 - val_accuracy: 0.3000\n","Epoch 6/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.1838 - accuracy: 0.2016 - val_loss: 1.8486 - val_accuracy: 0.3000\n","Epoch 7/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.2044 - accuracy: 0.1731 - val_loss: 1.8462 - val_accuracy: 0.3000\n","Epoch 8/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.6175 - accuracy: 0.2160 - val_loss: 1.8441 - val_accuracy: 0.3000\n","Epoch 9/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.7924 - accuracy: 0.2356 - val_loss: 1.8433 - val_accuracy: 0.3000\n","Epoch 10/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.8572 - accuracy: 0.2239 - val_loss: 1.8419 - val_accuracy: 0.3500\n","Epoch 11/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.8536 - accuracy: 0.2094 - val_loss: 1.8439 - val_accuracy: 0.3000\n","1/1 [==============================] - 0s 197ms/step - loss: 3.5643 - accuracy: 0.2778\n","Epoch 1/100\n","3/3 [==============================] - 1s 161ms/step - loss: 13.1934 - accuracy: 0.1381 - val_loss: 13.8194 - val_accuracy: 0.1500\n","Epoch 2/100\n","3/3 [==============================] - 0s 36ms/step - loss: 13.2846 - accuracy: 0.1225 - val_loss: 13.8182 - val_accuracy: 0.1000\n","Epoch 3/100\n","3/3 [==============================] - 0s 33ms/step - loss: 13.0065 - accuracy: 0.1342 - val_loss: 13.8159 - val_accuracy: 0.1000\n","Epoch 4/100\n","3/3 [==============================] - 0s 30ms/step - loss: 12.5022 - accuracy: 0.1420 - val_loss: 13.8149 - val_accuracy: 0.1000\n","Epoch 5/100\n","3/3 [==============================] - 0s 31ms/step - loss: 13.0258 - accuracy: 0.1147 - val_loss: 13.8139 - val_accuracy: 0.1000\n","Epoch 6/100\n","3/3 [==============================] - 0s 32ms/step - loss: 13.1610 - accuracy: 0.1147 - val_loss: 13.8129 - val_accuracy: 0.1000\n","Epoch 7/100\n","3/3 [==============================] - 0s 33ms/step - loss: 13.3795 - accuracy: 0.1147 - val_loss: 13.8117 - val_accuracy: 0.1000\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 13.1478 - accuracy: 0.1420 - val_loss: 13.8107 - val_accuracy: 0.1000\n","Epoch 9/100\n","3/3 [==============================] - 0s 29ms/step - loss: 13.0119 - accuracy: 0.1186 - val_loss: 13.8092 - val_accuracy: 0.1000\n","Epoch 10/100\n","3/3 [==============================] - 0s 31ms/step - loss: 12.6337 - accuracy: 0.1420 - val_loss: 13.8076 - val_accuracy: 0.1000\n","Epoch 11/100\n","3/3 [==============================] - 0s 32ms/step - loss: 12.9836 - accuracy: 0.1069 - val_loss: 13.8049 - val_accuracy: 0.1000\n","Epoch 12/100\n","3/3 [==============================] - 0s 37ms/step - loss: 12.6277 - accuracy: 0.1264 - val_loss: 13.8024 - val_accuracy: 0.1000\n","Epoch 13/100\n","3/3 [==============================] - 0s 32ms/step - loss: 12.8687 - accuracy: 0.1253 - val_loss: 13.7704 - val_accuracy: 0.1000\n","Epoch 14/100\n","3/3 [==============================] - 0s 36ms/step - loss: 12.7641 - accuracy: 0.1526 - val_loss: 13.7697 - val_accuracy: 0.1000\n","Epoch 15/100\n","3/3 [==============================] - 0s 31ms/step - loss: 12.5433 - accuracy: 0.1487 - val_loss: 13.7684 - val_accuracy: 0.1000\n","Epoch 16/100\n","3/3 [==============================] - 0s 35ms/step - loss: 12.7086 - accuracy: 0.1253 - val_loss: 13.7756 - val_accuracy: 0.1000\n","Epoch 17/100\n","3/3 [==============================] - 0s 29ms/step - loss: 12.3282 - accuracy: 0.1604 - val_loss: 13.7746 - val_accuracy: 0.1000\n","Epoch 18/100\n","3/3 [==============================] - 0s 31ms/step - loss: 12.4334 - accuracy: 0.1174 - val_loss: 13.7736 - val_accuracy: 0.1000\n","Epoch 19/100\n","3/3 [==============================] - 0s 33ms/step - loss: 12.1307 - accuracy: 0.1526 - val_loss: 13.7725 - val_accuracy: 0.1000\n","Epoch 20/100\n","3/3 [==============================] - 0s 33ms/step - loss: 12.7584 - accuracy: 0.1096 - val_loss: 13.7712 - val_accuracy: 0.1000\n","Epoch 21/100\n","3/3 [==============================] - 0s 31ms/step - loss: 12.2442 - accuracy: 0.1409 - val_loss: 13.7696 - val_accuracy: 0.1000\n","Epoch 22/100\n","3/3 [==============================] - 0s 35ms/step - loss: 11.9718 - accuracy: 0.1526 - val_loss: 13.7689 - val_accuracy: 0.1000\n","Epoch 23/100\n","3/3 [==============================] - 0s 32ms/step - loss: 12.6181 - accuracy: 0.1214 - val_loss: 13.7698 - val_accuracy: 0.1000\n","Epoch 24/100\n","3/3 [==============================] - 0s 36ms/step - loss: 12.5791 - accuracy: 0.1253 - val_loss: 13.7681 - val_accuracy: 0.1000\n","Epoch 25/100\n","3/3 [==============================] - 0s 34ms/step - loss: 12.3075 - accuracy: 0.1214 - val_loss: 13.7664 - val_accuracy: 0.1000\n","Epoch 26/100\n","3/3 [==============================] - 0s 33ms/step - loss: 12.1440 - accuracy: 0.1253 - val_loss: 13.7643 - val_accuracy: 0.1000\n","Epoch 27/100\n","3/3 [==============================] - 0s 29ms/step - loss: 12.1232 - accuracy: 0.1409 - val_loss: 13.7620 - val_accuracy: 0.1000\n","Epoch 28/100\n","3/3 [==============================] - 0s 34ms/step - loss: 12.4751 - accuracy: 0.1174 - val_loss: 13.7605 - val_accuracy: 0.1000\n","Epoch 29/100\n","3/3 [==============================] - 0s 35ms/step - loss: 11.8328 - accuracy: 0.1487 - val_loss: 13.7582 - val_accuracy: 0.1000\n","Epoch 30/100\n","3/3 [==============================] - 0s 30ms/step - loss: 12.1191 - accuracy: 0.1174 - val_loss: 13.7549 - val_accuracy: 0.1000\n","Epoch 31/100\n","3/3 [==============================] - 0s 30ms/step - loss: 12.0347 - accuracy: 0.1409 - val_loss: 13.7494 - val_accuracy: 0.1000\n","Epoch 32/100\n","3/3 [==============================] - 0s 30ms/step - loss: 11.7125 - accuracy: 0.1487 - val_loss: 13.7474 - val_accuracy: 0.1000\n","Epoch 33/100\n","3/3 [==============================] - 0s 30ms/step - loss: 12.4270 - accuracy: 0.1057 - val_loss: 13.7453 - val_accuracy: 0.1000\n","Epoch 34/100\n","3/3 [==============================] - 0s 32ms/step - loss: 11.7788 - accuracy: 0.1487 - val_loss: 13.7420 - val_accuracy: 0.1000\n","Epoch 35/100\n","3/3 [==============================] - 0s 32ms/step - loss: 11.1775 - accuracy: 0.1370 - val_loss: 13.7406 - val_accuracy: 0.1000\n","Epoch 36/100\n","3/3 [==============================] - 0s 35ms/step - loss: 11.6218 - accuracy: 0.1292 - val_loss: 13.7390 - val_accuracy: 0.1000\n","Epoch 37/100\n","3/3 [==============================] - 0s 32ms/step - loss: 11.4690 - accuracy: 0.1409 - val_loss: 13.7373 - val_accuracy: 0.1000\n","Epoch 38/100\n","3/3 [==============================] - 0s 37ms/step - loss: 11.7784 - accuracy: 0.1409 - val_loss: 13.7359 - val_accuracy: 0.1000\n","Epoch 39/100\n","3/3 [==============================] - 0s 39ms/step - loss: 11.9997 - accuracy: 0.1214 - val_loss: 13.7347 - val_accuracy: 0.1000\n","Epoch 40/100\n","3/3 [==============================] - 0s 35ms/step - loss: 11.6477 - accuracy: 0.1253 - val_loss: 13.7334 - val_accuracy: 0.1000\n","Epoch 41/100\n","3/3 [==============================] - 0s 33ms/step - loss: 12.2601 - accuracy: 0.1135 - val_loss: 13.7316 - val_accuracy: 0.1000\n","Epoch 42/100\n","3/3 [==============================] - 0s 32ms/step - loss: 11.8036 - accuracy: 0.1331 - val_loss: 13.7298 - val_accuracy: 0.1000\n","Epoch 43/100\n","3/3 [==============================] - 0s 35ms/step - loss: 11.4577 - accuracy: 0.1604 - val_loss: 13.7285 - val_accuracy: 0.1000\n","Epoch 44/100\n","3/3 [==============================] - 0s 30ms/step - loss: 11.2411 - accuracy: 0.1370 - val_loss: 13.7272 - val_accuracy: 0.1000\n","Epoch 45/100\n","3/3 [==============================] - 0s 31ms/step - loss: 11.6908 - accuracy: 0.1370 - val_loss: 13.7256 - val_accuracy: 0.1000\n","Epoch 46/100\n","3/3 [==============================] - 0s 30ms/step - loss: 10.8452 - accuracy: 0.1448 - val_loss: 13.7244 - val_accuracy: 0.1000\n","Epoch 47/100\n","3/3 [==============================] - 0s 33ms/step - loss: 11.4105 - accuracy: 0.1253 - val_loss: 13.7230 - val_accuracy: 0.1000\n","Epoch 48/100\n","3/3 [==============================] - 0s 31ms/step - loss: 11.2320 - accuracy: 0.1409 - val_loss: 13.7214 - val_accuracy: 0.1000\n","Epoch 49/100\n","3/3 [==============================] - 0s 34ms/step - loss: 11.9016 - accuracy: 0.1135 - val_loss: 13.7198 - val_accuracy: 0.1000\n","Epoch 50/100\n","3/3 [==============================] - 0s 31ms/step - loss: 11.2268 - accuracy: 0.1487 - val_loss: 13.7180 - val_accuracy: 0.1000\n","Epoch 51/100\n","3/3 [==============================] - 0s 30ms/step - loss: 11.1359 - accuracy: 0.1409 - val_loss: 13.7166 - val_accuracy: 0.1000\n","Epoch 52/100\n","3/3 [==============================] - 0s 38ms/step - loss: 11.6417 - accuracy: 0.1409 - val_loss: 13.7151 - val_accuracy: 0.1000\n","Epoch 53/100\n","3/3 [==============================] - 0s 29ms/step - loss: 11.3645 - accuracy: 0.1331 - val_loss: 13.7129 - val_accuracy: 0.1000\n","Epoch 54/100\n","3/3 [==============================] - 0s 33ms/step - loss: 11.6667 - accuracy: 0.1214 - val_loss: 13.7112 - val_accuracy: 0.1000\n","Epoch 55/100\n","3/3 [==============================] - 0s 30ms/step - loss: 11.4473 - accuracy: 0.1253 - val_loss: 13.7094 - val_accuracy: 0.1000\n","Epoch 56/100\n","3/3 [==============================] - 0s 29ms/step - loss: 11.5905 - accuracy: 0.1331 - val_loss: 13.7066 - val_accuracy: 0.1000\n","Epoch 57/100\n","3/3 [==============================] - 0s 30ms/step - loss: 11.4448 - accuracy: 0.1253 - val_loss: 13.7033 - val_accuracy: 0.1000\n","Epoch 58/100\n","3/3 [==============================] - 0s 29ms/step - loss: 11.0760 - accuracy: 0.1487 - val_loss: 13.7010 - val_accuracy: 0.1000\n","Epoch 59/100\n","3/3 [==============================] - 0s 30ms/step - loss: 11.1911 - accuracy: 0.1292 - val_loss: 13.6989 - val_accuracy: 0.1000\n","Epoch 60/100\n","3/3 [==============================] - 0s 32ms/step - loss: 11.0671 - accuracy: 0.1526 - val_loss: 13.6961 - val_accuracy: 0.1000\n","Epoch 61/100\n","3/3 [==============================] - 0s 30ms/step - loss: 11.1269 - accuracy: 0.1370 - val_loss: 13.6927 - val_accuracy: 0.1000\n","Epoch 62/100\n","3/3 [==============================] - 0s 30ms/step - loss: 10.6376 - accuracy: 0.1721 - val_loss: 13.6910 - val_accuracy: 0.1000\n","Epoch 63/100\n","3/3 [==============================] - 0s 29ms/step - loss: 11.4250 - accuracy: 0.1292 - val_loss: 13.6892 - val_accuracy: 0.1000\n","Epoch 64/100\n","3/3 [==============================] - 0s 29ms/step - loss: 11.1926 - accuracy: 0.1487 - val_loss: 13.6869 - val_accuracy: 0.1000\n","Epoch 65/100\n","3/3 [==============================] - 0s 29ms/step - loss: 10.7111 - accuracy: 0.1370 - val_loss: 13.6837 - val_accuracy: 0.1000\n","Epoch 66/100\n","3/3 [==============================] - 0s 40ms/step - loss: 10.9267 - accuracy: 0.1174 - val_loss: 13.6816 - val_accuracy: 0.1000\n","Epoch 67/100\n","3/3 [==============================] - 0s 31ms/step - loss: 11.3361 - accuracy: 0.1135 - val_loss: 13.6792 - val_accuracy: 0.1000\n","Epoch 68/100\n","3/3 [==============================] - 0s 32ms/step - loss: 11.5700 - accuracy: 0.1214 - val_loss: 13.6763 - val_accuracy: 0.1000\n","Epoch 69/100\n","3/3 [==============================] - 0s 33ms/step - loss: 10.3521 - accuracy: 0.1526 - val_loss: 13.6730 - val_accuracy: 0.1000\n","Epoch 70/100\n","3/3 [==============================] - 0s 31ms/step - loss: 10.6481 - accuracy: 0.1331 - val_loss: 13.6669 - val_accuracy: 0.1000\n","Epoch 71/100\n","3/3 [==============================] - 0s 36ms/step - loss: 9.5831 - accuracy: 0.1487 - val_loss: 13.6658 - val_accuracy: 0.1000\n","Epoch 72/100\n","3/3 [==============================] - 0s 32ms/step - loss: 10.6459 - accuracy: 0.1214 - val_loss: 13.6646 - val_accuracy: 0.1000\n","Epoch 73/100\n","3/3 [==============================] - 0s 31ms/step - loss: 10.0133 - accuracy: 0.1526 - val_loss: 13.6634 - val_accuracy: 0.1000\n","Epoch 74/100\n","3/3 [==============================] - 0s 32ms/step - loss: 10.2799 - accuracy: 0.1214 - val_loss: 13.6622 - val_accuracy: 0.1000\n","Epoch 75/100\n","3/3 [==============================] - 0s 32ms/step - loss: 10.6324 - accuracy: 0.1448 - val_loss: 13.6606 - val_accuracy: 0.1000\n","Epoch 76/100\n","3/3 [==============================] - 0s 35ms/step - loss: 10.2860 - accuracy: 0.1448 - val_loss: 13.6584 - val_accuracy: 0.1000\n","Epoch 77/100\n","3/3 [==============================] - 0s 32ms/step - loss: 10.8893 - accuracy: 0.1331 - val_loss: 13.6535 - val_accuracy: 0.1000\n","Epoch 78/100\n","3/3 [==============================] - 0s 32ms/step - loss: 10.2350 - accuracy: 0.1135 - val_loss: 13.6523 - val_accuracy: 0.1000\n","Epoch 79/100\n","3/3 [==============================] - 0s 45ms/step - loss: 10.4898 - accuracy: 0.1135 - val_loss: 13.6516 - val_accuracy: 0.1000\n","Epoch 80/100\n","3/3 [==============================] - 0s 33ms/step - loss: 9.7238 - accuracy: 0.1487 - val_loss: 13.6510 - val_accuracy: 0.1000\n","Epoch 81/100\n","3/3 [==============================] - 0s 33ms/step - loss: 10.3412 - accuracy: 0.1253 - val_loss: 13.6501 - val_accuracy: 0.1000\n","Epoch 82/100\n","3/3 [==============================] - 0s 32ms/step - loss: 10.1334 - accuracy: 0.1214 - val_loss: 13.6483 - val_accuracy: 0.1000\n","Epoch 83/100\n","3/3 [==============================] - 0s 30ms/step - loss: 9.6995 - accuracy: 0.1487 - val_loss: 13.6469 - val_accuracy: 0.1000\n","Epoch 84/100\n","3/3 [==============================] - 0s 31ms/step - loss: 9.8510 - accuracy: 0.1448 - val_loss: 13.6441 - val_accuracy: 0.1000\n","Epoch 85/100\n","3/3 [==============================] - 0s 30ms/step - loss: 9.6080 - accuracy: 0.1135 - val_loss: 13.6428 - val_accuracy: 0.1000\n","Epoch 86/100\n","3/3 [==============================] - 0s 35ms/step - loss: 9.4301 - accuracy: 0.1370 - val_loss: 13.6416 - val_accuracy: 0.1000\n","Epoch 87/100\n","3/3 [==============================] - 0s 32ms/step - loss: 9.9484 - accuracy: 0.1135 - val_loss: 13.6403 - val_accuracy: 0.1000\n","Epoch 88/100\n","3/3 [==============================] - 0s 31ms/step - loss: 10.1393 - accuracy: 0.1487 - val_loss: 13.6392 - val_accuracy: 0.1000\n","Epoch 89/100\n","3/3 [==============================] - 0s 32ms/step - loss: 9.8700 - accuracy: 0.1370 - val_loss: 13.6379 - val_accuracy: 0.1000\n","Epoch 90/100\n","3/3 [==============================] - 0s 31ms/step - loss: 9.4200 - accuracy: 0.1370 - val_loss: 13.6367 - val_accuracy: 0.1000\n","Epoch 91/100\n","3/3 [==============================] - 0s 33ms/step - loss: 9.8467 - accuracy: 0.1253 - val_loss: 13.6352 - val_accuracy: 0.1000\n","Epoch 92/100\n","3/3 [==============================] - 0s 40ms/step - loss: 9.9592 - accuracy: 0.1292 - val_loss: 13.6332 - val_accuracy: 0.1000\n","Epoch 93/100\n","3/3 [==============================] - 0s 38ms/step - loss: 10.4504 - accuracy: 0.1174 - val_loss: 13.6314 - val_accuracy: 0.1000\n","Epoch 94/100\n","3/3 [==============================] - 0s 31ms/step - loss: 10.1133 - accuracy: 0.1253 - val_loss: 13.6287 - val_accuracy: 0.1000\n","Epoch 95/100\n","3/3 [==============================] - 0s 31ms/step - loss: 10.1120 - accuracy: 0.1135 - val_loss: 13.6267 - val_accuracy: 0.1000\n","Epoch 96/100\n","3/3 [==============================] - 0s 33ms/step - loss: 9.7572 - accuracy: 0.1409 - val_loss: 13.6244 - val_accuracy: 0.1000\n","Epoch 97/100\n","3/3 [==============================] - 0s 31ms/step - loss: 9.4212 - accuracy: 0.1526 - val_loss: 13.6221 - val_accuracy: 0.1000\n","Epoch 98/100\n","3/3 [==============================] - 0s 29ms/step - loss: 9.6722 - accuracy: 0.1370 - val_loss: 13.6197 - val_accuracy: 0.1000\n","Epoch 99/100\n","3/3 [==============================] - 0s 30ms/step - loss: 9.7370 - accuracy: 0.1214 - val_loss: 13.6177 - val_accuracy: 0.1000\n","Epoch 100/100\n","3/3 [==============================] - 0s 31ms/step - loss: 9.5281 - accuracy: 0.1174 - val_loss: 13.6151 - val_accuracy: 0.1000\n","1/1 [==============================] - 0s 199ms/step - loss: 7.6377 - accuracy: 0.2222\n","Epoch 1/100\n","3/3 [==============================] - 1s 149ms/step - loss: 10.6354 - accuracy: 0.1542 - val_loss: 5.4634 - val_accuracy: 0.3500\n","Epoch 2/100\n","3/3 [==============================] - 0s 35ms/step - loss: 6.4476 - accuracy: 0.2175 - val_loss: 4.1457 - val_accuracy: 0.3000\n","Epoch 3/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.9602 - accuracy: 0.1795 - val_loss: 4.0067 - val_accuracy: 0.2500\n","Epoch 4/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.0330 - accuracy: 0.2370 - val_loss: 4.3068 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 42ms/step - loss: 4.4370 - accuracy: 0.1670 - val_loss: 5.0587 - val_accuracy: 0.1500\n","Epoch 6/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.1944 - accuracy: 0.2388 - val_loss: 2.7535 - val_accuracy: 0.3500\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.7323 - accuracy: 0.3049 - val_loss: 2.7713 - val_accuracy: 0.3500\n","Epoch 8/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.2161 - accuracy: 0.3497 - val_loss: 2.7638 - val_accuracy: 0.3500\n","Epoch 9/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.9338 - accuracy: 0.3028 - val_loss: 2.7602 - val_accuracy: 0.3500\n","Epoch 10/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.0734 - accuracy: 0.3340 - val_loss: 2.7586 - val_accuracy: 0.3500\n","Epoch 11/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.6918 - accuracy: 0.3340 - val_loss: 2.7585 - val_accuracy: 0.3500\n","Epoch 12/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.5851 - accuracy: 0.3184 - val_loss: 2.7584 - val_accuracy: 0.3500\n","Epoch 13/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.2758 - accuracy: 0.3223 - val_loss: 2.7582 - val_accuracy: 0.3500\n","Epoch 14/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.5884 - accuracy: 0.3340 - val_loss: 2.7581 - val_accuracy: 0.3500\n","Epoch 15/100\n","3/3 [==============================] - 0s 39ms/step - loss: 3.8377 - accuracy: 0.2911 - val_loss: 2.7580 - val_accuracy: 0.3500\n","Epoch 16/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.7483 - accuracy: 0.3340 - val_loss: 2.7580 - val_accuracy: 0.3500\n","1/1 [==============================] - 0s 176ms/step - loss: 2.0294 - accuracy: 0.1579\n","Epoch 1/100\n","3/3 [==============================] - 1s 149ms/step - loss: 7.4643 - accuracy: 0.3117 - val_loss: 9.9293 - val_accuracy: 0.3000\n","Epoch 2/100\n","3/3 [==============================] - 0s 41ms/step - loss: 8.0557 - accuracy: 0.3738 - val_loss: 10.0710 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.3838 - accuracy: 0.3262 - val_loss: 9.3992 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.1669 - accuracy: 0.3244 - val_loss: 9.3949 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 31ms/step - loss: 5.7354 - accuracy: 0.2971 - val_loss: 5.5416 - val_accuracy: 0.1500\n","Epoch 6/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.8423 - accuracy: 0.2747 - val_loss: 5.5459 - val_accuracy: 0.1500\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.0607 - accuracy: 0.2942 - val_loss: 5.5476 - val_accuracy: 0.1500\n","Epoch 8/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.0106 - accuracy: 0.2708 - val_loss: 5.5476 - val_accuracy: 0.1500\n","Epoch 9/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.3143 - accuracy: 0.2591 - val_loss: 5.5473 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.4424 - accuracy: 0.2708 - val_loss: 5.5473 - val_accuracy: 0.1500\n","Epoch 11/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.4614 - accuracy: 0.2825 - val_loss: 5.5472 - val_accuracy: 0.1500\n","Epoch 12/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.9661 - accuracy: 0.2903 - val_loss: 5.5472 - val_accuracy: 0.1500\n","Epoch 13/100\n","3/3 [==============================] - 0s 40ms/step - loss: 3.9821 - accuracy: 0.2942 - val_loss: 5.5472 - val_accuracy: 0.1500\n","Epoch 14/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.3813 - accuracy: 0.2786 - val_loss: 5.5471 - val_accuracy: 0.1500\n","Epoch 15/100\n","3/3 [==============================] - 0s 40ms/step - loss: 3.7852 - accuracy: 0.3450 - val_loss: 5.5471 - val_accuracy: 0.1500\n","1/1 [==============================] - 0s 185ms/step - loss: 4.2109 - accuracy: 0.1579\n","Epoch 1/100\n","3/3 [==============================] - 1s 147ms/step - loss: 9.2193 - accuracy: 0.2125 - val_loss: 2.5675 - val_accuracy: 0.5500\n","Epoch 2/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.8193 - accuracy: 0.2747 - val_loss: 1.8884 - val_accuracy: 0.5500\n","Epoch 3/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.4069 - accuracy: 0.2807 - val_loss: 1.1987 - val_accuracy: 0.5500\n","Epoch 4/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.7162 - accuracy: 0.2466 - val_loss: 1.1886 - val_accuracy: 0.5500\n","Epoch 5/100\n","3/3 [==============================] - 0s 28ms/step - loss: 2.0550 - accuracy: 0.3010 - val_loss: 1.1697 - val_accuracy: 0.5500\n","Epoch 6/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.4214 - accuracy: 0.2736 - val_loss: 1.1663 - val_accuracy: 0.5500\n","Epoch 7/100\n","3/3 [==============================] - 0s 28ms/step - loss: 2.0763 - accuracy: 0.3205 - val_loss: 1.1619 - val_accuracy: 0.5500\n","Epoch 8/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.1220 - accuracy: 0.3127 - val_loss: 1.1658 - val_accuracy: 0.5500\n","Epoch 9/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.3818 - accuracy: 0.2815 - val_loss: 1.1735 - val_accuracy: 0.5500\n","Epoch 10/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.0800 - accuracy: 0.3038 - val_loss: 1.2092 - val_accuracy: 0.5500\n","Epoch 11/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.3609 - accuracy: 0.3234 - val_loss: 1.2555 - val_accuracy: 0.5500\n","Epoch 12/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.2964 - accuracy: 0.2882 - val_loss: 1.3454 - val_accuracy: 0.5500\n","Epoch 13/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.1149 - accuracy: 0.3195 - val_loss: 1.9027 - val_accuracy: 0.5500\n","Epoch 14/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.3599 - accuracy: 0.3117 - val_loss: 1.8985 - val_accuracy: 0.5500\n","Epoch 15/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.9752 - accuracy: 0.2854 - val_loss: 1.8983 - val_accuracy: 0.5500\n","Epoch 16/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.8760 - accuracy: 0.2971 - val_loss: 1.8982 - val_accuracy: 0.5500\n","Epoch 17/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.3354 - accuracy: 0.2697 - val_loss: 1.8979 - val_accuracy: 0.5500\n","1/1 [==============================] - 0s 175ms/step - loss: 5.6038 - accuracy: 0.3684\n","Epoch 1/100\n","3/3 [==============================] - 1s 137ms/step - loss: 7.6393 - accuracy: 0.3029 - val_loss: 6.1017 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.5446 - accuracy: 0.2466 - val_loss: 2.7356 - val_accuracy: 0.3500\n","Epoch 3/100\n","3/3 [==============================] - 0s 39ms/step - loss: 4.3738 - accuracy: 0.3468 - val_loss: 3.8716 - val_accuracy: 0.5500\n","Epoch 4/100\n","3/3 [==============================] - 0s 33ms/step - loss: 5.9968 - accuracy: 0.3519 - val_loss: 4.5691 - val_accuracy: 0.4500\n","Epoch 5/100\n","3/3 [==============================] - 0s 32ms/step - loss: 5.2041 - accuracy: 0.3942 - val_loss: 3.9020 - val_accuracy: 0.4500\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.3044 - accuracy: 0.4059 - val_loss: 3.9015 - val_accuracy: 0.4500\n","Epoch 7/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.2049 - accuracy: 0.4098 - val_loss: 3.8958 - val_accuracy: 0.4500\n","Epoch 8/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.8214 - accuracy: 0.3512 - val_loss: 3.8768 - val_accuracy: 0.4500\n","Epoch 9/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.0356 - accuracy: 0.4371 - val_loss: 3.8730 - val_accuracy: 0.4500\n","Epoch 10/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.4942 - accuracy: 0.3981 - val_loss: 3.8699 - val_accuracy: 0.4500\n","Epoch 11/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.2934 - accuracy: 0.4332 - val_loss: 3.8681 - val_accuracy: 0.4500\n","Epoch 12/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.2117 - accuracy: 0.4410 - val_loss: 3.8681 - val_accuracy: 0.4500\n","1/1 [==============================] - 0s 197ms/step - loss: 4.2552 - accuracy: 0.3889\n","Epoch 1/100\n","3/3 [==============================] - 1s 152ms/step - loss: 7.2753 - accuracy: 0.2806 - val_loss: 7.0191 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 34ms/step - loss: 6.8837 - accuracy: 0.1737 - val_loss: 4.1458 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.3293 - accuracy: 0.2305 - val_loss: 4.1703 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.8616 - accuracy: 0.2232 - val_loss: 4.1622 - val_accuracy: 0.2000\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.4369 - accuracy: 0.2806 - val_loss: 4.1658 - val_accuracy: 0.2000\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.4637 - accuracy: 0.2884 - val_loss: 4.1632 - val_accuracy: 0.2000\n","Epoch 7/100\n","3/3 [==============================] - 0s 32ms/step - loss: 2.6786 - accuracy: 0.2432 - val_loss: 3.6570 - val_accuracy: 0.2500\n","Epoch 8/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.5500 - accuracy: 0.3569 - val_loss: 4.2531 - val_accuracy: 0.2500\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.0996 - accuracy: 0.3519 - val_loss: 3.6787 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.2230 - accuracy: 0.3507 - val_loss: 4.3066 - val_accuracy: 0.2500\n","Epoch 11/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.2015 - accuracy: 0.3703 - val_loss: 4.3224 - val_accuracy: 0.2500\n","Epoch 12/100\n","3/3 [==============================] - 0s 29ms/step - loss: 2.0458 - accuracy: 0.3859 - val_loss: 4.3562 - val_accuracy: 0.2500\n","Epoch 13/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.9111 - accuracy: 0.3820 - val_loss: 4.4241 - val_accuracy: 0.2500\n","Epoch 14/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.8389 - accuracy: 0.3703 - val_loss: 5.0903 - val_accuracy: 0.2500\n","Epoch 15/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.0773 - accuracy: 0.3781 - val_loss: 5.1183 - val_accuracy: 0.2500\n","Epoch 16/100\n","3/3 [==============================] - 0s 30ms/step - loss: 2.0296 - accuracy: 0.3742 - val_loss: 5.1271 - val_accuracy: 0.2500\n","Epoch 17/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.8150 - accuracy: 0.3703 - val_loss: 5.1329 - val_accuracy: 0.2500\n","1/1 [==============================] - 0s 186ms/step - loss: 2.6022 - accuracy: 0.4444\n","Epoch 1/100\n","3/3 [==============================] - 1s 154ms/step - loss: 5.9827 - accuracy: 0.1912 - val_loss: 4.0517 - val_accuracy: 0.3000\n","Epoch 2/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.5732 - accuracy: 0.3038 - val_loss: 5.3144 - val_accuracy: 0.3500\n","Epoch 3/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.2379 - accuracy: 0.4399 - val_loss: 1.9617 - val_accuracy: 0.4500\n","Epoch 4/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.4075 - accuracy: 0.3902 - val_loss: 1.3863 - val_accuracy: 0.4000\n","Epoch 5/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.3567 - accuracy: 0.4727 - val_loss: 1.3863 - val_accuracy: 0.4000\n","Epoch 6/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3513 - accuracy: 0.4844 - val_loss: 1.3863 - val_accuracy: 0.4000\n","Epoch 7/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.3567 - accuracy: 0.4922 - val_loss: 1.3863 - val_accuracy: 0.4000\n","Epoch 8/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3459 - accuracy: 0.5078 - val_loss: 1.3863 - val_accuracy: 0.4000\n","Epoch 9/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3621 - accuracy: 0.4609 - val_loss: 1.3863 - val_accuracy: 0.4000\n","Epoch 10/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3513 - accuracy: 0.5078 - val_loss: 1.3863 - val_accuracy: 0.4000\n","Epoch 11/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3459 - accuracy: 0.5117 - val_loss: 1.3863 - val_accuracy: 0.4000\n","Epoch 12/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.3459 - accuracy: 0.4805 - val_loss: 1.3863 - val_accuracy: 0.4000\n","Epoch 13/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3351 - accuracy: 0.5195 - val_loss: 1.3863 - val_accuracy: 0.4000\n","Epoch 14/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.3459 - accuracy: 0.5195 - val_loss: 1.3863 - val_accuracy: 0.4000\n","1/1 [==============================] - 0s 195ms/step - loss: 1.3863 - accuracy: 0.1579\n","Epoch 1/100\n","3/3 [==============================] - 1s 151ms/step - loss: 5.0048 - accuracy: 0.3067 - val_loss: 2.7104 - val_accuracy: 0.6500\n","Epoch 2/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.8513 - accuracy: 0.4136 - val_loss: 2.7104 - val_accuracy: 0.6500\n","Epoch 3/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.6624 - accuracy: 0.3863 - val_loss: 2.7104 - val_accuracy: 0.6500\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.6624 - accuracy: 0.4175 - val_loss: 2.7104 - val_accuracy: 0.6500\n","Epoch 5/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.9143 - accuracy: 0.3746 - val_loss: 2.7104 - val_accuracy: 0.6500\n","Epoch 6/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.1661 - accuracy: 0.4058 - val_loss: 2.7104 - val_accuracy: 0.6500\n","Epoch 7/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.9772 - accuracy: 0.3902 - val_loss: 2.7104 - val_accuracy: 0.6500\n","Epoch 8/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.6624 - accuracy: 0.4058 - val_loss: 2.7104 - val_accuracy: 0.6500\n","Epoch 9/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.9143 - accuracy: 0.3941 - val_loss: 2.7104 - val_accuracy: 0.6500\n","Epoch 10/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.7884 - accuracy: 0.4019 - val_loss: 2.7104 - val_accuracy: 0.6500\n","Epoch 11/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.9772 - accuracy: 0.4410 - val_loss: 2.7104 - val_accuracy: 0.6500\n","1/1 [==============================] - 0s 212ms/step - loss: 1.0986 - accuracy: 0.7895\n","Epoch 1/100\n","3/3 [==============================] - 1s 162ms/step - loss: 5.8086 - accuracy: 0.3397 - val_loss: 5.7697 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.3998 - accuracy: 0.4126 - val_loss: 3.9004 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.6569 - accuracy: 0.4410 - val_loss: 3.6960 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.9235 - accuracy: 0.3863 - val_loss: 2.6731 - val_accuracy: 0.4000\n","Epoch 5/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.5252 - accuracy: 0.4602 - val_loss: 2.6238 - val_accuracy: 0.4000\n","Epoch 6/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.3476 - accuracy: 0.4524 - val_loss: 2.5818 - val_accuracy: 0.4000\n","Epoch 7/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3414 - accuracy: 0.4641 - val_loss: 2.1289 - val_accuracy: 0.4000\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3190 - accuracy: 0.4875 - val_loss: 2.1287 - val_accuracy: 0.4000\n","Epoch 9/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.3507 - accuracy: 0.4680 - val_loss: 2.1284 - val_accuracy: 0.4000\n","Epoch 10/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.3390 - accuracy: 0.4289 - val_loss: 2.1283 - val_accuracy: 0.4000\n","Epoch 11/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.3408 - accuracy: 0.4680 - val_loss: 2.1282 - val_accuracy: 0.4000\n","Epoch 12/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3460 - accuracy: 0.4758 - val_loss: 2.1281 - val_accuracy: 0.4000\n","Epoch 13/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3389 - accuracy: 0.4563 - val_loss: 2.1277 - val_accuracy: 0.4000\n","Epoch 14/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.3340 - accuracy: 0.4613 - val_loss: 2.1276 - val_accuracy: 0.4000\n","Epoch 15/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3335 - accuracy: 0.4300 - val_loss: 2.1274 - val_accuracy: 0.4000\n","Epoch 16/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3236 - accuracy: 0.4300 - val_loss: 2.1273 - val_accuracy: 0.4000\n","Epoch 17/100\n","3/3 [==============================] - 0s 29ms/step - loss: 1.3433 - accuracy: 0.4144 - val_loss: 2.1271 - val_accuracy: 0.4000\n","Epoch 18/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3264 - accuracy: 0.4456 - val_loss: 2.1269 - val_accuracy: 0.4500\n","Epoch 19/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3311 - accuracy: 0.4534 - val_loss: 2.1269 - val_accuracy: 0.4500\n","Epoch 20/100\n","3/3 [==============================] - 0s 30ms/step - loss: 1.3311 - accuracy: 0.4378 - val_loss: 2.1269 - val_accuracy: 0.4500\n","Epoch 21/100\n","3/3 [==============================] - 0s 39ms/step - loss: 1.3365 - accuracy: 0.4222 - val_loss: 2.1269 - val_accuracy: 0.4500\n","Epoch 22/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.3365 - accuracy: 0.4495 - val_loss: 2.1269 - val_accuracy: 0.4500\n","Epoch 23/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.3419 - accuracy: 0.4573 - val_loss: 2.1269 - val_accuracy: 0.4500\n","Epoch 24/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3203 - accuracy: 0.4183 - val_loss: 2.1269 - val_accuracy: 0.4500\n","Epoch 25/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.3257 - accuracy: 0.4456 - val_loss: 2.1269 - val_accuracy: 0.4500\n","Epoch 26/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3203 - accuracy: 0.4730 - val_loss: 2.1269 - val_accuracy: 0.4500\n","Epoch 27/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3365 - accuracy: 0.4613 - val_loss: 2.1269 - val_accuracy: 0.4500\n","Epoch 28/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3365 - accuracy: 0.4730 - val_loss: 2.1269 - val_accuracy: 0.4500\n","1/1 [==============================] - 0s 214ms/step - loss: 1.3863 - accuracy: 0.5789\n","Epoch 1/100\n","3/3 [==============================] - 1s 171ms/step - loss: 5.4810 - accuracy: 0.1965 - val_loss: 2.9859 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.9003 - accuracy: 0.4199 - val_loss: 2.9321 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 42ms/step - loss: 2.3688 - accuracy: 0.4454 - val_loss: 4.8925 - val_accuracy: 0.5500\n","Epoch 4/100\n","3/3 [==============================] - 0s 40ms/step - loss: 3.4578 - accuracy: 0.4270 - val_loss: 3.2888 - val_accuracy: 0.4000\n","Epoch 5/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.6031 - accuracy: 0.5808 - val_loss: 2.6672 - val_accuracy: 0.4500\n","Epoch 6/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.4617 - accuracy: 0.5240 - val_loss: 3.2133 - val_accuracy: 0.3500\n","Epoch 7/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.4696 - accuracy: 0.5624 - val_loss: 3.1912 - val_accuracy: 0.4000\n","Epoch 8/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.2836 - accuracy: 0.5996 - val_loss: 3.1645 - val_accuracy: 0.5000\n","Epoch 9/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.5055 - accuracy: 0.5601 - val_loss: 3.1531 - val_accuracy: 0.4500\n","Epoch 10/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.2058 - accuracy: 0.6477 - val_loss: 3.1350 - val_accuracy: 0.4500\n","Epoch 11/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.6555 - accuracy: 0.6074 - val_loss: 3.1210 - val_accuracy: 0.4500\n","Epoch 12/100\n","3/3 [==============================] - 0s 37ms/step - loss: 1.1187 - accuracy: 0.6571 - val_loss: 3.1083 - val_accuracy: 0.4500\n","Epoch 13/100\n","3/3 [==============================] - 0s 36ms/step - loss: 1.3411 - accuracy: 0.6258 - val_loss: 3.1059 - val_accuracy: 0.4500\n","Epoch 14/100\n","3/3 [==============================] - 0s 43ms/step - loss: 1.1596 - accuracy: 0.6442 - val_loss: 3.1091 - val_accuracy: 0.4500\n","Epoch 15/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.2818 - accuracy: 0.6637 - val_loss: 3.1085 - val_accuracy: 0.5000\n","1/1 [==============================] - 0s 208ms/step - loss: 3.5882 - accuracy: 0.3889\n","Epoch 1/100\n","3/3 [==============================] - 1s 158ms/step - loss: 8.6943 - accuracy: 0.1859 - val_loss: 7.4568 - val_accuracy: 0.3000\n","Epoch 2/100\n","3/3 [==============================] - 0s 40ms/step - loss: 6.8191 - accuracy: 0.3496 - val_loss: 6.6739 - val_accuracy: 0.3500\n","Epoch 3/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.8273 - accuracy: 0.4227 - val_loss: 5.1726 - val_accuracy: 0.3500\n","Epoch 4/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.6220 - accuracy: 0.4794 - val_loss: 3.5722 - val_accuracy: 0.5500\n","Epoch 5/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.0133 - accuracy: 0.5546 - val_loss: 3.5095 - val_accuracy: 0.6000\n","Epoch 6/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.6318 - accuracy: 0.5534 - val_loss: 3.5033 - val_accuracy: 0.6500\n","Epoch 7/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.3256 - accuracy: 0.4944 - val_loss: 3.5140 - val_accuracy: 0.6500\n","Epoch 8/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.7246 - accuracy: 0.5401 - val_loss: 3.8622 - val_accuracy: 0.5500\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.4964 - accuracy: 0.5061 - val_loss: 7.2625 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 42ms/step - loss: 9.3604 - accuracy: 0.1186 - val_loss: 7.2611 - val_accuracy: 0.1500\n","Epoch 11/100\n","3/3 [==============================] - 0s 38ms/step - loss: 8.7580 - accuracy: 0.1342 - val_loss: 7.2559 - val_accuracy: 0.1500\n","Epoch 12/100\n","3/3 [==============================] - 0s 32ms/step - loss: 9.4716 - accuracy: 0.1420 - val_loss: 7.2508 - val_accuracy: 0.1500\n","Epoch 13/100\n","3/3 [==============================] - 0s 32ms/step - loss: 9.5479 - accuracy: 0.1225 - val_loss: 7.2456 - val_accuracy: 0.1500\n","Epoch 14/100\n","3/3 [==============================] - 0s 32ms/step - loss: 9.1666 - accuracy: 0.1381 - val_loss: 7.2414 - val_accuracy: 0.1500\n","Epoch 15/100\n","3/3 [==============================] - 0s 31ms/step - loss: 9.1099 - accuracy: 0.1225 - val_loss: 7.2379 - val_accuracy: 0.1500\n","Epoch 16/100\n","3/3 [==============================] - 0s 31ms/step - loss: 9.3882 - accuracy: 0.1147 - val_loss: 7.2362 - val_accuracy: 0.1500\n","1/1 [==============================] - 0s 205ms/step - loss: 16.9980 - accuracy: 0.0000e+00\n","Epoch 1/100\n","3/3 [==============================] - 1s 146ms/step - loss: 9.8577 - accuracy: 0.2360 - val_loss: 7.1287 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 35ms/step - loss: 9.9265 - accuracy: 0.2242 - val_loss: 7.0935 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 32ms/step - loss: 8.1299 - accuracy: 0.3117 - val_loss: 6.3283 - val_accuracy: 0.2500\n","Epoch 4/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.7661 - accuracy: 0.2971 - val_loss: 5.6318 - val_accuracy: 0.2000\n","Epoch 5/100\n","3/3 [==============================] - 0s 36ms/step - loss: 6.4994 - accuracy: 0.2719 - val_loss: 5.6311 - val_accuracy: 0.2000\n","Epoch 6/100\n","3/3 [==============================] - 0s 43ms/step - loss: 6.1999 - accuracy: 0.2406 - val_loss: 5.6161 - val_accuracy: 0.2500\n","Epoch 7/100\n","3/3 [==============================] - 0s 36ms/step - loss: 6.3599 - accuracy: 0.2591 - val_loss: 5.5800 - val_accuracy: 0.2000\n","Epoch 8/100\n","3/3 [==============================] - 0s 37ms/step - loss: 5.9277 - accuracy: 0.2619 - val_loss: 5.0193 - val_accuracy: 0.2000\n","Epoch 9/100\n","3/3 [==============================] - 0s 38ms/step - loss: 5.0455 - accuracy: 0.3301 - val_loss: 5.5431 - val_accuracy: 0.2000\n","Epoch 10/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.7263 - accuracy: 0.3184 - val_loss: 5.0128 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.0082 - accuracy: 0.3379 - val_loss: 5.0275 - val_accuracy: 0.2000\n","Epoch 12/100\n","3/3 [==============================] - 0s 37ms/step - loss: 4.3305 - accuracy: 0.3340 - val_loss: 4.4533 - val_accuracy: 0.2000\n","Epoch 13/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.3071 - accuracy: 0.3202 - val_loss: 4.4110 - val_accuracy: 0.2000\n","Epoch 14/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.9582 - accuracy: 0.3280 - val_loss: 4.3802 - val_accuracy: 0.2000\n","Epoch 15/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.6927 - accuracy: 0.3241 - val_loss: 4.2313 - val_accuracy: 0.2500\n","Epoch 16/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.5587 - accuracy: 0.3561 - val_loss: 3.5926 - val_accuracy: 0.2500\n","Epoch 17/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.3388 - accuracy: 0.3970 - val_loss: 4.2602 - val_accuracy: 0.2500\n","Epoch 18/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.9716 - accuracy: 0.4691 - val_loss: 4.2472 - val_accuracy: 0.3000\n","Epoch 19/100\n","3/3 [==============================] - 0s 39ms/step - loss: 3.2175 - accuracy: 0.4009 - val_loss: 4.2506 - val_accuracy: 0.2000\n","Epoch 20/100\n","3/3 [==============================] - 0s 30ms/step - loss: 4.3343 - accuracy: 0.3707 - val_loss: 4.3146 - val_accuracy: 0.2000\n","Epoch 21/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.3316 - accuracy: 0.4350 - val_loss: 4.2972 - val_accuracy: 0.2000\n","Epoch 22/100\n","3/3 [==============================] - 0s 29ms/step - loss: 3.5741 - accuracy: 0.4350 - val_loss: 4.2904 - val_accuracy: 0.2000\n","Epoch 23/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.1050 - accuracy: 0.4311 - val_loss: 4.2913 - val_accuracy: 0.2000\n","Epoch 24/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.2490 - accuracy: 0.4808 - val_loss: 4.2754 - val_accuracy: 0.2000\n","Epoch 25/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.5211 - accuracy: 0.4740 - val_loss: 4.2708 - val_accuracy: 0.2000\n","Epoch 26/100\n","3/3 [==============================] - 0s 35ms/step - loss: 3.4599 - accuracy: 0.4701 - val_loss: 4.2701 - val_accuracy: 0.2000\n","1/1 [==============================] - 0s 176ms/step - loss: 5.0103 - accuracy: 0.2105\n","Epoch 1/100\n","3/3 [==============================] - 1s 148ms/step - loss: 5.4323 - accuracy: 0.2640 - val_loss: 4.2709 - val_accuracy: 0.3500\n","Epoch 2/100\n","3/3 [==============================] - 0s 35ms/step - loss: 4.3857 - accuracy: 0.2992 - val_loss: 1.9569 - val_accuracy: 0.5500\n","Epoch 3/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.8715 - accuracy: 0.2776 - val_loss: 1.3390 - val_accuracy: 0.5000\n","Epoch 4/100\n","3/3 [==============================] - 0s 40ms/step - loss: 2.8927 - accuracy: 0.2971 - val_loss: 1.3637 - val_accuracy: 0.4000\n","Epoch 5/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.8546 - accuracy: 0.2669 - val_loss: 1.3703 - val_accuracy: 0.4000\n","Epoch 6/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.5449 - accuracy: 0.2932 - val_loss: 1.3711 - val_accuracy: 0.4000\n","Epoch 7/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.2202 - accuracy: 0.3031 - val_loss: 1.3715 - val_accuracy: 0.4000\n","Epoch 8/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.3746 - accuracy: 0.2992 - val_loss: 1.3712 - val_accuracy: 0.4000\n","Epoch 9/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.3992 - accuracy: 0.2456 - val_loss: 1.3721 - val_accuracy: 0.4000\n","Epoch 10/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.4231 - accuracy: 0.2953 - val_loss: 1.3732 - val_accuracy: 0.4000\n","Epoch 11/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.2185 - accuracy: 0.2747 - val_loss: 1.3750 - val_accuracy: 0.4000\n","Epoch 12/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.3713 - accuracy: 0.2903 - val_loss: 1.3743 - val_accuracy: 0.4000\n","Epoch 13/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.0375 - accuracy: 0.2893 - val_loss: 1.3729 - val_accuracy: 0.4000\n","1/1 [==============================] - 0s 173ms/step - loss: 4.4820 - accuracy: 0.2105\n","Epoch 1/100\n","3/3 [==============================] - 1s 155ms/step - loss: 7.3985 - accuracy: 0.2651 - val_loss: 7.3021 - val_accuracy: 0.3500\n","Epoch 2/100\n","3/3 [==============================] - 0s 37ms/step - loss: 8.4799 - accuracy: 0.2438 - val_loss: 6.6567 - val_accuracy: 0.3500\n","Epoch 3/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.6131 - accuracy: 0.2466 - val_loss: 7.8084 - val_accuracy: 0.3000\n","Epoch 4/100\n","3/3 [==============================] - 0s 34ms/step - loss: 7.9224 - accuracy: 0.2495 - val_loss: 7.7837 - val_accuracy: 0.3000\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 7.3268 - accuracy: 0.2758 - val_loss: 7.8757 - val_accuracy: 0.2500\n","Epoch 6/100\n","3/3 [==============================] - 0s 32ms/step - loss: 8.0484 - accuracy: 0.2175 - val_loss: 7.3234 - val_accuracy: 0.2000\n","Epoch 7/100\n","3/3 [==============================] - 0s 31ms/step - loss: 7.7298 - accuracy: 0.2466 - val_loss: 7.1293 - val_accuracy: 0.1500\n","Epoch 8/100\n","3/3 [==============================] - 0s 36ms/step - loss: 7.6587 - accuracy: 0.2505 - val_loss: 7.0472 - val_accuracy: 0.1500\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 6.9698 - accuracy: 0.2622 - val_loss: 6.5457 - val_accuracy: 0.1500\n","Epoch 10/100\n","3/3 [==============================] - 0s 39ms/step - loss: 6.1333 - accuracy: 0.2679 - val_loss: 7.9832 - val_accuracy: 0.1000\n","Epoch 11/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.8914 - accuracy: 0.2960 - val_loss: 8.6155 - val_accuracy: 0.1000\n","Epoch 12/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.7235 - accuracy: 0.2815 - val_loss: 8.7109 - val_accuracy: 0.1000\n","Epoch 13/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.7553 - accuracy: 0.3447 - val_loss: 8.7252 - val_accuracy: 0.0500\n","Epoch 14/100\n","3/3 [==============================] - 0s 34ms/step - loss: 5.1018 - accuracy: 0.3681 - val_loss: 8.7570 - val_accuracy: 0.0500\n","Epoch 15/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.6812 - accuracy: 0.3720 - val_loss: 8.8466 - val_accuracy: 0.1500\n","Epoch 16/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.8555 - accuracy: 0.3095 - val_loss: 9.5125 - val_accuracy: 0.1500\n","Epoch 17/100\n","3/3 [==============================] - 0s 33ms/step - loss: 4.6099 - accuracy: 0.3642 - val_loss: 6.8960 - val_accuracy: 0.1500\n","Epoch 18/100\n","3/3 [==============================] - 0s 32ms/step - loss: 4.0782 - accuracy: 0.2932 - val_loss: 5.4555 - val_accuracy: 0.1500\n","Epoch 19/100\n","3/3 [==============================] - 0s 42ms/step - loss: 3.5293 - accuracy: 0.3174 - val_loss: 4.3698 - val_accuracy: 0.1500\n","Epoch 20/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.1601 - accuracy: 0.3525 - val_loss: 4.9683 - val_accuracy: 0.1500\n","Epoch 21/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.8793 - accuracy: 0.3408 - val_loss: 4.9658 - val_accuracy: 0.1500\n","Epoch 22/100\n","3/3 [==============================] - 0s 45ms/step - loss: 1.8178 - accuracy: 0.3642 - val_loss: 4.9715 - val_accuracy: 0.1500\n","Epoch 23/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.9301 - accuracy: 0.3291 - val_loss: 4.9730 - val_accuracy: 0.1500\n","Epoch 24/100\n","3/3 [==============================] - 0s 39ms/step - loss: 2.0150 - accuracy: 0.3710 - val_loss: 4.9393 - val_accuracy: 0.1500\n","Epoch 25/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.7691 - accuracy: 0.3671 - val_loss: 4.9670 - val_accuracy: 0.1500\n","Epoch 26/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.7200 - accuracy: 0.3671 - val_loss: 4.9718 - val_accuracy: 0.1500\n","Epoch 27/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.7903 - accuracy: 0.3632 - val_loss: 4.9771 - val_accuracy: 0.1000\n","Epoch 28/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.7003 - accuracy: 0.3476 - val_loss: 4.9813 - val_accuracy: 0.1000\n","Epoch 29/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.9028 - accuracy: 0.3515 - val_loss: 4.2476 - val_accuracy: 0.2000\n","Epoch 30/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.4285 - accuracy: 0.2776 - val_loss: 4.2477 - val_accuracy: 0.2000\n","Epoch 31/100\n","3/3 [==============================] - 0s 38ms/step - loss: 1.6744 - accuracy: 0.2854 - val_loss: 4.2381 - val_accuracy: 0.2000\n","Epoch 32/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.5040 - accuracy: 0.3088 - val_loss: 4.2379 - val_accuracy: 0.2000\n","Epoch 33/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.6403 - accuracy: 0.3020 - val_loss: 4.2421 - val_accuracy: 0.2000\n","Epoch 34/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.4602 - accuracy: 0.2736 - val_loss: 4.2408 - val_accuracy: 0.2000\n","Epoch 35/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.5192 - accuracy: 0.2854 - val_loss: 4.2421 - val_accuracy: 0.2000\n","Epoch 36/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.5517 - accuracy: 0.2854 - val_loss: 4.2409 - val_accuracy: 0.2000\n","Epoch 37/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.6274 - accuracy: 0.3049 - val_loss: 4.2407 - val_accuracy: 0.2000\n","Epoch 38/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.6296 - accuracy: 0.2736 - val_loss: 4.2432 - val_accuracy: 0.2000\n","Epoch 39/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.5737 - accuracy: 0.2882 - val_loss: 4.2367 - val_accuracy: 0.2000\n","Epoch 40/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.7338 - accuracy: 0.3156 - val_loss: 4.2392 - val_accuracy: 0.2000\n","Epoch 41/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.6173 - accuracy: 0.2921 - val_loss: 4.2404 - val_accuracy: 0.2000\n","Epoch 42/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.5308 - accuracy: 0.3077 - val_loss: 4.2284 - val_accuracy: 0.2000\n","Epoch 43/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.6150 - accuracy: 0.3234 - val_loss: 4.2179 - val_accuracy: 0.2000\n","Epoch 44/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.7291 - accuracy: 0.2882 - val_loss: 4.2117 - val_accuracy: 0.2000\n","Epoch 45/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.5311 - accuracy: 0.3312 - val_loss: 4.2062 - val_accuracy: 0.2000\n","Epoch 46/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.5941 - accuracy: 0.3468 - val_loss: 4.1989 - val_accuracy: 0.2000\n","Epoch 47/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.4535 - accuracy: 0.3156 - val_loss: 4.1256 - val_accuracy: 0.2000\n","Epoch 48/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.7191 - accuracy: 0.3379 - val_loss: 3.6765 - val_accuracy: 0.2000\n","Epoch 49/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.5560 - accuracy: 0.3145 - val_loss: 3.6819 - val_accuracy: 0.2000\n","Epoch 50/100\n","3/3 [==============================] - 0s 42ms/step - loss: 1.5042 - accuracy: 0.3106 - val_loss: 3.6910 - val_accuracy: 0.2000\n","Epoch 51/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.5450 - accuracy: 0.3301 - val_loss: 3.7011 - val_accuracy: 0.2000\n","Epoch 52/100\n","3/3 [==============================] - 0s 39ms/step - loss: 1.2325 - accuracy: 0.3301 - val_loss: 3.7334 - val_accuracy: 0.2000\n","Epoch 53/100\n","3/3 [==============================] - 0s 33ms/step - loss: 1.2901 - accuracy: 0.3262 - val_loss: 3.7935 - val_accuracy: 0.2000\n","Epoch 54/100\n","3/3 [==============================] - 0s 32ms/step - loss: 1.4346 - accuracy: 0.3106 - val_loss: 4.3089 - val_accuracy: 0.2000\n","Epoch 55/100\n","3/3 [==============================] - 0s 31ms/step - loss: 1.4325 - accuracy: 0.3273 - val_loss: 4.3089 - val_accuracy: 0.2000\n","Epoch 56/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.3581 - accuracy: 0.3028 - val_loss: 4.3090 - val_accuracy: 0.2000\n","Epoch 57/100\n","3/3 [==============================] - 0s 35ms/step - loss: 1.4434 - accuracy: 0.3536 - val_loss: 4.3091 - val_accuracy: 0.2000\n","Epoch 58/100\n","3/3 [==============================] - 0s 34ms/step - loss: 1.3242 - accuracy: 0.3184 - val_loss: 4.3097 - val_accuracy: 0.2000\n","1/1 [==============================] - 0s 193ms/step - loss: 3.7245 - accuracy: 0.1579\n","Epoch 1/100\n","3/3 [==============================] - 1s 149ms/step - loss: 6.4829 - accuracy: 0.2751 - val_loss: 5.5921 - val_accuracy: 0.2500\n","Epoch 2/100\n","3/3 [==============================] - 0s 36ms/step - loss: 5.4544 - accuracy: 0.2634 - val_loss: 4.3312 - val_accuracy: 0.2500\n","Epoch 3/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.9696 - accuracy: 0.2427 - val_loss: 3.5583 - val_accuracy: 0.1500\n","Epoch 4/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.9693 - accuracy: 0.2645 - val_loss: 2.7705 - val_accuracy: 0.1500\n","Epoch 5/100\n","3/3 [==============================] - 0s 36ms/step - loss: 3.5412 - accuracy: 0.2321 - val_loss: 2.7606 - val_accuracy: 0.1500\n","Epoch 6/100\n","3/3 [==============================] - 0s 37ms/step - loss: 3.3794 - accuracy: 0.2661 - val_loss: 2.5932 - val_accuracy: 0.2000\n","Epoch 7/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.5706 - accuracy: 0.3107 - val_loss: 2.5799 - val_accuracy: 0.2000\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.5087 - accuracy: 0.3264 - val_loss: 2.6268 - val_accuracy: 0.2000\n","Epoch 9/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.5493 - accuracy: 0.3068 - val_loss: 2.5886 - val_accuracy: 0.2000\n","Epoch 10/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.2179 - accuracy: 0.2717 - val_loss: 2.6205 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.8751 - accuracy: 0.2912 - val_loss: 2.7054 - val_accuracy: 0.2000\n","Epoch 12/100\n","3/3 [==============================] - 0s 38ms/step - loss: 2.6858 - accuracy: 0.3018 - val_loss: 2.6798 - val_accuracy: 0.2000\n","Epoch 13/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.5135 - accuracy: 0.2811 - val_loss: 2.6951 - val_accuracy: 0.2000\n","Epoch 14/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.3727 - accuracy: 0.3608 - val_loss: 2.6920 - val_accuracy: 0.2000\n","Epoch 15/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.4432 - accuracy: 0.3441 - val_loss: 2.6921 - val_accuracy: 0.2000\n","Epoch 16/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.4184 - accuracy: 0.3820 - val_loss: 2.6915 - val_accuracy: 0.2000\n","Epoch 17/100\n","3/3 [==============================] - 0s 36ms/step - loss: 2.3195 - accuracy: 0.3781 - val_loss: 2.6871 - val_accuracy: 0.2000\n","1/1 [==============================] - 0s 181ms/step - loss: 5.3635 - accuracy: 0.2222\n","Epoch 1/100\n","3/3 [==============================] - 1s 145ms/step - loss: 7.9199 - accuracy: 0.1253 - val_loss: 5.7126 - val_accuracy: 0.2000\n","Epoch 2/100\n","3/3 [==============================] - 0s 32ms/step - loss: 7.6053 - accuracy: 0.1503 - val_loss: 6.0621 - val_accuracy: 0.2000\n","Epoch 3/100\n","3/3 [==============================] - 0s 36ms/step - loss: 6.4679 - accuracy: 0.1871 - val_loss: 6.3003 - val_accuracy: 0.2000\n","Epoch 4/100\n","3/3 [==============================] - 0s 35ms/step - loss: 5.0236 - accuracy: 0.1765 - val_loss: 4.7931 - val_accuracy: 0.2000\n","Epoch 5/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.2887 - accuracy: 0.2133 - val_loss: 4.8639 - val_accuracy: 0.2000\n","Epoch 6/100\n","3/3 [==============================] - 0s 34ms/step - loss: 4.5069 - accuracy: 0.2043 - val_loss: 4.9201 - val_accuracy: 0.2000\n","Epoch 7/100\n","3/3 [==============================] - 0s 38ms/step - loss: 4.4418 - accuracy: 0.1876 - val_loss: 5.4093 - val_accuracy: 0.2000\n","Epoch 8/100\n","3/3 [==============================] - 0s 31ms/step - loss: 4.2137 - accuracy: 0.2579 - val_loss: 5.3858 - val_accuracy: 0.2000\n","Epoch 9/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.9370 - accuracy: 0.1448 - val_loss: 4.5415 - val_accuracy: 0.2500\n","Epoch 10/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.1809 - accuracy: 0.1041 - val_loss: 4.5052 - val_accuracy: 0.2000\n","Epoch 11/100\n","3/3 [==============================] - 0s 33ms/step - loss: 3.6367 - accuracy: 0.1420 - val_loss: 4.4450 - val_accuracy: 0.2000\n","Epoch 12/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.8818 - accuracy: 0.0952 - val_loss: 3.9709 - val_accuracy: 0.2000\n","Epoch 13/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.2596 - accuracy: 0.1264 - val_loss: 3.8096 - val_accuracy: 0.3000\n","Epoch 14/100\n","3/3 [==============================] - 0s 31ms/step - loss: 3.6737 - accuracy: 0.2979 - val_loss: 3.2753 - val_accuracy: 0.3000\n","Epoch 15/100\n","3/3 [==============================] - 0s 30ms/step - loss: 3.2698 - accuracy: 0.3107 - val_loss: 3.3445 - val_accuracy: 0.3500\n","Epoch 16/100\n","3/3 [==============================] - 0s 32ms/step - loss: 3.7624 - accuracy: 0.3084 - val_loss: 3.3445 - val_accuracy: 0.3500\n","Epoch 17/100\n","3/3 [==============================] - 0s 34ms/step - loss: 3.2238 - accuracy: 0.3346 - val_loss: 3.3427 - val_accuracy: 0.3500\n","Epoch 18/100\n","3/3 [==============================] - 0s 31ms/step - loss: 2.7769 - accuracy: 0.3464 - val_loss: 3.3434 - val_accuracy: 0.3500\n","Epoch 19/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.9262 - accuracy: 0.3307 - val_loss: 3.3418 - val_accuracy: 0.3500\n","Epoch 20/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.9067 - accuracy: 0.3190 - val_loss: 3.3442 - val_accuracy: 0.3500\n","Epoch 21/100\n","3/3 [==============================] - 0s 33ms/step - loss: 2.9089 - accuracy: 0.3424 - val_loss: 3.3438 - val_accuracy: 0.3500\n","Epoch 22/100\n","3/3 [==============================] - 0s 37ms/step - loss: 2.9686 - accuracy: 0.3776 - val_loss: 3.3443 - val_accuracy: 0.3500\n","Epoch 23/100\n","3/3 [==============================] - 0s 35ms/step - loss: 2.9827 - accuracy: 0.3190 - val_loss: 3.4131 - val_accuracy: 0.3000\n","Epoch 24/100\n","3/3 [==============================] - 0s 34ms/step - loss: 2.6641 - accuracy: 0.3123 - val_loss: 3.4164 - val_accuracy: 0.3500\n","1/1 [==============================] - 0s 174ms/step - loss: 1.9695 - accuracy: 0.2778\n","Epoch 1/100\n","3/3 [==============================] - 1s 153ms/step - loss: 6.3355 - accuracy: 0.2018 - val_loss: 6.1406 - val_accuracy: 0.3000\n","Epoch 2/100\n","3/3 [==============================] - 0s 36ms/step - loss: 7.2064 - accuracy: 0.2931 - val_loss: 13.3951 - val_accuracy: 0.0500\n","Epoch 3/100\n","3/3 [==============================] - 0s 35ms/step - loss: 10.2568 - accuracy: 0.2526 - val_loss: 14.0746 - val_accuracy: 0.0500\n","Epoch 4/100\n","3/3 [==============================] - 0s 37ms/step - loss: 10.2316 - accuracy: 0.2291 - val_loss: 14.0906 - val_accuracy: 0.0500\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 10.5376 - accuracy: 0.2057 - val_loss: 14.2400 - val_accuracy: 0.0500\n","Epoch 6/100\n","3/3 [==============================] - 0s 37ms/step - loss: 9.9048 - accuracy: 0.2408 - val_loss: 14.7453 - val_accuracy: 0.0500\n","Epoch 7/100\n","3/3 [==============================] - 0s 38ms/step - loss: 9.2567 - accuracy: 0.2604 - val_loss: 14.7405 - val_accuracy: 0.0500\n","Epoch 8/100\n","3/3 [==============================] - 0s 34ms/step - loss: 9.6020 - accuracy: 0.2736 - val_loss: 14.7368 - val_accuracy: 0.0500\n","Epoch 9/100\n","3/3 [==============================] - 0s 42ms/step - loss: 10.0504 - accuracy: 0.2618 - val_loss: 14.7328 - val_accuracy: 0.0500\n","Epoch 10/100\n","3/3 [==============================] - 0s 37ms/step - loss: 9.9373 - accuracy: 0.2579 - val_loss: 14.7310 - val_accuracy: 0.0500\n","Epoch 11/100\n","3/3 [==============================] - 0s 36ms/step - loss: 10.2266 - accuracy: 0.2213 - val_loss: 13.9583 - val_accuracy: 0.0500\n","Model with rank: 1\n","Parameters: {'n_neurons': 90, 'n_hidden': 2, 'learning_rate': 0.003}\n","\n","Model with rank: 2\n","Parameters: {'n_neurons': 40, 'n_hidden': 3, 'learning_rate': 0.002}\n","\n","Model with rank: 3\n","Parameters: {'n_neurons': 70, 'n_hidden': 2, 'learning_rate': 0.0003}\n","\n","Model with rank: 4\n","Parameters: {'n_neurons': 60, 'n_hidden': 2, 'learning_rate': 0.0003}\n","\n","Model with rank: 5\n","Parameters: {'n_neurons': 100, 'n_hidden': 1, 'learning_rate': 0.003}\n","\n","Model with rank: 6\n","Parameters: {'n_neurons': 30, 'n_hidden': 2, 'learning_rate': 3e-05}\n","\n","Model with rank: 7\n","Parameters: {'n_neurons': 30, 'n_hidden': 0, 'learning_rate': 3e-05}\n","\n","Model with rank: 8\n","Parameters: {'n_neurons': 40, 'n_hidden': 2, 'learning_rate': 0.0003}\n","\n","Model with rank: 9\n","Parameters: {'n_neurons': 50, 'n_hidden': 2, 'learning_rate': 3e-05}\n","\n","Model with rank: 10\n","Parameters: {'n_neurons': 70, 'n_hidden': 0, 'learning_rate': 0.003}\n","\n","Model with rank: 11\n","Parameters: {'n_neurons': 10, 'n_hidden': 0, 'learning_rate': 0.002}\n","\n","Model with rank: 12\n","Parameters: {'n_neurons': 90, 'n_hidden': 1, 'learning_rate': 0.002}\n","\n","Model with rank: 13\n","Parameters: {'n_neurons': 50, 'n_hidden': 1, 'learning_rate': 0.003}\n","\n","Model with rank: 14\n","Parameters: {'n_neurons': 70, 'n_hidden': 0, 'learning_rate': 0.0003}\n","\n","Model with rank: 15\n","Parameters: {'n_neurons': 60, 'n_hidden': 3, 'learning_rate': 0.001}\n","\n","Model with rank: 16\n","Parameters: {'n_neurons': 60, 'n_hidden': 3, 'learning_rate': 0.002}\n","\n","Model with rank: 17\n","Parameters: {'n_neurons': 70, 'n_hidden': 1, 'learning_rate': 0.003}\n","\n","Model with rank: 18\n","Parameters: {'n_neurons': 20, 'n_hidden': 0, 'learning_rate': 0.002}\n","\n","Model with rank: 19\n","Parameters: {'n_neurons': 90, 'n_hidden': 2, 'learning_rate': 0.001}\n","\n","Model with rank: 20\n","Parameters: {'n_neurons': 20, 'n_hidden': 1, 'learning_rate': 3e-05}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E6l8icnQp-qe","executionInfo":{"status":"ok","timestamp":1617269947846,"user_tz":-540,"elapsed":81119,"user":{"displayName":"최은우","photoUrl":"","userId":"09535764796893882081"}},"outputId":"d1f1b8f6-87f7-4a5e-f887-b8a653e9026e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#하이퍼파라미터 실습 2(출처:https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)\n","\n","\n","# Use scikit-learn to grid search the batch size and epochs\n","\n","import numpy as np\n","import pandas as pd\n","import joblib\n","import scipy\n","\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.preprocessing import StandardScaler, RobustScaler\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.layers import Dropout\n","from keras.constraints import maxnorm\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, f1_score\n","from keras.models import load_model\n","from keras.optimizers import Adadelta\n","from imblearn.over_sampling import SMOTE\n","from scipy.stats import uniform as sp_randFloat\n","from scipy.stats import randint as sp_randInt  \n","\n","# fix random seed for reproducibility\n","\n","seed = 7\n","np.random.seed(seed)\n","\n","#데이터 입력\n","df = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/csv/PA_internal_withothers.csv')\n","df1 = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/csv/PA_external_withothers.csv')\n","df2 = pd.concat([df, df1])\n","\n","#데이터 분류\n","dataset = df.values\n","X = dataset[:,0:-1]\n","Y = dataset[:,-1]\n","\n","ex_data =df1.values\n","exX = ex_data[:,0:-1]\n","exY = ex_data[:,-1]\n","\n","tot_data = df2.values\n","totX = tot_data[:,0:-1]\n","totY = tot_data[:,-1]\n","\n","#X 표준화\n","\n","scaler = RobustScaler()\n","\n","X_scaled = scaler.fit_transform(X)\n","exX_scaled = scaler.transform(exX)\n","totX_scaled = scaler.transform(totX)\n","\n","#Oversampling using SMOTE\n","\n","#smote = SMOTE(random_state=0)\n","#X_over, Y_over = smote.fit_sample(X_scaled, Y)\n","\n","# Function to create model, required for KerasClassifier\n","input_dim = X_scaled.shape[1]\n","n_class = len(set(Y))\n","\n","def create_model(activation='relu'):\n","   # create model\n","    model = Sequential()\n","    model.add(Dense(10, input_dim=input_dim , activation=activation))\n","    model.add(Dense(n_class, activation='softmax'))\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n","    return model\n","\n","# create model\n","model = KerasClassifier(create_model, batch_size = 10, epochs = 100, verbose=0)\n","\n","# define the grid search parameters\n","\n","activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n","param_grid = dict(activation=activation)\n","grid =GridSearchCV(model, param_grid, n_jobs=-1, cv=5)\n","grid_result = grid.fit(X_scaled, Y)\n","\n","# summarize results\n","#print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","#means = grid_result.cv_results_['mean_test_score']\n","#stds = grid_result.cv_results_['std_test_score']\n","#params = grid_result.cv_results_['params']\n","#for mean, stdev, param in zip(means, stds, params):\n","#    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n","print(grid_result.best_params_)\n","\n","ann = grid_result.best_estimator_   \n","   \n","#print(ann.evaluate(X_scaled, Y)[1])\n","#print(ann.evaluate(exX_scaled, exY)[1])\n","#print(ann.evaluate(totX_scaled, totY)[1])   \n","\n","#결과리포트 생성(단일)\n","\n","def get_clf_eval(y_test=None, pred=None):\n","    confusion = confusion_matrix(y_test, pred)\n","    accuracy = accuracy_score(y_test, pred)\n","    print('오차행렬')\n","    print(confusion)\n","    print('정확도: {0:.4f}'.format(accuracy))\n","\n","def get_model_train_eval(model, ftr_train=None, ftr_test=None, ftr_tot=None, tgt_train=None, tgt_test=None, tgt_tot=None):\n","    model.fit(ftr_train, tgt_train)\n","    pred = model.predict(ftr_train)\n","    predex = model.predict(ftr_test)\n","    predtot = model.predict(ftr_tot)\n","    get_clf_eval(tgt_train, pred)\n","    get_clf_eval(tgt_test, predex)\n","    get_clf_eval(tgt_tot, predtot)\n","    \n","get_model_train_eval(ann, ftr_train=X_scaled, ftr_test=exX_scaled, ftr_tot=totX_scaled, tgt_train=Y, tgt_test=exY, tgt_tot=totY) \n","\n","#top 3 리포트 작성\n","\n","def report(results, n_top=20):\n","    for i in range(1, n_top + 1):\n","        candidates = np.flatnonzero(results['rank_test_score'] == i)\n","        for candidate in candidates:\n","            print(\"Model with rank: {0}\".format(i))\n","            print(\"Parameters: {0}\".format(results['params'][candidate]))\n","            print(\"\") #여기에 accu, conf 추가해야 함\n","            \n","report(grid.cv_results_)            \n","    \n","#정확도와 혼동함수 생성\n","\n","#pred = ann.predict(X_scaled)\n","#accuracy = accuracy_score(Y, pred)\n","#print('ann 내부 정확도: {0:.4f}'.format(accuracy))\n","#conf_matrix = confusion_matrix(Y, pred)\n","#print(conf_matrix)\n","#conf_matrix_nor = confusion_matrix(Y, pred)/60\n","#print(conf_matrix_nor)\n","\n","#pred2 = ann.predict(exX_scaled)\n","#accuracy = accuracy_score(exY, pred2)\n","#print('ann 외부 정확도: {0:.4f}'.format(accuracy))\n","#conf_matrix2 = confusion_matrix(exY, pred2)\n","#print(conf_matrix2)\n","#conf_matrix2_nor = confusion_matrix(exY, pred2)/14\n","#print(conf_matrix2_nor)\n","\n","#pred3 = ann.predict(totX_scaled)\n","#accuracy = accuracy_score(totY, pred3)\n","#print('ann 전체 정확도: {0:.4f}'.format(accuracy))\n","#conf_matrix3 = confusion_matrix(totY, pred3)\n","#print(conf_matrix3)\n","#conf_matrix3_nor = confusion_matrix(totY, pred3)/74\n","#print(conf_matrix3_nor)    \n","    \n","#모델 저장\n","\n","ann.model.save('PA_ann_0401_2.h5')\n","\n","#0324 total 0.93 test 0.64 0324_2 total 0.95 test 0.71(그치만 과적합) 0324_3 total 0.96 test 0.79\n","\n","#0331&0331_2 0.9 0.40 0.81  0331_3 0.48 0.65 0.51 0331_4 0.91 0.42 0.82 0404_1 0.82 0.53 0.77"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","{'activation': 'relu'}\n","오차행렬\n","[[64  0  0  0]\n"," [ 8 37  0  0]\n"," [ 0  0  8  0]\n"," [ 0  0  0 10]]\n","정확도: 0.9370\n","오차행렬\n","[[ 8  3  0  0]\n"," [10  3  0  0]\n"," [ 0  0  1  1]\n"," [ 1  0  0  1]]\n","정확도: 0.4643\n","오차행렬\n","[[72  3  0  0]\n"," [18 40  0  0]\n"," [ 0  0  9  1]\n"," [ 1  0  0 11]]\n","정확도: 0.8516\n","Model with rank: 1\n","Parameters: {'activation': 'relu'}\n","\n","Model with rank: 2\n","Parameters: {'activation': 'linear'}\n","\n","Model with rank: 3\n","Parameters: {'activation': 'tanh'}\n","\n","Model with rank: 4\n","Parameters: {'activation': 'sigmoid'}\n","\n","Model with rank: 5\n","Parameters: {'activation': 'hard_sigmoid'}\n","\n","Model with rank: 6\n","Parameters: {'activation': 'softmax'}\n","\n","Model with rank: 7\n","Parameters: {'activation': 'softsign'}\n","\n","Model with rank: 8\n","Parameters: {'activation': 'softplus'}\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oHnuDcOVp-qf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617272866358,"user_tz":-540,"elapsed":14198,"user":{"displayName":"최은우","photoUrl":"","userId":"09535764796893882081"}},"outputId":"ec08732c-f310-4cc4-a471-f2fc60792467"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import pandas as pd\n","import joblib\n","import tensorflow as tf\n","\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.preprocessing import StandardScaler, RobustScaler\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.layers import Dropout\n","from keras.constraints import maxnorm\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, f1_score\n","from keras.models import load_model\n","from keras.optimizers import Adadelta\n","from scipy.stats import randint, uniform, loguniform\n","from imblearn.over_sampling import SMOTE\n","from tensorflow.python.keras.utils import np_utils\n","\n","# fix random seed for reproducibility\n","\n","seed = 7\n","np.random.seed(seed)\n","\n","#데이터 입력\n","df = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/csv/PA_internal_withothers.csv')\n","df1 = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/csv/PA_external_withothers.csv')\n","df2 = pd.concat([df, df1])\n","\n","#데이터 분류\n","dataset = df.values\n","X = dataset[:,0:-1]\n","Y = dataset[:,-1]\n","\n","ex_data =df1.values\n","exX = ex_data[:,0:-1]\n","exY = ex_data[:,-1]\n","\n","tot_data = df2.values\n","totX = tot_data[:,0:-1]\n","totY = tot_data[:,-1]\n","\n","#X 표준화\n","\n","scaler = RobustScaler()\n","\n","X_scaled = scaler.fit_transform(X)\n","exX_scaled = scaler.transform(exX)\n","totX_scaled = scaler.transform(totX)\n","\n","#Y 인코딩\n","\n","Y_encoded = tf.keras.utils.to_categorical(Y)\n","exY_encoded = tf.keras.utils.to_categorical(exY)\n","totY_encoded = tf.keras.utils.to_categorical(totY)\n","\n","#모델 생성\n","\n","input_dim = X_scaled.shape[1]\n","n_class = len(set(Y))\n","\n","model = Sequential()\n","model.add(Dense(50, input_dim=input_dim , activation='relu'))\n","model.add(Dense(n_class))\n","model.compile(loss='MSE', optimizer='adam', metrics=['accuracy'])\n","\n","#모델 학습\n","model.fit(X_scaled,Y_encoded, epochs=200, batch_size=5)\n","\n","#학습 평가\n","\n","print(model.evaluate(X_scaled, Y_encoded)[1])\n","print(model.evaluate(exX_scaled, exY_encoded)[1])\n","print(model.evaluate(totX_scaled, totY_encoded)[1])\n","\n","#모델 저장\n","\n","model.save('PA_ann_0401_.h5')\n","\n","#0401_3 0.74 0.53 0.70\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Epoch 1/200\n","26/26 [==============================] - 0s 2ms/step - loss: 15.8912 - accuracy: 0.2324\n","Epoch 2/200\n","26/26 [==============================] - 0s 2ms/step - loss: 14.4963 - accuracy: 0.4104\n","Epoch 3/200\n","26/26 [==============================] - 0s 2ms/step - loss: 5.5547 - accuracy: 0.2261\n","Epoch 4/200\n","26/26 [==============================] - 0s 2ms/step - loss: 5.9596 - accuracy: 0.3227\n","Epoch 5/200\n","26/26 [==============================] - 0s 2ms/step - loss: 2.8726 - accuracy: 0.4543\n","Epoch 6/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.8661 - accuracy: 0.4748\n","Epoch 7/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.5814\n","Epoch 8/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.4653\n","Epoch 9/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.5351\n","Epoch 10/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.6332\n","Epoch 11/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.6586\n","Epoch 12/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.7893\n","Epoch 13/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.7624\n","Epoch 14/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.8399\n","Epoch 15/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.8282\n","Epoch 16/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.7753\n","Epoch 17/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.7682\n","Epoch 18/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.7769\n","Epoch 19/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.7748\n","Epoch 20/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.7417 - accuracy: 0.7400\n","Epoch 21/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.6211\n","Epoch 22/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.7988\n","Epoch 23/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8090\n","Epoch 24/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.7626\n","Epoch 25/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7016\n","Epoch 26/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.7762\n","Epoch 27/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.7674\n","Epoch 28/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.7567\n","Epoch 29/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.7322\n","Epoch 30/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.8543\n","Epoch 31/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.7327\n","Epoch 32/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.8342\n","Epoch 33/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.8190\n","Epoch 34/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0864 - accuracy: 0.8978\n","Epoch 35/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.8875\n","Epoch 36/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.8781\n","Epoch 37/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.8616\n","Epoch 38/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.8342\n","Epoch 39/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.8885\n","Epoch 40/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.8997\n","Epoch 41/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.8071\n","Epoch 42/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.7409\n","Epoch 43/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.8368\n","Epoch 44/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.8511\n","Epoch 45/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.8908\n","Epoch 46/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.8075\n","Epoch 47/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.8108\n","Epoch 48/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.8475\n","Epoch 49/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1659 - accuracy: 0.7918\n","Epoch 50/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.8159\n","Epoch 51/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.7335\n","Epoch 52/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7553\n","Epoch 53/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.7294 - accuracy: 0.7436\n","Epoch 54/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.6985\n","Epoch 55/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.8362\n","Epoch 56/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.7967\n","Epoch 57/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.8614\n","Epoch 58/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.8555\n","Epoch 59/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.8692\n","Epoch 60/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.8742\n","Epoch 61/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.8068\n","Epoch 62/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.8372\n","Epoch 63/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.8902\n","Epoch 64/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.8703\n","Epoch 65/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9102\n","Epoch 66/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.8879\n","Epoch 67/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.8979\n","Epoch 68/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.8461\n","Epoch 69/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.8898\n","Epoch 70/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.8987\n","Epoch 71/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.8493\n","Epoch 72/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.8727\n","Epoch 73/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.8809\n","Epoch 74/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9502\n","Epoch 75/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.8938\n","Epoch 76/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.8355\n","Epoch 77/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9054\n","Epoch 78/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.8938\n","Epoch 79/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9029\n","Epoch 80/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9417\n","Epoch 81/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9237\n","Epoch 82/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9127\n","Epoch 83/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.7979\n","Epoch 84/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.8424\n","Epoch 85/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.8803\n","Epoch 86/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.8419\n","Epoch 87/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.8748\n","Epoch 88/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.8966\n","Epoch 89/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9257\n","Epoch 90/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.8616\n","Epoch 91/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.8631\n","Epoch 92/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.8881\n","Epoch 93/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.8767\n","Epoch 94/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.8677\n","Epoch 95/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.8622\n","Epoch 96/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.8956\n","Epoch 97/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.8192\n","Epoch 98/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.8066\n","Epoch 99/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9194\n","Epoch 100/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.8535\n","Epoch 101/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9073\n","Epoch 102/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.8710\n","Epoch 103/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.8674\n","Epoch 104/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.7828\n","Epoch 105/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.8782\n","Epoch 106/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.8474\n","Epoch 107/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.8565\n","Epoch 108/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.8630\n","Epoch 109/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.8508\n","Epoch 110/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.8712\n","Epoch 111/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.8215\n","Epoch 112/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9153\n","Epoch 113/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.8865\n","Epoch 114/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.8835\n","Epoch 115/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.8422\n","Epoch 116/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.8499\n","Epoch 117/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9042\n","Epoch 118/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9242\n","Epoch 119/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.8765\n","Epoch 120/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.8809\n","Epoch 121/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.8307\n","Epoch 122/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9449\n","Epoch 123/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.8793\n","Epoch 124/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.8564\n","Epoch 125/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.8867\n","Epoch 126/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.8578\n","Epoch 127/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.8891\n","Epoch 128/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9244\n","Epoch 129/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.8492\n","Epoch 130/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.8691\n","Epoch 131/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.8399\n","Epoch 132/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.8987\n","Epoch 133/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.8843\n","Epoch 134/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.8576\n","Epoch 135/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.8769\n","Epoch 136/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.8660\n","Epoch 137/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.8764\n","Epoch 138/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.8987\n","Epoch 139/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.8770\n","Epoch 140/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.8389\n","Epoch 141/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.8110\n","Epoch 142/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.8614\n","Epoch 143/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9041\n","Epoch 144/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.8819\n","Epoch 145/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.8373\n","Epoch 146/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.8796\n","Epoch 147/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.8838\n","Epoch 148/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.8678\n","Epoch 149/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.8886\n","Epoch 150/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.8688\n","Epoch 151/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.8415\n","Epoch 152/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.8927\n","Epoch 153/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.8917\n","Epoch 154/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.8548\n","Epoch 155/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.8924\n","Epoch 156/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.7912\n","Epoch 157/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9011\n","Epoch 158/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.8671\n","Epoch 159/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.7604\n","Epoch 160/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.8844\n","Epoch 161/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.8738\n","Epoch 162/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9022\n","Epoch 163/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.8807\n","Epoch 164/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.8429\n","Epoch 165/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.8810\n","Epoch 166/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.8263\n","Epoch 167/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.8295\n","Epoch 168/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.8270\n","Epoch 169/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.7936\n","Epoch 170/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.8574\n","Epoch 171/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.8530\n","Epoch 172/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.8955\n","Epoch 173/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.8002\n","Epoch 174/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.8423\n","Epoch 175/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.8459\n","Epoch 176/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.8221\n","Epoch 177/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.8552\n","Epoch 178/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.8561\n","Epoch 179/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.8167\n","Epoch 180/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.8393\n","Epoch 181/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.8040\n","Epoch 182/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.8648\n","Epoch 183/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.8722\n","Epoch 184/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.8075\n","Epoch 185/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.8621\n","Epoch 186/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.8411\n","Epoch 187/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.8359\n","Epoch 188/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.8256\n","Epoch 189/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.8352\n","Epoch 190/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.8547\n","Epoch 191/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.8250\n","Epoch 192/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.8476\n","Epoch 193/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.8223\n","Epoch 194/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.8308\n","Epoch 195/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.8600\n","Epoch 196/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.8474\n","Epoch 197/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.8171\n","Epoch 198/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.8805\n","Epoch 199/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.8563\n","Epoch 200/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.8460\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.8268\n","0.8267716765403748\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1893 - accuracy: 0.4286\n","0.4285714328289032\n","5/5 [==============================] - 0s 3ms/step - loss: 0.0823 - accuracy: 0.7548\n","0.7548387050628662\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zfwi1gH-p-qf","executionInfo":{"status":"ok","timestamp":1617249794519,"user_tz":-540,"elapsed":1625,"user":{"displayName":"최은우","photoUrl":"","userId":"09535764796893882081"}},"outputId":"2e444202-6bc1-4bda-a824-641932b98e3b"},"source":["print(list(range(1,100,1)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KvVWWAXdp-qf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617148118276,"user_tz":-540,"elapsed":633,"user":{"displayName":"최은우","photoUrl":"","userId":"09535764796893882081"}},"outputId":"761f7a96-94f3-4c31-f82c-975512cea189"},"source":["from scipy.stats import uniform as sp_randFloat\n","from scipy.stats import randint as sp_randInt  \n","\n","Float = sp_randFloat(1e-5, 1e-4)\n","print(Float)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<scipy.stats._distn_infrastructure.rv_frozen object at 0x7f709001cd90>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x9DHisxSp-qf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617181253547,"user_tz":-540,"elapsed":2090,"user":{"displayName":"최은우","photoUrl":"","userId":"09535764796893882081"}},"outputId":"c29a87a4-90b1-4eac-fb90-ffb637f0f888"},"source":["import numpy as np\n","\n","print(list(np.random.uniform(0.8, 1, 30)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0.9910936646005852, 0.9365827708750836, 0.8106257381345916, 0.8617705369727595, 0.9185189374646746, 0.8470240814514929, 0.9929941999072254, 0.9890096447585588, 0.9696801761675378, 0.8944647992576805, 0.9682953429796795, 0.8262221284695829, 0.8617467314595672, 0.8925992788308834, 0.9483694401366933, 0.8971650457417794, 0.8273752237594902, 0.8687073059408716, 0.8648852339344886, 0.8600837808636079, 0.8331002800931575, 0.8829803545146504, 0.8896241315005446, 0.9549800751628035, 0.9592781401565097, 0.9044780256003224, 0.8921260592326554, 0.9556427203087794, 0.977457790370547, 0.9349837539733575]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dcpjiQmzioQZ"},"source":["from imblearn.over_sampling import SMOTE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYZKETM14-1s","executionInfo":{"status":"ok","timestamp":1617374197276,"user_tz":-540,"elapsed":478751,"user":{"displayName":"최은우","photoUrl":"","userId":"09535764796893882081"}},"outputId":"da4193d2-2aff-48c5-8317-ac5d868aa3ae"},"source":["import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import BatchNormalization\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.decomposition import PCA\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","seed=0\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","\n","#데이터 입력\n","df = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/csv/PA_internal_withothers.csv')\n","df1 = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/csv/PA_external_withothers.csv')\n","df2 = pd.concat([df, df1])\n","\n","#데이터 분류\n","#dataset = df.values\n","#X = dataset[:,0:-1]\n","#Y = dataset[:,-1]\n","\n","#ex_data =df1.values\n","#exX = ex_data[:,0:-1]\n","#exY = ex_data[:,-1]\n","\n","tot_data = df2.values\n","totX = tot_data[:,0:-1]\n","totY = tot_data[:,-1]\n","\n","#X 표준화\n","\n","pca = PCA(n_components=20)\n","\n","#X_scaled = scaler.fit_transform(X)\n","#exX_scaled = scaler.transform(exX)\n","totX_scaled = pca.fit_transform(totX)\n","\n","#Y 인코딩\n","\n","#Y_encoded = tf.keras.utils.to_categorical(Y)\n","#exY_encoded = tf.keras.utils.to_categorical(exY)\n","totY_encoded = tf.keras.utils.to_categorical(totY)\n","\n","#k겹 교차검증용 데이터 split\n","\n","n_fold = 10\n","skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n","\n","#빈 accu 배열\n","\n","accuracy = []\n","\n","#모델 설정, 컴파일, 실행\n","\n","input_dim = totX_scaled.shape[1]\n","n_class = 4\n","\n","for train, test in skf.split(totX_scaled, totY):\n","    model = Sequential()\n","    model.add(Dense(1000, input_dim = input_dim, activation='relu'))\n","    model.add(Dense(500, input_dim = input_dim, activation='relu'))\n","    model.add(Dense(300, input_dim = input_dim, activation='relu'))\n","    model.add(Dense(200, input_dim = input_dim, activation='relu'))\n","    model.add(Dense(100, input_dim = input_dim, activation='relu'))\n","    model.add(Dense(n_class, activation='softmax'))\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.fit(totX_scaled[train], totY[train], epochs=500, batch_size=5)\n","    k_accuracy = '%.4f' % (model.evaluate(totX_scaled[test], totY[test])[1])\n","    accuracy.append(k_accuracy)\n","\n","#결과 출력 \n","\n","print('\\n %.f fold accuracy:' % n_fold, accuracy)\n","\n","model.save('PA_ann_0402_2.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","Epoch 7/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1175.6037 - accuracy: 0.2885\n","Epoch 8/500\n","28/28 [==============================] - 0s 2ms/step - loss: 714.6125 - accuracy: 0.5210\n","Epoch 9/500\n","28/28 [==============================] - 0s 3ms/step - loss: 308.7324 - accuracy: 0.3821\n","Epoch 10/500\n","28/28 [==============================] - 0s 3ms/step - loss: 153.9510 - accuracy: 0.3764\n","Epoch 11/500\n","28/28 [==============================] - 0s 2ms/step - loss: 149.7351 - accuracy: 0.4850\n","Epoch 12/500\n","28/28 [==============================] - 0s 2ms/step - loss: 207.7498 - accuracy: 0.3569\n","Epoch 13/500\n","28/28 [==============================] - 0s 3ms/step - loss: 402.7594 - accuracy: 0.4071\n","Epoch 14/500\n","28/28 [==============================] - 0s 2ms/step - loss: 359.2771 - accuracy: 0.4184\n","Epoch 15/500\n","28/28 [==============================] - 0s 2ms/step - loss: 154.7456 - accuracy: 0.5212\n","Epoch 16/500\n","28/28 [==============================] - 0s 2ms/step - loss: 150.1894 - accuracy: 0.4301\n","Epoch 17/500\n","28/28 [==============================] - 0s 3ms/step - loss: 52.3057 - accuracy: 0.5219\n","Epoch 18/500\n","28/28 [==============================] - 0s 2ms/step - loss: 114.2358 - accuracy: 0.4739\n","Epoch 19/500\n","28/28 [==============================] - 0s 3ms/step - loss: 88.3557 - accuracy: 0.5096\n","Epoch 20/500\n","28/28 [==============================] - 0s 2ms/step - loss: 94.0956 - accuracy: 0.3868\n","Epoch 21/500\n","28/28 [==============================] - 0s 2ms/step - loss: 134.0043 - accuracy: 0.4066\n","Epoch 22/500\n","28/28 [==============================] - 0s 3ms/step - loss: 62.5514 - accuracy: 0.4313\n","Epoch 23/500\n","28/28 [==============================] - 0s 3ms/step - loss: 75.7548 - accuracy: 0.3997\n","Epoch 24/500\n","28/28 [==============================] - 0s 2ms/step - loss: 46.3215 - accuracy: 0.4623\n","Epoch 25/500\n","28/28 [==============================] - 0s 2ms/step - loss: 20.2587 - accuracy: 0.4192\n","Epoch 26/500\n","28/28 [==============================] - 0s 3ms/step - loss: 13.3172 - accuracy: 0.4903\n","Epoch 27/500\n","28/28 [==============================] - 0s 2ms/step - loss: 28.4305 - accuracy: 0.4947\n","Epoch 28/500\n","28/28 [==============================] - 0s 3ms/step - loss: 43.2042 - accuracy: 0.4416\n","Epoch 29/500\n","28/28 [==============================] - 0s 3ms/step - loss: 41.8113 - accuracy: 0.4699\n","Epoch 30/500\n","28/28 [==============================] - 0s 3ms/step - loss: 125.4347 - accuracy: 0.4474\n","Epoch 31/500\n","28/28 [==============================] - 0s 2ms/step - loss: 22.3045 - accuracy: 0.4044\n","Epoch 32/500\n","28/28 [==============================] - 0s 2ms/step - loss: 20.1056 - accuracy: 0.4811\n","Epoch 33/500\n","28/28 [==============================] - 0s 3ms/step - loss: 11.5521 - accuracy: 0.4787\n","Epoch 34/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.7481 - accuracy: 0.5424\n","Epoch 35/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.9830 - accuracy: 0.6004\n","Epoch 36/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.7649 - accuracy: 0.4580\n","Epoch 37/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.4466 - accuracy: 0.5356\n","Epoch 38/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.7882 - accuracy: 0.4194\n","Epoch 39/500\n","28/28 [==============================] - 0s 2ms/step - loss: 7.3783 - accuracy: 0.4507\n","Epoch 40/500\n","28/28 [==============================] - 0s 2ms/step - loss: 6.5543 - accuracy: 0.5129\n","Epoch 41/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.4375 - accuracy: 0.5904\n","Epoch 42/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.2041 - accuracy: 0.5831\n","Epoch 43/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.1940 - accuracy: 0.4107\n","Epoch 44/500\n","28/28 [==============================] - 0s 2ms/step - loss: 7.1055 - accuracy: 0.4608\n","Epoch 45/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.2935 - accuracy: 0.5435\n","Epoch 46/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.2681 - accuracy: 0.5478\n","Epoch 47/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.7694 - accuracy: 0.4970\n","Epoch 48/500\n","28/28 [==============================] - 0s 3ms/step - loss: 18.9579 - accuracy: 0.5686\n","Epoch 49/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.3229 - accuracy: 0.4445\n","Epoch 50/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.3672 - accuracy: 0.4399\n","Epoch 51/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.4620 - accuracy: 0.4948\n","Epoch 52/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.6830 - accuracy: 0.4976\n","Epoch 53/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.7865 - accuracy: 0.4591\n","Epoch 54/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.7499 - accuracy: 0.4849\n","Epoch 55/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.4606 - accuracy: 0.4548\n","Epoch 56/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.5714 - accuracy: 0.4483\n","Epoch 57/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.5794 - accuracy: 0.6370\n","Epoch 58/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.9960 - accuracy: 0.4830\n","Epoch 59/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.3387 - accuracy: 0.5552\n","Epoch 60/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.3906 - accuracy: 0.5513\n","Epoch 61/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.5205 - accuracy: 0.5360\n","Epoch 62/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0962 - accuracy: 0.6161\n","Epoch 63/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9815 - accuracy: 0.5846\n","Epoch 64/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.5139 - accuracy: 0.4355\n","Epoch 65/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.4819 - accuracy: 0.5213\n","Epoch 66/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1688 - accuracy: 0.6432\n","Epoch 67/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0899 - accuracy: 0.5359\n","Epoch 68/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0345 - accuracy: 0.6026\n","Epoch 69/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1235 - accuracy: 0.5055\n","Epoch 70/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8709 - accuracy: 0.6708\n","Epoch 71/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.3080 - accuracy: 0.6081\n","Epoch 72/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0867 - accuracy: 0.5865\n","Epoch 73/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9050 - accuracy: 0.5721\n","Epoch 74/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9501 - accuracy: 0.5737\n","Epoch 75/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0616 - accuracy: 0.5100\n","Epoch 76/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0778 - accuracy: 0.5433\n","Epoch 77/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9289 - accuracy: 0.6333\n","Epoch 78/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.5032\n","Epoch 79/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9388 - accuracy: 0.6574\n","Epoch 80/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0672 - accuracy: 0.4908\n","Epoch 81/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2277 - accuracy: 0.4815\n","Epoch 82/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0014 - accuracy: 0.5474\n","Epoch 83/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9393 - accuracy: 0.5208\n","Epoch 84/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0609 - accuracy: 0.4479\n","Epoch 85/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2346 - accuracy: 0.4020\n","Epoch 86/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1011 - accuracy: 0.4900\n","Epoch 87/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1764 - accuracy: 0.4038\n","Epoch 88/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1219 - accuracy: 0.3931\n","Epoch 89/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0392 - accuracy: 0.4894\n","Epoch 90/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9675 - accuracy: 0.5027\n","Epoch 91/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.4134 - accuracy: 0.4372\n","Epoch 92/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.5295 - accuracy: 0.4044\n","Epoch 93/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.4667 - accuracy: 0.3574\n","Epoch 94/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.1290 - accuracy: 0.4138\n","Epoch 95/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.6661 - accuracy: 0.5362\n","Epoch 96/500\n","28/28 [==============================] - 0s 2ms/step - loss: 23.5494 - accuracy: 0.4675\n","Epoch 97/500\n","28/28 [==============================] - 0s 2ms/step - loss: 6.2872 - accuracy: 0.4994\n","Epoch 98/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.7383 - accuracy: 0.5468\n","Epoch 99/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1792 - accuracy: 0.4505\n","Epoch 100/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2970 - accuracy: 0.5706\n","Epoch 101/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0878 - accuracy: 0.4724\n","Epoch 102/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1205 - accuracy: 0.4765\n","Epoch 103/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0203 - accuracy: 0.4988\n","Epoch 104/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0763 - accuracy: 0.5168\n","Epoch 105/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0577 - accuracy: 0.5108\n","Epoch 106/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0777 - accuracy: 0.4856\n","Epoch 107/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0865 - accuracy: 0.5112\n","Epoch 108/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0508 - accuracy: 0.4946\n","Epoch 109/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9536 - accuracy: 0.5990\n","Epoch 110/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0856 - accuracy: 0.4699\n","Epoch 111/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9854 - accuracy: 0.5305\n","Epoch 112/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0263 - accuracy: 0.4888\n","Epoch 113/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0652 - accuracy: 0.5304\n","Epoch 114/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0121 - accuracy: 0.5449\n","Epoch 115/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0782 - accuracy: 0.4738\n","Epoch 116/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0526 - accuracy: 0.5054\n","Epoch 117/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0881 - accuracy: 0.4771\n","Epoch 118/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0124 - accuracy: 0.4981\n","Epoch 119/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0568 - accuracy: 0.4984\n","Epoch 120/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0475 - accuracy: 0.5564\n","Epoch 121/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0440 - accuracy: 0.4891\n","Epoch 122/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0695 - accuracy: 0.4479\n","Epoch 123/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0547 - accuracy: 0.4590\n","Epoch 124/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9969 - accuracy: 0.5416\n","Epoch 125/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0111 - accuracy: 0.5038\n","Epoch 126/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0823 - accuracy: 0.4637\n","Epoch 127/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0882 - accuracy: 0.4613\n","Epoch 128/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0535 - accuracy: 0.5026\n","Epoch 129/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0887 - accuracy: 0.4457\n","Epoch 130/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0214 - accuracy: 0.5256\n","Epoch 131/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1007 - accuracy: 0.4703\n","Epoch 132/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0374 - accuracy: 0.4758\n","Epoch 133/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0330 - accuracy: 0.4701\n","Epoch 134/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0532 - accuracy: 0.5351\n","Epoch 135/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0545 - accuracy: 0.4868\n","Epoch 136/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0610 - accuracy: 0.4585\n","Epoch 137/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0145 - accuracy: 0.4905\n","Epoch 138/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0666 - accuracy: 0.4186\n","Epoch 139/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0199 - accuracy: 0.5110\n","Epoch 140/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0382 - accuracy: 0.5415\n","Epoch 141/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0884 - accuracy: 0.4762\n","Epoch 142/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0799 - accuracy: 0.4931\n","Epoch 143/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0214 - accuracy: 0.5551\n","Epoch 144/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0867 - accuracy: 0.5077\n","Epoch 145/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0753 - accuracy: 0.5182\n","Epoch 146/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0122 - accuracy: 0.5596\n","Epoch 147/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0573 - accuracy: 0.4892\n","Epoch 148/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0649 - accuracy: 0.5351\n","Epoch 149/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0549 - accuracy: 0.4709\n","Epoch 150/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0010 - accuracy: 0.5124\n","Epoch 151/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0735 - accuracy: 0.5103\n","Epoch 152/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0822 - accuracy: 0.4491\n","Epoch 153/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0683 - accuracy: 0.5149\n","Epoch 154/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.5319\n","Epoch 155/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0134 - accuracy: 0.5306\n","Epoch 156/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0670 - accuracy: 0.4989\n","Epoch 157/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1238 - accuracy: 0.4544\n","Epoch 158/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0918 - accuracy: 0.4611\n","Epoch 159/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9592 - accuracy: 0.4916\n","Epoch 160/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0359 - accuracy: 0.4828\n","Epoch 161/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0602 - accuracy: 0.4591\n","Epoch 162/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9652 - accuracy: 0.5052\n","Epoch 163/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0288 - accuracy: 0.4491\n","Epoch 164/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1026 - accuracy: 0.5015\n","Epoch 165/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0173 - accuracy: 0.4834\n","Epoch 166/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1092 - accuracy: 0.4698\n","Epoch 167/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0214 - accuracy: 0.5197\n","Epoch 168/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0288 - accuracy: 0.5023\n","Epoch 169/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9916 - accuracy: 0.5610\n","Epoch 170/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0042 - accuracy: 0.4745\n","Epoch 171/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0535 - accuracy: 0.5541\n","Epoch 172/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0578 - accuracy: 0.4819\n","Epoch 173/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0628 - accuracy: 0.4964\n","Epoch 174/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0304 - accuracy: 0.4599\n","Epoch 175/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0431 - accuracy: 0.5050\n","Epoch 176/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0638 - accuracy: 0.5033\n","Epoch 177/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0459 - accuracy: 0.5260\n","Epoch 178/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1592 - accuracy: 0.4278\n","Epoch 179/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9647 - accuracy: 0.5509\n","Epoch 180/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1504 - accuracy: 0.4427\n","Epoch 181/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9683 - accuracy: 0.5037\n","Epoch 182/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0179 - accuracy: 0.5584\n","Epoch 183/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0418 - accuracy: 0.5706\n","Epoch 184/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0907 - accuracy: 0.4552\n","Epoch 185/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0774 - accuracy: 0.4754\n","Epoch 186/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0276 - accuracy: 0.5482\n","Epoch 187/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0428 - accuracy: 0.4540\n","Epoch 188/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0900 - accuracy: 0.4399\n","Epoch 189/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0669 - accuracy: 0.5171\n","Epoch 190/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1432 - accuracy: 0.4704\n","Epoch 191/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0494 - accuracy: 0.5104\n","Epoch 192/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0061 - accuracy: 0.5754\n","Epoch 193/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0927 - accuracy: 0.4474\n","Epoch 194/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0475 - accuracy: 0.4895\n","Epoch 195/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0294 - accuracy: 0.5495\n","Epoch 196/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1575 - accuracy: 0.4715\n","Epoch 197/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0785 - accuracy: 0.4714\n","Epoch 198/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9978 - accuracy: 0.4983\n","Epoch 199/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0909 - accuracy: 0.4682\n","Epoch 200/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0730 - accuracy: 0.4851\n","Epoch 201/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0378 - accuracy: 0.5362\n","Epoch 202/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0530 - accuracy: 0.4652\n","Epoch 203/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0494 - accuracy: 0.5182\n","Epoch 204/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1256 - accuracy: 0.4741\n","Epoch 205/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0353 - accuracy: 0.5007\n","Epoch 206/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1170 - accuracy: 0.4603\n","Epoch 207/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0703 - accuracy: 0.5040\n","Epoch 208/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0618 - accuracy: 0.4775\n","Epoch 209/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0915 - accuracy: 0.4215\n","Epoch 210/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0444 - accuracy: 0.5454\n","Epoch 211/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0509 - accuracy: 0.5143\n","Epoch 212/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0389 - accuracy: 0.5354\n","Epoch 213/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0011 - accuracy: 0.5289\n","Epoch 214/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0602 - accuracy: 0.4864\n","Epoch 215/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0575 - accuracy: 0.5086\n","Epoch 216/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0529 - accuracy: 0.5131\n","Epoch 217/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0992 - accuracy: 0.4850\n","Epoch 218/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1448 - accuracy: 0.4367\n","Epoch 219/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0739 - accuracy: 0.4753\n","Epoch 220/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1180 - accuracy: 0.4503\n","Epoch 221/500\n","28/28 [==============================] - 0s 4ms/step - loss: 1.0866 - accuracy: 0.5166\n","Epoch 222/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0934 - accuracy: 0.5007\n","Epoch 223/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1778 - accuracy: 0.4828\n","Epoch 224/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1248 - accuracy: 0.4516\n","Epoch 225/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1201 - accuracy: 0.4389\n","Epoch 226/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9948 - accuracy: 0.5455\n","Epoch 227/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0240 - accuracy: 0.4911\n","Epoch 228/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0005 - accuracy: 0.5433\n","Epoch 229/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0939 - accuracy: 0.4877\n","Epoch 230/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0941 - accuracy: 0.4763\n","Epoch 231/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1564 - accuracy: 0.4647\n","Epoch 232/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0899 - accuracy: 0.5352\n","Epoch 233/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1170 - accuracy: 0.4351\n","Epoch 234/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0713 - accuracy: 0.5061\n","Epoch 235/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.5089\n","Epoch 236/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0346 - accuracy: 0.5019\n","Epoch 237/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1006 - accuracy: 0.5116\n","Epoch 238/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0424 - accuracy: 0.5437\n","Epoch 239/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0937 - accuracy: 0.5023\n","Epoch 240/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0285 - accuracy: 0.5703\n","Epoch 241/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.4800\n","Epoch 242/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1571 - accuracy: 0.4247\n","Epoch 243/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0546 - accuracy: 0.5348\n","Epoch 244/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1479 - accuracy: 0.4736\n","Epoch 245/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0804 - accuracy: 0.5175\n","Epoch 246/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0141 - accuracy: 0.4775\n","Epoch 247/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0319 - accuracy: 0.4819\n","Epoch 248/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0726 - accuracy: 0.4976\n","Epoch 249/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1356 - accuracy: 0.4868\n","Epoch 250/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0140 - accuracy: 0.5179\n","Epoch 251/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0623 - accuracy: 0.4869\n","Epoch 252/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0769 - accuracy: 0.4923\n","Epoch 253/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0155 - accuracy: 0.5204\n","Epoch 254/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0837 - accuracy: 0.4904\n","Epoch 255/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0636 - accuracy: 0.4968\n","Epoch 256/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0876 - accuracy: 0.5069\n","Epoch 257/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1601 - accuracy: 0.4728\n","Epoch 258/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.4840\n","Epoch 259/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0619 - accuracy: 0.5387\n","Epoch 260/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0421 - accuracy: 0.5166\n","Epoch 261/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0740 - accuracy: 0.5158\n","Epoch 262/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0658 - accuracy: 0.5360\n","Epoch 263/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0405 - accuracy: 0.4456\n","Epoch 264/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1467 - accuracy: 0.5200\n","Epoch 265/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0792 - accuracy: 0.4803\n","Epoch 266/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0394 - accuracy: 0.4549\n","Epoch 267/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0623 - accuracy: 0.5173\n","Epoch 268/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0783 - accuracy: 0.4318\n","Epoch 269/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0372 - accuracy: 0.5279\n","Epoch 270/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0678 - accuracy: 0.5558\n","Epoch 271/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0635 - accuracy: 0.5226\n","Epoch 272/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9437 - accuracy: 0.5219\n","Epoch 273/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0663 - accuracy: 0.4972\n","Epoch 274/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0955 - accuracy: 0.4743\n","Epoch 275/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0964 - accuracy: 0.5050\n","Epoch 276/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0535 - accuracy: 0.4433\n","Epoch 277/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0540 - accuracy: 0.4734\n","Epoch 278/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9743 - accuracy: 0.5472\n","Epoch 279/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0576 - accuracy: 0.5256\n","Epoch 280/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0193 - accuracy: 0.4893\n","Epoch 281/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.4483\n","Epoch 282/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0580 - accuracy: 0.5655\n","Epoch 283/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1132 - accuracy: 0.5215\n","Epoch 284/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0209 - accuracy: 0.4931\n","Epoch 285/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0423 - accuracy: 0.5483\n","Epoch 286/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1382 - accuracy: 0.4288\n","Epoch 287/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0759 - accuracy: 0.4129\n","Epoch 288/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1304 - accuracy: 0.4661\n","Epoch 289/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0237 - accuracy: 0.5045\n","Epoch 290/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9958 - accuracy: 0.5239\n","Epoch 291/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1474 - accuracy: 0.4556\n","Epoch 292/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1230 - accuracy: 0.4189\n","Epoch 293/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0745 - accuracy: 0.5107\n","Epoch 294/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0520 - accuracy: 0.5182\n","Epoch 295/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1767 - accuracy: 0.4146\n","Epoch 296/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9479 - accuracy: 0.5388\n","Epoch 297/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1317 - accuracy: 0.5177\n","Epoch 298/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1128 - accuracy: 0.5296\n","Epoch 299/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0905 - accuracy: 0.4445\n","Epoch 300/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0473 - accuracy: 0.5563\n","Epoch 301/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9298 - accuracy: 0.5790\n","Epoch 302/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0158 - accuracy: 0.5469\n","Epoch 303/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0242 - accuracy: 0.5695\n","Epoch 304/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0810 - accuracy: 0.5048\n","Epoch 305/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1022 - accuracy: 0.4612\n","Epoch 306/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0139 - accuracy: 0.4778\n","Epoch 307/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0731 - accuracy: 0.5155\n","Epoch 308/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0446 - accuracy: 0.5092\n","Epoch 309/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0018 - accuracy: 0.5083\n","Epoch 310/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0477 - accuracy: 0.5416\n","Epoch 311/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0105 - accuracy: 0.5809\n","Epoch 312/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0715 - accuracy: 0.4359\n","Epoch 313/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0787 - accuracy: 0.4185\n","Epoch 314/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0586 - accuracy: 0.4565\n","Epoch 315/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0155 - accuracy: 0.5266\n","Epoch 316/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0311 - accuracy: 0.4893\n","Epoch 317/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1146 - accuracy: 0.4645\n","Epoch 318/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0888 - accuracy: 0.5061\n","Epoch 319/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0133 - accuracy: 0.5344\n","Epoch 320/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0543 - accuracy: 0.4931\n","Epoch 321/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1695 - accuracy: 0.4248\n","Epoch 322/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0820 - accuracy: 0.4603\n","Epoch 323/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1240 - accuracy: 0.4713\n","Epoch 324/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1569 - accuracy: 0.4663\n","Epoch 325/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0175 - accuracy: 0.5775\n","Epoch 326/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0387 - accuracy: 0.4869\n","Epoch 327/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1170 - accuracy: 0.4220\n","Epoch 328/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0427 - accuracy: 0.5194\n","Epoch 329/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0614 - accuracy: 0.4817\n","Epoch 330/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1366 - accuracy: 0.4195\n","Epoch 331/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1098 - accuracy: 0.5080\n","Epoch 332/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9842 - accuracy: 0.5265\n","Epoch 333/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0954 - accuracy: 0.5022\n","Epoch 334/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0703 - accuracy: 0.4715\n","Epoch 335/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0570 - accuracy: 0.5069\n","Epoch 336/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0812 - accuracy: 0.4990\n","Epoch 337/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1027 - accuracy: 0.5155\n","Epoch 338/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0802 - accuracy: 0.5046\n","Epoch 339/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0983 - accuracy: 0.5111\n","Epoch 340/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0405 - accuracy: 0.4512\n","Epoch 341/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0388 - accuracy: 0.5009\n","Epoch 342/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0164 - accuracy: 0.5402\n","Epoch 343/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1493 - accuracy: 0.4419\n","Epoch 344/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0408 - accuracy: 0.4610\n","Epoch 345/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0207 - accuracy: 0.4945\n","Epoch 346/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0346 - accuracy: 0.5180\n","Epoch 347/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1488 - accuracy: 0.4187\n","Epoch 348/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0557 - accuracy: 0.4833\n","Epoch 349/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1081 - accuracy: 0.5099\n","Epoch 350/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0469 - accuracy: 0.4881\n","Epoch 351/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0846 - accuracy: 0.4614\n","Epoch 352/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0533 - accuracy: 0.5214\n","Epoch 353/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9572 - accuracy: 0.5585\n","Epoch 354/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9946 - accuracy: 0.5388\n","Epoch 355/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0397 - accuracy: 0.4737\n","Epoch 356/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0805 - accuracy: 0.4467\n","Epoch 357/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0630 - accuracy: 0.5072\n","Epoch 358/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0299 - accuracy: 0.5205\n","Epoch 359/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0943 - accuracy: 0.4849\n","Epoch 360/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0905 - accuracy: 0.4895\n","Epoch 361/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0495 - accuracy: 0.4677\n","Epoch 362/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0735 - accuracy: 0.5150\n","Epoch 363/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0627 - accuracy: 0.4764\n","Epoch 364/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9757 - accuracy: 0.5513\n","Epoch 365/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9941 - accuracy: 0.5119\n","Epoch 366/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0830 - accuracy: 0.5173\n","Epoch 367/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0362 - accuracy: 0.4057\n","Epoch 368/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0919 - accuracy: 0.5046\n","Epoch 369/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0691 - accuracy: 0.4558\n","Epoch 370/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1279 - accuracy: 0.4876\n","Epoch 371/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0334 - accuracy: 0.4845\n","Epoch 372/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0004 - accuracy: 0.5547\n","Epoch 373/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0465 - accuracy: 0.5303\n","Epoch 374/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1073 - accuracy: 0.5232\n","Epoch 375/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1386 - accuracy: 0.4242\n","Epoch 376/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9730 - accuracy: 0.4868\n","Epoch 377/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0912 - accuracy: 0.4827\n","Epoch 378/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1835 - accuracy: 0.4643\n","Epoch 379/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9889 - accuracy: 0.5395\n","Epoch 380/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0458 - accuracy: 0.4910\n","Epoch 381/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9974 - accuracy: 0.5235\n","Epoch 382/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1124 - accuracy: 0.4918\n","Epoch 383/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1963 - accuracy: 0.4408\n","Epoch 384/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0327 - accuracy: 0.5229\n","Epoch 385/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1628 - accuracy: 0.4762\n","Epoch 386/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0087 - accuracy: 0.5263\n","Epoch 387/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9923 - accuracy: 0.6051\n","Epoch 388/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0781 - accuracy: 0.5104\n","Epoch 389/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0801 - accuracy: 0.5075\n","Epoch 390/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0105 - accuracy: 0.5115\n","Epoch 391/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0799 - accuracy: 0.4707\n","Epoch 392/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0728 - accuracy: 0.5274\n","Epoch 393/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0244 - accuracy: 0.5285\n","Epoch 394/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0722 - accuracy: 0.4488\n","Epoch 395/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0371 - accuracy: 0.4708\n","Epoch 396/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1441 - accuracy: 0.4896\n","Epoch 397/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0648 - accuracy: 0.4960\n","Epoch 398/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0317 - accuracy: 0.4331\n","Epoch 399/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0226 - accuracy: 0.5360\n","Epoch 400/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1395 - accuracy: 0.3922\n","Epoch 401/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0838 - accuracy: 0.4954\n","Epoch 402/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0396 - accuracy: 0.4684\n","Epoch 403/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0093 - accuracy: 0.4742\n","Epoch 404/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0601 - accuracy: 0.5260\n","Epoch 405/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0564 - accuracy: 0.4886\n","Epoch 406/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0451 - accuracy: 0.4338\n","Epoch 407/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9665 - accuracy: 0.5686\n","Epoch 408/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1603 - accuracy: 0.4057\n","Epoch 409/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0274 - accuracy: 0.4929\n","Epoch 410/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1050 - accuracy: 0.4869\n","Epoch 411/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0970 - accuracy: 0.5479\n","Epoch 412/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0612 - accuracy: 0.4858\n","Epoch 413/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1272 - accuracy: 0.4410\n","Epoch 414/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1225 - accuracy: 0.4573\n","Epoch 415/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1574 - accuracy: 0.4420\n","Epoch 416/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0673 - accuracy: 0.4577\n","Epoch 417/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0396 - accuracy: 0.5267\n","Epoch 418/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0223 - accuracy: 0.5490\n","Epoch 419/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0863 - accuracy: 0.4856\n","Epoch 420/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0495 - accuracy: 0.4853\n","Epoch 421/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0765 - accuracy: 0.4773\n","Epoch 422/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0702 - accuracy: 0.4698\n","Epoch 423/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0316 - accuracy: 0.4730\n","Epoch 424/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1108 - accuracy: 0.4548\n","Epoch 425/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0833 - accuracy: 0.5032\n","Epoch 426/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0852 - accuracy: 0.5282\n","Epoch 427/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1507 - accuracy: 0.4224\n","Epoch 428/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0644 - accuracy: 0.4687\n","Epoch 429/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0251 - accuracy: 0.4586\n","Epoch 430/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0496 - accuracy: 0.4684\n","Epoch 431/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1072 - accuracy: 0.4696\n","Epoch 432/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1340 - accuracy: 0.4421\n","Epoch 433/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0679 - accuracy: 0.4937\n","Epoch 434/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1415 - accuracy: 0.4238\n","Epoch 435/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9961 - accuracy: 0.6084\n","Epoch 436/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0388 - accuracy: 0.5258\n","Epoch 437/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0446 - accuracy: 0.5174\n","Epoch 438/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0911 - accuracy: 0.4830\n","Epoch 439/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1011 - accuracy: 0.4837\n","Epoch 440/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1342 - accuracy: 0.4561\n","Epoch 441/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1098 - accuracy: 0.4393\n","Epoch 442/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0790 - accuracy: 0.4834\n","Epoch 443/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0710 - accuracy: 0.5203\n","Epoch 444/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0416 - accuracy: 0.5144\n","Epoch 445/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0991 - accuracy: 0.4622\n","Epoch 446/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0419 - accuracy: 0.4811\n","Epoch 447/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0527 - accuracy: 0.4486\n","Epoch 448/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0740 - accuracy: 0.4883\n","Epoch 449/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0940 - accuracy: 0.4954\n","Epoch 450/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0316 - accuracy: 0.4985\n","Epoch 451/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1104 - accuracy: 0.4828\n","Epoch 452/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0817 - accuracy: 0.4899\n","Epoch 453/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0314 - accuracy: 0.5199\n","Epoch 454/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0780 - accuracy: 0.4931\n","Epoch 455/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1677 - accuracy: 0.4750\n","Epoch 456/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1141 - accuracy: 0.5104\n","Epoch 457/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1458 - accuracy: 0.4839\n","Epoch 458/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0657 - accuracy: 0.5125\n","Epoch 459/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0023 - accuracy: 0.5455\n","Epoch 460/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0804 - accuracy: 0.5095\n","Epoch 461/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0885 - accuracy: 0.5142\n","Epoch 462/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0293 - accuracy: 0.5148\n","Epoch 463/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0423 - accuracy: 0.4678\n","Epoch 464/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9985 - accuracy: 0.5236\n","Epoch 465/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0438 - accuracy: 0.4614\n","Epoch 466/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0345 - accuracy: 0.5768\n","Epoch 467/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9779 - accuracy: 0.5693\n","Epoch 468/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1124 - accuracy: 0.4526\n","Epoch 469/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0693 - accuracy: 0.4513\n","Epoch 470/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0603 - accuracy: 0.5151\n","Epoch 471/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1212 - accuracy: 0.5133\n","Epoch 472/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0521 - accuracy: 0.5654\n","Epoch 473/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0879 - accuracy: 0.5173\n","Epoch 474/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0909 - accuracy: 0.5162\n","Epoch 475/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1078 - accuracy: 0.4609\n","Epoch 476/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1095 - accuracy: 0.4940\n","Epoch 477/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0293 - accuracy: 0.5132\n","Epoch 478/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0917 - accuracy: 0.4647\n","Epoch 479/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0785 - accuracy: 0.4646\n","Epoch 480/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0787 - accuracy: 0.5120\n","Epoch 481/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0723 - accuracy: 0.5111\n","Epoch 482/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1324 - accuracy: 0.4440\n","Epoch 483/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0606 - accuracy: 0.4912\n","Epoch 484/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0608 - accuracy: 0.5132\n","Epoch 485/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0121 - accuracy: 0.5058\n","Epoch 486/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0286 - accuracy: 0.5248\n","Epoch 487/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9850 - accuracy: 0.5119\n","Epoch 488/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1686 - accuracy: 0.4891\n","Epoch 489/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0899 - accuracy: 0.4969\n","Epoch 490/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0795 - accuracy: 0.5145\n","Epoch 491/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1441 - accuracy: 0.4663\n","Epoch 492/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0613 - accuracy: 0.4834\n","Epoch 493/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1450 - accuracy: 0.4751\n","Epoch 494/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0363 - accuracy: 0.5539\n","Epoch 495/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2277 - accuracy: 0.4021\n","Epoch 496/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0923 - accuracy: 0.4863\n","Epoch 497/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0974 - accuracy: 0.5004\n","Epoch 498/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1260 - accuracy: 0.4677\n","Epoch 499/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0263 - accuracy: 0.5234\n","Epoch 500/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9570 - accuracy: 0.5229\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa017bf5050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 148ms/step - loss: 2.0603 - accuracy: 0.4667\n","Epoch 1/500\n","28/28 [==============================] - 1s 3ms/step - loss: 6127.1693 - accuracy: 0.3875\n","Epoch 2/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2988.2109 - accuracy: 0.4343\n","Epoch 3/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2338.9182 - accuracy: 0.3896\n","Epoch 4/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3028.1983 - accuracy: 0.4542\n","Epoch 5/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2031.5943 - accuracy: 0.4083\n","Epoch 6/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1000.9519 - accuracy: 0.4533\n","Epoch 7/500\n","28/28 [==============================] - 0s 2ms/step - loss: 631.7742 - accuracy: 0.5366\n","Epoch 8/500\n","28/28 [==============================] - 0s 2ms/step - loss: 995.3711 - accuracy: 0.4480\n","Epoch 9/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1746.8729 - accuracy: 0.4810\n","Epoch 10/500\n","28/28 [==============================] - 0s 2ms/step - loss: 271.1083 - accuracy: 0.4375\n","Epoch 11/500\n","28/28 [==============================] - 0s 3ms/step - loss: 97.7607 - accuracy: 0.4706\n","Epoch 12/500\n","28/28 [==============================] - 0s 3ms/step - loss: 152.5636 - accuracy: 0.3359\n","Epoch 13/500\n","28/28 [==============================] - 0s 2ms/step - loss: 78.6230 - accuracy: 0.3903\n","Epoch 14/500\n","28/28 [==============================] - 0s 2ms/step - loss: 108.2017 - accuracy: 0.4727\n","Epoch 15/500\n","28/28 [==============================] - 0s 3ms/step - loss: 51.6945 - accuracy: 0.4754\n","Epoch 16/500\n","28/28 [==============================] - 0s 3ms/step - loss: 216.4176 - accuracy: 0.4708\n","Epoch 17/500\n","28/28 [==============================] - 0s 2ms/step - loss: 118.5489 - accuracy: 0.4890\n","Epoch 18/500\n","28/28 [==============================] - 0s 2ms/step - loss: 633.4532 - accuracy: 0.4666\n","Epoch 19/500\n","28/28 [==============================] - 0s 3ms/step - loss: 94.5680 - accuracy: 0.3184\n","Epoch 20/500\n","28/28 [==============================] - 0s 3ms/step - loss: 78.6448 - accuracy: 0.4334\n","Epoch 21/500\n","28/28 [==============================] - 0s 3ms/step - loss: 45.2274 - accuracy: 0.4278\n","Epoch 22/500\n","28/28 [==============================] - 0s 2ms/step - loss: 48.0506 - accuracy: 0.4896\n","Epoch 23/500\n","28/28 [==============================] - 0s 3ms/step - loss: 26.6452 - accuracy: 0.5102\n","Epoch 24/500\n","28/28 [==============================] - 0s 3ms/step - loss: 27.6476 - accuracy: 0.4135\n","Epoch 25/500\n","28/28 [==============================] - 0s 2ms/step - loss: 36.7444 - accuracy: 0.5775\n","Epoch 26/500\n","28/28 [==============================] - 0s 3ms/step - loss: 178.3135 - accuracy: 0.3787\n","Epoch 27/500\n","28/28 [==============================] - 0s 2ms/step - loss: 30.4909 - accuracy: 0.4242\n","Epoch 28/500\n","28/28 [==============================] - 0s 3ms/step - loss: 139.1890 - accuracy: 0.5027\n","Epoch 29/500\n","28/28 [==============================] - 0s 2ms/step - loss: 59.6817 - accuracy: 0.4407\n","Epoch 30/500\n","28/28 [==============================] - 0s 3ms/step - loss: 39.0377 - accuracy: 0.4132\n","Epoch 31/500\n","28/28 [==============================] - 0s 2ms/step - loss: 87.1011 - accuracy: 0.4118\n","Epoch 32/500\n","28/28 [==============================] - 0s 2ms/step - loss: 35.1980 - accuracy: 0.4830\n","Epoch 33/500\n","28/28 [==============================] - 0s 2ms/step - loss: 96.1966 - accuracy: 0.5286\n","Epoch 34/500\n","28/28 [==============================] - 0s 2ms/step - loss: 31.0088 - accuracy: 0.4299\n","Epoch 35/500\n","28/28 [==============================] - 0s 3ms/step - loss: 29.6634 - accuracy: 0.4253\n","Epoch 36/500\n","28/28 [==============================] - 0s 2ms/step - loss: 17.0306 - accuracy: 0.5075\n","Epoch 37/500\n","28/28 [==============================] - 0s 2ms/step - loss: 34.1939 - accuracy: 0.4832\n","Epoch 38/500\n","28/28 [==============================] - 0s 2ms/step - loss: 39.0100 - accuracy: 0.4291\n","Epoch 39/500\n","28/28 [==============================] - 0s 2ms/step - loss: 15.1598 - accuracy: 0.6213\n","Epoch 40/500\n","28/28 [==============================] - 0s 3ms/step - loss: 21.9101 - accuracy: 0.3905\n","Epoch 41/500\n","28/28 [==============================] - 0s 3ms/step - loss: 9.0956 - accuracy: 0.5527\n","Epoch 42/500\n","28/28 [==============================] - 0s 2ms/step - loss: 12.9347 - accuracy: 0.5482\n","Epoch 43/500\n","28/28 [==============================] - 0s 3ms/step - loss: 25.2990 - accuracy: 0.4609\n","Epoch 44/500\n","28/28 [==============================] - 0s 2ms/step - loss: 9.8452 - accuracy: 0.4890\n","Epoch 45/500\n","28/28 [==============================] - 0s 3ms/step - loss: 13.6041 - accuracy: 0.4592\n","Epoch 46/500\n","28/28 [==============================] - 0s 2ms/step - loss: 7.7629 - accuracy: 0.5270\n","Epoch 47/500\n","28/28 [==============================] - 0s 2ms/step - loss: 9.9231 - accuracy: 0.5602\n","Epoch 48/500\n","28/28 [==============================] - 0s 3ms/step - loss: 12.4531 - accuracy: 0.3819\n","Epoch 49/500\n","28/28 [==============================] - 0s 3ms/step - loss: 17.6894 - accuracy: 0.4648\n","Epoch 50/500\n","28/28 [==============================] - 0s 2ms/step - loss: 19.6757 - accuracy: 0.4055\n","Epoch 51/500\n","28/28 [==============================] - 0s 3ms/step - loss: 10.0897 - accuracy: 0.5492\n","Epoch 52/500\n","28/28 [==============================] - 0s 2ms/step - loss: 5.0764 - accuracy: 0.5354\n","Epoch 53/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.2487 - accuracy: 0.5274\n","Epoch 54/500\n","28/28 [==============================] - 0s 3ms/step - loss: 13.7282 - accuracy: 0.3858\n","Epoch 55/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.6315 - accuracy: 0.4837\n","Epoch 56/500\n","28/28 [==============================] - 0s 3ms/step - loss: 8.0365 - accuracy: 0.4352\n","Epoch 57/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.9382 - accuracy: 0.5162\n","Epoch 58/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.4431 - accuracy: 0.5251\n","Epoch 59/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.0313 - accuracy: 0.6374\n","Epoch 60/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.6934 - accuracy: 0.5669\n","Epoch 61/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.4210 - accuracy: 0.6286\n","Epoch 62/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.2397 - accuracy: 0.5287\n","Epoch 63/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.2851 - accuracy: 0.5476\n","Epoch 64/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.2624 - accuracy: 0.4830\n","Epoch 65/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.7162 - accuracy: 0.5343\n","Epoch 66/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.7752 - accuracy: 0.5541\n","Epoch 67/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.8073 - accuracy: 0.5907\n","Epoch 68/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.7618 - accuracy: 0.5612\n","Epoch 69/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.4256 - accuracy: 0.4616\n","Epoch 70/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.4954 - accuracy: 0.6314\n","Epoch 71/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.6282 - accuracy: 0.5593\n","Epoch 72/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.8594 - accuracy: 0.4601\n","Epoch 73/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.6893 - accuracy: 0.4990\n","Epoch 74/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.1696 - accuracy: 0.5813\n","Epoch 75/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.6305 - accuracy: 0.5047\n","Epoch 76/500\n","28/28 [==============================] - 0s 3ms/step - loss: 89.7663 - accuracy: 0.4592\n","Epoch 77/500\n","28/28 [==============================] - 0s 3ms/step - loss: 74.3927 - accuracy: 0.4493\n","Epoch 78/500\n","28/28 [==============================] - 0s 2ms/step - loss: 15.9975 - accuracy: 0.4569\n","Epoch 79/500\n","28/28 [==============================] - 0s 2ms/step - loss: 47.9632 - accuracy: 0.4490\n","Epoch 80/500\n","28/28 [==============================] - 0s 3ms/step - loss: 9.1308 - accuracy: 0.4700\n","Epoch 81/500\n","28/28 [==============================] - 0s 3ms/step - loss: 16.3786 - accuracy: 0.4808\n","Epoch 82/500\n","28/28 [==============================] - 0s 2ms/step - loss: 12.5098 - accuracy: 0.5035\n","Epoch 83/500\n","28/28 [==============================] - 0s 2ms/step - loss: 13.6421 - accuracy: 0.4531\n","Epoch 84/500\n","28/28 [==============================] - 0s 2ms/step - loss: 16.2427 - accuracy: 0.4025\n","Epoch 85/500\n","28/28 [==============================] - 0s 2ms/step - loss: 7.1219 - accuracy: 0.4277\n","Epoch 86/500\n","28/28 [==============================] - 0s 2ms/step - loss: 6.1054 - accuracy: 0.4439\n","Epoch 87/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.3107 - accuracy: 0.4953\n","Epoch 88/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.9856 - accuracy: 0.4292\n","Epoch 89/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.4952 - accuracy: 0.5198\n","Epoch 90/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.9650 - accuracy: 0.4258\n","Epoch 91/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.2481 - accuracy: 0.5639\n","Epoch 92/500\n","28/28 [==============================] - 0s 3ms/step - loss: 9.2953 - accuracy: 0.4493\n","Epoch 93/500\n","28/28 [==============================] - 0s 2ms/step - loss: 7.2498 - accuracy: 0.4797\n","Epoch 94/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.2288 - accuracy: 0.4160\n","Epoch 95/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.6936 - accuracy: 0.5125\n","Epoch 96/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.3874 - accuracy: 0.4149\n","Epoch 97/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.5479 - accuracy: 0.5433\n","Epoch 98/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.1188 - accuracy: 0.4524\n","Epoch 99/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.6494 - accuracy: 0.4685\n","Epoch 100/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1455 - accuracy: 0.5913\n","Epoch 101/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.8894 - accuracy: 0.4791\n","Epoch 102/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.9160 - accuracy: 0.5181\n","Epoch 103/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.2298 - accuracy: 0.5585\n","Epoch 104/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.9926 - accuracy: 0.6319\n","Epoch 105/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.1454 - accuracy: 0.4269\n","Epoch 106/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.5614 - accuracy: 0.5470\n","Epoch 107/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.9978 - accuracy: 0.5336\n","Epoch 108/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.4862 - accuracy: 0.5278\n","Epoch 109/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.2410 - accuracy: 0.5206\n","Epoch 110/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.0717 - accuracy: 0.5291\n","Epoch 111/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2011 - accuracy: 0.5316\n","Epoch 112/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1036 - accuracy: 0.4908\n","Epoch 113/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2239 - accuracy: 0.4165\n","Epoch 114/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.3786 - accuracy: 0.4625\n","Epoch 115/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0533 - accuracy: 0.4676\n","Epoch 116/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9850 - accuracy: 0.5667\n","Epoch 117/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2860 - accuracy: 0.4543\n","Epoch 118/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9611 - accuracy: 0.4617\n","Epoch 119/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.4191 - accuracy: 0.5459\n","Epoch 120/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1743 - accuracy: 0.4973\n","Epoch 121/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0118 - accuracy: 0.4937\n","Epoch 122/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.3343 - accuracy: 0.4733\n","Epoch 123/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9257 - accuracy: 0.5365\n","Epoch 124/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9490 - accuracy: 0.4944\n","Epoch 125/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.7945 - accuracy: 0.5947\n","Epoch 126/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0479 - accuracy: 0.4982\n","Epoch 127/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9833 - accuracy: 0.5495\n","Epoch 128/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0489 - accuracy: 0.4268\n","Epoch 129/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9299 - accuracy: 0.6414\n","Epoch 130/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9727 - accuracy: 0.5744\n","Epoch 131/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9069 - accuracy: 0.5604\n","Epoch 132/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9492 - accuracy: 0.5928\n","Epoch 133/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9003 - accuracy: 0.4852\n","Epoch 134/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.8168 - accuracy: 0.6078\n","Epoch 135/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.7915 - accuracy: 0.6026\n","Epoch 136/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9094 - accuracy: 0.5835\n","Epoch 137/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.8861 - accuracy: 0.5639\n","Epoch 138/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8507 - accuracy: 0.4970\n","Epoch 139/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.7959 - accuracy: 0.6225\n","Epoch 140/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9080 - accuracy: 0.5860\n","Epoch 141/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9095 - accuracy: 0.5693\n","Epoch 142/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9122 - accuracy: 0.4602\n","Epoch 143/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.7965 - accuracy: 0.6601\n","Epoch 144/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.8693 - accuracy: 0.6556\n","Epoch 145/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9615 - accuracy: 0.5033\n","Epoch 146/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8287 - accuracy: 0.6156\n","Epoch 147/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9053 - accuracy: 0.6034\n","Epoch 148/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.7146 - accuracy: 0.5920\n","Epoch 149/500\n","28/28 [==============================] - 0s 2ms/step - loss: 8.2187 - accuracy: 0.4543\n","Epoch 150/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.4277 - accuracy: 0.4405\n","Epoch 151/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2032 - accuracy: 0.4445\n","Epoch 152/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.5655 - accuracy: 0.4347\n","Epoch 153/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2218 - accuracy: 0.3913\n","Epoch 154/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1287 - accuracy: 0.4620\n","Epoch 155/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1183 - accuracy: 0.4305\n","Epoch 156/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1193 - accuracy: 0.4465\n","Epoch 157/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1228 - accuracy: 0.4211\n","Epoch 158/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0257 - accuracy: 0.4821\n","Epoch 159/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0153 - accuracy: 0.5510\n","Epoch 160/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0849 - accuracy: 0.4761\n","Epoch 161/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0218 - accuracy: 0.5667\n","Epoch 162/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9924 - accuracy: 0.5385\n","Epoch 163/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0262 - accuracy: 0.4805\n","Epoch 164/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0706 - accuracy: 0.4192\n","Epoch 165/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9936 - accuracy: 0.5066\n","Epoch 166/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0254 - accuracy: 0.4853\n","Epoch 167/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0419 - accuracy: 0.5487\n","Epoch 168/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9901 - accuracy: 0.5191\n","Epoch 169/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9924 - accuracy: 0.5673\n","Epoch 170/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9964 - accuracy: 0.5208\n","Epoch 171/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0219 - accuracy: 0.5366\n","Epoch 172/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0304 - accuracy: 0.4294\n","Epoch 173/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0044 - accuracy: 0.4951\n","Epoch 174/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9647 - accuracy: 0.5176\n","Epoch 175/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0029 - accuracy: 0.5591\n","Epoch 176/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9966 - accuracy: 0.5314\n","Epoch 177/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0427 - accuracy: 0.4987\n","Epoch 178/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1100 - accuracy: 0.5105\n","Epoch 179/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9437 - accuracy: 0.5199\n","Epoch 180/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0677 - accuracy: 0.4719\n","Epoch 181/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9253 - accuracy: 0.5527\n","Epoch 182/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9610 - accuracy: 0.5714\n","Epoch 183/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9803 - accuracy: 0.5553\n","Epoch 184/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9955 - accuracy: 0.5142\n","Epoch 185/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9628 - accuracy: 0.5183\n","Epoch 186/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9983 - accuracy: 0.5600\n","Epoch 187/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9988 - accuracy: 0.5432\n","Epoch 188/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9886 - accuracy: 0.4966\n","Epoch 189/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9674 - accuracy: 0.5663\n","Epoch 190/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0471 - accuracy: 0.5928\n","Epoch 191/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0026 - accuracy: 0.5022\n","Epoch 192/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0069 - accuracy: 0.5266\n","Epoch 193/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0424 - accuracy: 0.5042\n","Epoch 194/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9441 - accuracy: 0.5294\n","Epoch 195/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9613 - accuracy: 0.5213\n","Epoch 196/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0677 - accuracy: 0.4726\n","Epoch 197/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0127 - accuracy: 0.4684\n","Epoch 198/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9342 - accuracy: 0.5478\n","Epoch 199/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0719 - accuracy: 0.5199\n","Epoch 200/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9894 - accuracy: 0.5465\n","Epoch 201/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9847 - accuracy: 0.5391\n","Epoch 202/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0827 - accuracy: 0.4644\n","Epoch 203/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9678 - accuracy: 0.5654\n","Epoch 204/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0590 - accuracy: 0.5194\n","Epoch 205/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9775 - accuracy: 0.5460\n","Epoch 206/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0433 - accuracy: 0.5119\n","Epoch 207/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0179 - accuracy: 0.5114\n","Epoch 208/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0161 - accuracy: 0.4841\n","Epoch 209/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9937 - accuracy: 0.4927\n","Epoch 210/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0239 - accuracy: 0.5564\n","Epoch 211/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8938 - accuracy: 0.5379\n","Epoch 212/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0104 - accuracy: 0.5152\n","Epoch 213/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0091 - accuracy: 0.5088\n","Epoch 214/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9739 - accuracy: 0.5494\n","Epoch 215/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9937 - accuracy: 0.5397\n","Epoch 216/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9295 - accuracy: 0.5549\n","Epoch 217/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0368 - accuracy: 0.5166\n","Epoch 218/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0415 - accuracy: 0.4991\n","Epoch 219/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9434 - accuracy: 0.5180\n","Epoch 220/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0138 - accuracy: 0.5208\n","Epoch 221/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9601 - accuracy: 0.5740\n","Epoch 222/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9888 - accuracy: 0.5213\n","Epoch 223/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0759 - accuracy: 0.4965\n","Epoch 224/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1058 - accuracy: 0.4385\n","Epoch 225/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0076 - accuracy: 0.4804\n","Epoch 226/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9301 - accuracy: 0.5810\n","Epoch 227/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9501 - accuracy: 0.5788\n","Epoch 228/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0355 - accuracy: 0.5111\n","Epoch 229/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0193 - accuracy: 0.5201\n","Epoch 230/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0029 - accuracy: 0.5353\n","Epoch 231/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1075 - accuracy: 0.5191\n","Epoch 232/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0282 - accuracy: 0.5276\n","Epoch 233/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0203 - accuracy: 0.5006\n","Epoch 234/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0706 - accuracy: 0.4739\n","Epoch 235/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0288 - accuracy: 0.4942\n","Epoch 236/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1004 - accuracy: 0.4931\n","Epoch 237/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0694 - accuracy: 0.4797\n","Epoch 238/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9778 - accuracy: 0.5542\n","Epoch 239/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0617 - accuracy: 0.5049\n","Epoch 240/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9971 - accuracy: 0.5559\n","Epoch 241/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0031 - accuracy: 0.5260\n","Epoch 242/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0126 - accuracy: 0.5002\n","Epoch 243/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0133 - accuracy: 0.5613\n","Epoch 244/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0656 - accuracy: 0.4354\n","Epoch 245/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0378 - accuracy: 0.4925\n","Epoch 246/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9577 - accuracy: 0.5336\n","Epoch 247/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9225 - accuracy: 0.5387\n","Epoch 248/500\n","28/28 [==============================] - 0s 4ms/step - loss: 1.0878 - accuracy: 0.4949\n","Epoch 249/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0711 - accuracy: 0.5341\n","Epoch 250/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9554 - accuracy: 0.5038\n","Epoch 251/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9339 - accuracy: 0.5748\n","Epoch 252/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0363 - accuracy: 0.5405\n","Epoch 253/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0057 - accuracy: 0.5111\n","Epoch 254/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9605 - accuracy: 0.5889\n","Epoch 255/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9732 - accuracy: 0.5584\n","Epoch 256/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0431 - accuracy: 0.5380\n","Epoch 257/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0855 - accuracy: 0.5129\n","Epoch 258/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9893 - accuracy: 0.5851\n","Epoch 259/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9131 - accuracy: 0.5576\n","Epoch 260/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9818 - accuracy: 0.5305\n","Epoch 261/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9976 - accuracy: 0.5268\n","Epoch 262/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9839 - accuracy: 0.5517\n","Epoch 263/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9968 - accuracy: 0.5159\n","Epoch 264/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0222 - accuracy: 0.5443\n","Epoch 265/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9496 - accuracy: 0.5268\n","Epoch 266/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9650 - accuracy: 0.5001\n","Epoch 267/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0001 - accuracy: 0.5766\n","Epoch 268/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0238 - accuracy: 0.4970\n","Epoch 269/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9528 - accuracy: 0.5530\n","Epoch 270/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9748 - accuracy: 0.6083\n","Epoch 271/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0309 - accuracy: 0.5363\n","Epoch 272/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9192 - accuracy: 0.5151\n","Epoch 273/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0506 - accuracy: 0.5080\n","Epoch 274/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0710 - accuracy: 0.4650\n","Epoch 275/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0176 - accuracy: 0.5586\n","Epoch 276/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0540 - accuracy: 0.3890\n","Epoch 277/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0238 - accuracy: 0.5288\n","Epoch 278/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9413 - accuracy: 0.5588\n","Epoch 279/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0609 - accuracy: 0.5327\n","Epoch 280/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9819 - accuracy: 0.5093\n","Epoch 281/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9691 - accuracy: 0.4254\n","Epoch 282/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0686 - accuracy: 0.5017\n","Epoch 283/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0985 - accuracy: 0.5277\n","Epoch 284/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0052 - accuracy: 0.5100\n","Epoch 285/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9159 - accuracy: 0.6063\n","Epoch 286/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0429 - accuracy: 0.5109\n","Epoch 287/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0193 - accuracy: 0.4363\n","Epoch 288/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0114 - accuracy: 0.5129\n","Epoch 289/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0075 - accuracy: 0.5441\n","Epoch 290/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9154 - accuracy: 0.5513\n","Epoch 291/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0849 - accuracy: 0.4785\n","Epoch 292/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0262 - accuracy: 0.4752\n","Epoch 293/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9549 - accuracy: 0.5348\n","Epoch 294/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0031 - accuracy: 0.5337\n","Epoch 295/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0213 - accuracy: 0.5169\n","Epoch 296/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8510 - accuracy: 0.5447\n","Epoch 297/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0373 - accuracy: 0.5663\n","Epoch 298/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1059 - accuracy: 0.4984\n","Epoch 299/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0734 - accuracy: 0.4690\n","Epoch 300/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0577 - accuracy: 0.5209\n","Epoch 301/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0067 - accuracy: 0.5409\n","Epoch 302/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9615 - accuracy: 0.5551\n","Epoch 303/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9379 - accuracy: 0.5728\n","Epoch 304/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0284 - accuracy: 0.5378\n","Epoch 305/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9569 - accuracy: 0.5313\n","Epoch 306/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9669 - accuracy: 0.4951\n","Epoch 307/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0365 - accuracy: 0.4996\n","Epoch 308/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9689 - accuracy: 0.5580\n","Epoch 309/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9483 - accuracy: 0.5335\n","Epoch 310/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9584 - accuracy: 0.5922\n","Epoch 311/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9761 - accuracy: 0.5709\n","Epoch 312/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0246 - accuracy: 0.4913\n","Epoch 313/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0142 - accuracy: 0.4870\n","Epoch 314/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0330 - accuracy: 0.4610\n","Epoch 315/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0078 - accuracy: 0.5199\n","Epoch 316/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0614 - accuracy: 0.4491\n","Epoch 317/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9957 - accuracy: 0.4952\n","Epoch 318/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0687 - accuracy: 0.5234\n","Epoch 319/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0425 - accuracy: 0.5063\n","Epoch 320/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9819 - accuracy: 0.5286\n","Epoch 321/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0604 - accuracy: 0.5173\n","Epoch 322/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9929 - accuracy: 0.5258\n","Epoch 323/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0420 - accuracy: 0.5028\n","Epoch 324/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0050 - accuracy: 0.5380\n","Epoch 325/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9688 - accuracy: 0.5520\n","Epoch 326/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0399 - accuracy: 0.4865\n","Epoch 327/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1030 - accuracy: 0.4503\n","Epoch 328/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0300 - accuracy: 0.4688\n","Epoch 329/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9268 - accuracy: 0.5129\n","Epoch 330/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1408 - accuracy: 0.4471\n","Epoch 331/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0749 - accuracy: 0.5227\n","Epoch 332/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9136 - accuracy: 0.5322\n","Epoch 333/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9470 - accuracy: 0.5711\n","Epoch 334/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9695 - accuracy: 0.5214\n","Epoch 335/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0732 - accuracy: 0.5194\n","Epoch 336/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0080 - accuracy: 0.5550\n","Epoch 337/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0083 - accuracy: 0.5067\n","Epoch 338/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0668 - accuracy: 0.5239\n","Epoch 339/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9521 - accuracy: 0.5212\n","Epoch 340/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0247 - accuracy: 0.4547\n","Epoch 341/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0298 - accuracy: 0.5463\n","Epoch 342/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0016 - accuracy: 0.5070\n","Epoch 343/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0387 - accuracy: 0.4792\n","Epoch 344/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1002 - accuracy: 0.4283\n","Epoch 345/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9149 - accuracy: 0.5651\n","Epoch 346/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9256 - accuracy: 0.5830\n","Epoch 347/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1030 - accuracy: 0.4633\n","Epoch 348/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9421 - accuracy: 0.5150\n","Epoch 349/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0221 - accuracy: 0.5243\n","Epoch 350/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9947 - accuracy: 0.4992\n","Epoch 351/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9929 - accuracy: 0.5050\n","Epoch 352/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0392 - accuracy: 0.5044\n","Epoch 353/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9524 - accuracy: 0.5393\n","Epoch 354/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9922 - accuracy: 0.5367\n","Epoch 355/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.8894 - accuracy: 0.5360\n","Epoch 356/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9962 - accuracy: 0.4294\n","Epoch 357/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0332 - accuracy: 0.4867\n","Epoch 358/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9658 - accuracy: 0.5200\n","Epoch 359/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0677 - accuracy: 0.4638\n","Epoch 360/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0668 - accuracy: 0.4721\n","Epoch 361/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9785 - accuracy: 0.4982\n","Epoch 362/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0165 - accuracy: 0.5206\n","Epoch 363/500\n","28/28 [==============================] - 0s 4ms/step - loss: 0.9630 - accuracy: 0.5100\n","Epoch 364/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9387 - accuracy: 0.5626\n","Epoch 365/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9637 - accuracy: 0.4870\n","Epoch 366/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9710 - accuracy: 0.5733\n","Epoch 367/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0200 - accuracy: 0.4494\n","Epoch 368/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0760 - accuracy: 0.5428\n","Epoch 369/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9790 - accuracy: 0.4964\n","Epoch 370/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9911 - accuracy: 0.5297\n","Epoch 371/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9638 - accuracy: 0.5119\n","Epoch 372/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0443 - accuracy: 0.5476\n","Epoch 373/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.5699\n","Epoch 374/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9924 - accuracy: 0.5632\n","Epoch 375/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0555 - accuracy: 0.4916\n","Epoch 376/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9165 - accuracy: 0.5118\n","Epoch 377/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0002 - accuracy: 0.5164\n","Epoch 378/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0809 - accuracy: 0.5261\n","Epoch 379/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9153 - accuracy: 0.5489\n","Epoch 380/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9937 - accuracy: 0.4989\n","Epoch 381/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9723 - accuracy: 0.5765\n","Epoch 382/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0195 - accuracy: 0.5166\n","Epoch 383/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0863 - accuracy: 0.5175\n","Epoch 384/500\n","28/28 [==============================] - 0s 4ms/step - loss: 1.0065 - accuracy: 0.5197\n","Epoch 385/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0731 - accuracy: 0.5052\n","Epoch 386/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9514 - accuracy: 0.5248\n","Epoch 387/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9550 - accuracy: 0.5445\n","Epoch 388/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9940 - accuracy: 0.5265\n","Epoch 389/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9849 - accuracy: 0.4848\n","Epoch 390/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9467 - accuracy: 0.5019\n","Epoch 391/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0622 - accuracy: 0.5012\n","Epoch 392/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0409 - accuracy: 0.5485\n","Epoch 393/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9549 - accuracy: 0.5416\n","Epoch 394/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0843 - accuracy: 0.4906\n","Epoch 395/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9331 - accuracy: 0.4795\n","Epoch 396/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0450 - accuracy: 0.5613\n","Epoch 397/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9890 - accuracy: 0.5335\n","Epoch 398/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9530 - accuracy: 0.4792\n","Epoch 399/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9948 - accuracy: 0.4921\n","Epoch 400/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0735 - accuracy: 0.3960\n","Epoch 401/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0261 - accuracy: 0.5038\n","Epoch 402/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0105 - accuracy: 0.4956\n","Epoch 403/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9844 - accuracy: 0.4798\n","Epoch 404/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1078 - accuracy: 0.4407\n","Epoch 405/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9757 - accuracy: 0.5609\n","Epoch 406/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9327 - accuracy: 0.5044\n","Epoch 407/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9187 - accuracy: 0.5739\n","Epoch 408/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0099 - accuracy: 0.5008\n","Epoch 409/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9961 - accuracy: 0.4888\n","Epoch 410/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0232 - accuracy: 0.5763\n","Epoch 411/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9923 - accuracy: 0.5735\n","Epoch 412/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0871 - accuracy: 0.4383\n","Epoch 413/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0901 - accuracy: 0.4375\n","Epoch 414/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9591 - accuracy: 0.5280\n","Epoch 415/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0489 - accuracy: 0.4770\n","Epoch 416/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0620 - accuracy: 0.4776\n","Epoch 417/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9185 - accuracy: 0.6029\n","Epoch 418/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9730 - accuracy: 0.5562\n","Epoch 419/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0310 - accuracy: 0.4676\n","Epoch 420/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9804 - accuracy: 0.5139\n","Epoch 421/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9599 - accuracy: 0.5273\n","Epoch 422/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9134 - accuracy: 0.5426\n","Epoch 423/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9692 - accuracy: 0.4907\n","Epoch 424/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0217 - accuracy: 0.4567\n","Epoch 425/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0006 - accuracy: 0.5325\n","Epoch 426/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9508 - accuracy: 0.6047\n","Epoch 427/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0904 - accuracy: 0.4501\n","Epoch 428/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9718 - accuracy: 0.5345\n","Epoch 429/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9309 - accuracy: 0.5119\n","Epoch 430/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9654 - accuracy: 0.5144\n","Epoch 431/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9953 - accuracy: 0.5308\n","Epoch 432/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0258 - accuracy: 0.4728\n","Epoch 433/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0274 - accuracy: 0.4687\n","Epoch 434/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0076 - accuracy: 0.4914\n","Epoch 435/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9685 - accuracy: 0.5235\n","Epoch 436/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9750 - accuracy: 0.5307\n","Epoch 437/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9738 - accuracy: 0.5362\n","Epoch 438/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0679 - accuracy: 0.5295\n","Epoch 439/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9849 - accuracy: 0.4918\n","Epoch 440/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9450 - accuracy: 0.5509\n","Epoch 441/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0704 - accuracy: 0.4456\n","Epoch 442/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0434 - accuracy: 0.4645\n","Epoch 443/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0761 - accuracy: 0.4904\n","Epoch 444/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0135 - accuracy: 0.4844\n","Epoch 445/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9731 - accuracy: 0.5090\n","Epoch 446/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0131 - accuracy: 0.5083\n","Epoch 447/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0159 - accuracy: 0.4910\n","Epoch 448/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0501 - accuracy: 0.5175\n","Epoch 449/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.5319\n","Epoch 450/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9856 - accuracy: 0.5400\n","Epoch 451/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0254 - accuracy: 0.4992\n","Epoch 452/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0295 - accuracy: 0.5229\n","Epoch 453/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9628 - accuracy: 0.5387\n","Epoch 454/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0422 - accuracy: 0.4933\n","Epoch 455/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0143 - accuracy: 0.5647\n","Epoch 456/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0447 - accuracy: 0.4925\n","Epoch 457/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9979 - accuracy: 0.5448\n","Epoch 458/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0230 - accuracy: 0.5168\n","Epoch 459/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0466 - accuracy: 0.5124\n","Epoch 460/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0584 - accuracy: 0.5475\n","Epoch 461/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0752 - accuracy: 0.5084\n","Epoch 462/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9877 - accuracy: 0.5155\n","Epoch 463/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9308 - accuracy: 0.5058\n","Epoch 464/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9494 - accuracy: 0.5048\n","Epoch 465/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9974 - accuracy: 0.4894\n","Epoch 466/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9725 - accuracy: 0.5779\n","Epoch 467/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9623 - accuracy: 0.5292\n","Epoch 468/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9821 - accuracy: 0.4577\n","Epoch 469/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9294 - accuracy: 0.5367\n","Epoch 470/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0044 - accuracy: 0.5481\n","Epoch 471/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0532 - accuracy: 0.5286\n","Epoch 472/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0201 - accuracy: 0.5466\n","Epoch 473/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0262 - accuracy: 0.5206\n","Epoch 474/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9984 - accuracy: 0.5446\n","Epoch 475/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0048 - accuracy: 0.5078\n","Epoch 476/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0752 - accuracy: 0.4750\n","Epoch 477/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0100 - accuracy: 0.5123\n","Epoch 478/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0460 - accuracy: 0.5161\n","Epoch 479/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0092 - accuracy: 0.4805\n","Epoch 480/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0071 - accuracy: 0.5295\n","Epoch 481/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0025 - accuracy: 0.5133\n","Epoch 482/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0269 - accuracy: 0.4812\n","Epoch 483/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9951 - accuracy: 0.4895\n","Epoch 484/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9899 - accuracy: 0.5054\n","Epoch 485/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9249 - accuracy: 0.5502\n","Epoch 486/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9844 - accuracy: 0.5484\n","Epoch 487/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0106 - accuracy: 0.4685\n","Epoch 488/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0393 - accuracy: 0.5544\n","Epoch 489/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0252 - accuracy: 0.5067\n","Epoch 490/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9455 - accuracy: 0.5879\n","Epoch 491/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0664 - accuracy: 0.5015\n","Epoch 492/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9301 - accuracy: 0.5212\n","Epoch 493/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9964 - accuracy: 0.5457\n","Epoch 494/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.5423\n","Epoch 495/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1721 - accuracy: 0.4172\n","Epoch 496/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0187 - accuracy: 0.5655\n","Epoch 497/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0116 - accuracy: 0.5000\n","Epoch 498/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0359 - accuracy: 0.4923\n","Epoch 499/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0143 - accuracy: 0.4445\n","Epoch 500/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9868 - accuracy: 0.5056\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa0301990e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 167ms/step - loss: 70.3640 - accuracy: 0.5333\n","Epoch 1/500\n","28/28 [==============================] - 1s 2ms/step - loss: 14141.7243 - accuracy: 0.2717\n","Epoch 2/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2946.7462 - accuracy: 0.4198\n","Epoch 3/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4658.6438 - accuracy: 0.4809\n","Epoch 4/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2659.7754 - accuracy: 0.4460\n","Epoch 5/500\n","28/28 [==============================] - 0s 3ms/step - loss: 807.8428 - accuracy: 0.4732\n","Epoch 6/500\n","28/28 [==============================] - 0s 2ms/step - loss: 373.5829 - accuracy: 0.4818\n","Epoch 7/500\n","28/28 [==============================] - 0s 3ms/step - loss: 671.0537 - accuracy: 0.5073\n","Epoch 8/500\n","28/28 [==============================] - 0s 3ms/step - loss: 691.4066 - accuracy: 0.4231\n","Epoch 9/500\n","28/28 [==============================] - 0s 2ms/step - loss: 653.5198 - accuracy: 0.3953\n","Epoch 10/500\n","28/28 [==============================] - 0s 2ms/step - loss: 258.0724 - accuracy: 0.4097\n","Epoch 11/500\n","28/28 [==============================] - 0s 2ms/step - loss: 424.4201 - accuracy: 0.4846\n","Epoch 12/500\n","28/28 [==============================] - 0s 2ms/step - loss: 495.7548 - accuracy: 0.3530\n","Epoch 13/500\n","28/28 [==============================] - 0s 2ms/step - loss: 417.2156 - accuracy: 0.4091\n","Epoch 14/500\n","28/28 [==============================] - 0s 2ms/step - loss: 934.6474 - accuracy: 0.4224\n","Epoch 15/500\n","28/28 [==============================] - 0s 3ms/step - loss: 392.4158 - accuracy: 0.5628\n","Epoch 16/500\n","28/28 [==============================] - 0s 2ms/step - loss: 181.4693 - accuracy: 0.5135\n","Epoch 17/500\n","28/28 [==============================] - 0s 2ms/step - loss: 126.4751 - accuracy: 0.4505\n","Epoch 18/500\n","28/28 [==============================] - 0s 2ms/step - loss: 136.9475 - accuracy: 0.5347\n","Epoch 19/500\n","28/28 [==============================] - 0s 2ms/step - loss: 116.9320 - accuracy: 0.4591\n","Epoch 20/500\n","28/28 [==============================] - 0s 3ms/step - loss: 96.5637 - accuracy: 0.4001\n","Epoch 21/500\n","28/28 [==============================] - 0s 2ms/step - loss: 26.5926 - accuracy: 0.4168\n","Epoch 22/500\n","28/28 [==============================] - 0s 2ms/step - loss: 23.2226 - accuracy: 0.4347\n","Epoch 23/500\n","28/28 [==============================] - 0s 3ms/step - loss: 19.1769 - accuracy: 0.4763\n","Epoch 24/500\n","28/28 [==============================] - 0s 3ms/step - loss: 15.4896 - accuracy: 0.4779\n","Epoch 25/500\n","28/28 [==============================] - 0s 3ms/step - loss: 10.3991 - accuracy: 0.4332\n","Epoch 26/500\n","28/28 [==============================] - 0s 3ms/step - loss: 9.3207 - accuracy: 0.4058\n","Epoch 27/500\n","28/28 [==============================] - 0s 2ms/step - loss: 6.2859 - accuracy: 0.5220\n","Epoch 28/500\n","28/28 [==============================] - 0s 3ms/step - loss: 8.0401 - accuracy: 0.4414\n","Epoch 29/500\n","28/28 [==============================] - 0s 3ms/step - loss: 11.0129 - accuracy: 0.5324\n","Epoch 30/500\n","28/28 [==============================] - 0s 3ms/step - loss: 12.7483 - accuracy: 0.3497\n","Epoch 31/500\n","28/28 [==============================] - 0s 3ms/step - loss: 14.6353 - accuracy: 0.4319\n","Epoch 32/500\n","28/28 [==============================] - 0s 3ms/step - loss: 10.3283 - accuracy: 0.4928\n","Epoch 33/500\n","28/28 [==============================] - 0s 3ms/step - loss: 13.4068 - accuracy: 0.5195\n","Epoch 34/500\n","28/28 [==============================] - 0s 3ms/step - loss: 9.8313 - accuracy: 0.4541\n","Epoch 35/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.2785 - accuracy: 0.5299\n","Epoch 36/500\n","28/28 [==============================] - 0s 3ms/step - loss: 7.2550 - accuracy: 0.4234\n","Epoch 37/500\n","28/28 [==============================] - 0s 2ms/step - loss: 6.4731 - accuracy: 0.5376\n","Epoch 38/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.6672 - accuracy: 0.5244\n","Epoch 39/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.6116 - accuracy: 0.5564\n","Epoch 40/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.4241 - accuracy: 0.4412\n","Epoch 41/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.9064 - accuracy: 0.5805\n","Epoch 42/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.7806 - accuracy: 0.5697\n","Epoch 43/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.0560 - accuracy: 0.5755\n","Epoch 44/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.4889 - accuracy: 0.5472\n","Epoch 45/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.2031 - accuracy: 0.6242\n","Epoch 46/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.7775 - accuracy: 0.5419\n","Epoch 47/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.1733 - accuracy: 0.5153\n","Epoch 48/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.0561 - accuracy: 0.5627\n","Epoch 49/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.4678 - accuracy: 0.5651\n","Epoch 50/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.5189 - accuracy: 0.4960\n","Epoch 51/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.8797 - accuracy: 0.5574\n","Epoch 52/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.9660 - accuracy: 0.5724\n","Epoch 53/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.0207 - accuracy: 0.5972\n","Epoch 54/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.3738 - accuracy: 0.5398\n","Epoch 55/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.1598 - accuracy: 0.4481\n","Epoch 56/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.3074 - accuracy: 0.5135\n","Epoch 57/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.5835 - accuracy: 0.5519\n","Epoch 58/500\n","28/28 [==============================] - 0s 3ms/step - loss: 8.3147 - accuracy: 0.5012\n","Epoch 59/500\n","28/28 [==============================] - 0s 3ms/step - loss: 10.6425 - accuracy: 0.5151\n","Epoch 60/500\n","28/28 [==============================] - 0s 2ms/step - loss: 10.0458 - accuracy: 0.5380\n","Epoch 61/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.0914 - accuracy: 0.5092\n","Epoch 62/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.5898 - accuracy: 0.4094\n","Epoch 63/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.0528 - accuracy: 0.6130\n","Epoch 64/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.1160 - accuracy: 0.4514\n","Epoch 65/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.8733 - accuracy: 0.3844\n","Epoch 66/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.6255 - accuracy: 0.5666\n","Epoch 67/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.3051 - accuracy: 0.4501\n","Epoch 68/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.1032 - accuracy: 0.4938\n","Epoch 69/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.7063 - accuracy: 0.4199\n","Epoch 70/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.4959 - accuracy: 0.4217\n","Epoch 71/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.1546 - accuracy: 0.4386\n","Epoch 72/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.9223 - accuracy: 0.3591\n","Epoch 73/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.7713 - accuracy: 0.4080\n","Epoch 74/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1885 - accuracy: 0.4226\n","Epoch 75/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1431 - accuracy: 0.3886\n","Epoch 76/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.3711 - accuracy: 0.3857\n","Epoch 77/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.3223 - accuracy: 0.3606\n","Epoch 78/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2621 - accuracy: 0.4062\n","Epoch 79/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0965 - accuracy: 0.4309\n","Epoch 80/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1207 - accuracy: 0.4092\n","Epoch 81/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0665 - accuracy: 0.4053\n","Epoch 82/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0730 - accuracy: 0.4429\n","Epoch 83/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0378 - accuracy: 0.4159\n","Epoch 84/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1472 - accuracy: 0.3706\n","Epoch 85/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9972 - accuracy: 0.4038\n","Epoch 86/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1157 - accuracy: 0.4183\n","Epoch 87/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1795 - accuracy: 0.4844\n","Epoch 88/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1245 - accuracy: 0.4989\n","Epoch 89/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0249 - accuracy: 0.5470\n","Epoch 90/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9556 - accuracy: 0.5225\n","Epoch 91/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0477 - accuracy: 0.5456\n","Epoch 92/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0937 - accuracy: 0.5108\n","Epoch 93/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0302 - accuracy: 0.5013\n","Epoch 94/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0175 - accuracy: 0.5075\n","Epoch 95/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0152 - accuracy: 0.4926\n","Epoch 96/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9575 - accuracy: 0.5297\n","Epoch 97/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0707 - accuracy: 0.5049\n","Epoch 98/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0843 - accuracy: 0.5309\n","Epoch 99/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0983 - accuracy: 0.4802\n","Epoch 100/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9728 - accuracy: 0.6278\n","Epoch 101/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0864 - accuracy: 0.4672\n","Epoch 102/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0083 - accuracy: 0.5337\n","Epoch 103/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9849 - accuracy: 0.5145\n","Epoch 104/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0476 - accuracy: 0.5456\n","Epoch 105/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0382 - accuracy: 0.5045\n","Epoch 106/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0393 - accuracy: 0.5226\n","Epoch 107/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0324 - accuracy: 0.5279\n","Epoch 108/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0217 - accuracy: 0.5338\n","Epoch 109/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9298 - accuracy: 0.5908\n","Epoch 110/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0704 - accuracy: 0.4770\n","Epoch 111/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9939 - accuracy: 0.5428\n","Epoch 112/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0227 - accuracy: 0.4675\n","Epoch 113/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0305 - accuracy: 0.5824\n","Epoch 114/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9782 - accuracy: 0.5097\n","Epoch 115/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0299 - accuracy: 0.5514\n","Epoch 116/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0363 - accuracy: 0.4728\n","Epoch 117/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0062 - accuracy: 0.5131\n","Epoch 118/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9618 - accuracy: 0.5130\n","Epoch 119/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9799 - accuracy: 0.5613\n","Epoch 120/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0357 - accuracy: 0.5503\n","Epoch 121/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0430 - accuracy: 0.4664\n","Epoch 122/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0480 - accuracy: 0.4732\n","Epoch 123/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0223 - accuracy: 0.4807\n","Epoch 124/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9325 - accuracy: 0.5717\n","Epoch 125/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9502 - accuracy: 0.5292\n","Epoch 126/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0331 - accuracy: 0.4780\n","Epoch 127/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0056 - accuracy: 0.5395\n","Epoch 128/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0140 - accuracy: 0.5083\n","Epoch 129/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0335 - accuracy: 0.4385\n","Epoch 130/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0062 - accuracy: 0.5069\n","Epoch 131/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0795 - accuracy: 0.4529\n","Epoch 132/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0352 - accuracy: 0.4718\n","Epoch 133/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0608 - accuracy: 0.4600\n","Epoch 134/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0533 - accuracy: 0.4948\n","Epoch 135/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0397 - accuracy: 0.5215\n","Epoch 136/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0650 - accuracy: 0.4287\n","Epoch 137/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0177 - accuracy: 0.5071\n","Epoch 138/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0775 - accuracy: 0.4654\n","Epoch 139/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9951 - accuracy: 0.4925\n","Epoch 140/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0134 - accuracy: 0.5340\n","Epoch 141/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0610 - accuracy: 0.5165\n","Epoch 142/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0515 - accuracy: 0.5110\n","Epoch 143/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0055 - accuracy: 0.5432\n","Epoch 144/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0730 - accuracy: 0.4835\n","Epoch 145/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0148 - accuracy: 0.5295\n","Epoch 146/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0297 - accuracy: 0.5048\n","Epoch 147/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0448 - accuracy: 0.4841\n","Epoch 148/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0609 - accuracy: 0.4785\n","Epoch 149/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0316 - accuracy: 0.5305\n","Epoch 150/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9625 - accuracy: 0.5703\n","Epoch 151/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0592 - accuracy: 0.4998\n","Epoch 152/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0841 - accuracy: 0.4179\n","Epoch 153/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0485 - accuracy: 0.5045\n","Epoch 154/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0434 - accuracy: 0.5126\n","Epoch 155/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9422 - accuracy: 0.5949\n","Epoch 156/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0509 - accuracy: 0.4888\n","Epoch 157/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1170 - accuracy: 0.4708\n","Epoch 158/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0794 - accuracy: 0.4344\n","Epoch 159/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9189 - accuracy: 0.5732\n","Epoch 160/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0457 - accuracy: 0.4768\n","Epoch 161/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0464 - accuracy: 0.4642\n","Epoch 162/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9628 - accuracy: 0.4882\n","Epoch 163/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9543 - accuracy: 0.5094\n","Epoch 164/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0722 - accuracy: 0.4887\n","Epoch 165/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9932 - accuracy: 0.4971\n","Epoch 166/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0750 - accuracy: 0.4658\n","Epoch 167/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9931 - accuracy: 0.5406\n","Epoch 168/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9787 - accuracy: 0.5179\n","Epoch 169/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9559 - accuracy: 0.5721\n","Epoch 170/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9656 - accuracy: 0.5444\n","Epoch 171/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0276 - accuracy: 0.5477\n","Epoch 172/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0356 - accuracy: 0.4738\n","Epoch 173/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0344 - accuracy: 0.5101\n","Epoch 174/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0072 - accuracy: 0.5254\n","Epoch 175/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0268 - accuracy: 0.5127\n","Epoch 176/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0209 - accuracy: 0.5066\n","Epoch 177/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.5301\n","Epoch 178/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1146 - accuracy: 0.4388\n","Epoch 179/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9397 - accuracy: 0.5583\n","Epoch 180/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1343 - accuracy: 0.4472\n","Epoch 181/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9641 - accuracy: 0.5208\n","Epoch 182/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0119 - accuracy: 0.5482\n","Epoch 183/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0432 - accuracy: 0.5661\n","Epoch 184/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0529 - accuracy: 0.4894\n","Epoch 185/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0096 - accuracy: 0.5138\n","Epoch 186/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0413 - accuracy: 0.4932\n","Epoch 187/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0295 - accuracy: 0.4890\n","Epoch 188/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0827 - accuracy: 0.4396\n","Epoch 189/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9693 - accuracy: 0.5727\n","Epoch 190/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0737 - accuracy: 0.5380\n","Epoch 191/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0275 - accuracy: 0.5278\n","Epoch 192/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9988 - accuracy: 0.5472\n","Epoch 193/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0718 - accuracy: 0.4592\n","Epoch 194/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0247 - accuracy: 0.5489\n","Epoch 195/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0260 - accuracy: 0.5161\n","Epoch 196/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1013 - accuracy: 0.5492\n","Epoch 197/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0381 - accuracy: 0.4824\n","Epoch 198/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9695 - accuracy: 0.4983\n","Epoch 199/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0525 - accuracy: 0.5161\n","Epoch 200/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0607 - accuracy: 0.5094\n","Epoch 201/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0018 - accuracy: 0.5794\n","Epoch 202/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0673 - accuracy: 0.4774\n","Epoch 203/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0372 - accuracy: 0.5152\n","Epoch 204/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0939 - accuracy: 0.5081\n","Epoch 205/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0001 - accuracy: 0.5428\n","Epoch 206/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0453 - accuracy: 0.5299\n","Epoch 207/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0741 - accuracy: 0.5010\n","Epoch 208/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0561 - accuracy: 0.4969\n","Epoch 209/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0467 - accuracy: 0.4552\n","Epoch 210/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0045 - accuracy: 0.5852\n","Epoch 211/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0000 - accuracy: 0.5362\n","Epoch 212/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0223 - accuracy: 0.5563\n","Epoch 213/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0011 - accuracy: 0.5129\n","Epoch 214/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0720 - accuracy: 0.4780\n","Epoch 215/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0383 - accuracy: 0.4981\n","Epoch 216/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9811 - accuracy: 0.5546\n","Epoch 217/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0687 - accuracy: 0.5184\n","Epoch 218/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0460 - accuracy: 0.5243\n","Epoch 219/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0116 - accuracy: 0.5096\n","Epoch 220/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0884 - accuracy: 0.4677\n","Epoch 221/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1031 - accuracy: 0.4808\n","Epoch 222/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0321 - accuracy: 0.5246\n","Epoch 223/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1561 - accuracy: 0.4553\n","Epoch 224/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1262 - accuracy: 0.4448\n","Epoch 225/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0884 - accuracy: 0.4548\n","Epoch 226/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0023 - accuracy: 0.5619\n","Epoch 227/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9465 - accuracy: 0.5933\n","Epoch 228/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0193 - accuracy: 0.5287\n","Epoch 229/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1076 - accuracy: 0.4702\n","Epoch 230/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0704 - accuracy: 0.5305\n","Epoch 231/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1339 - accuracy: 0.5212\n","Epoch 232/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9962 - accuracy: 0.5788\n","Epoch 233/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0374 - accuracy: 0.4788\n","Epoch 234/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0534 - accuracy: 0.4922\n","Epoch 235/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0326 - accuracy: 0.5316\n","Epoch 236/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0469 - accuracy: 0.4640\n","Epoch 237/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0891 - accuracy: 0.5115\n","Epoch 238/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0377 - accuracy: 0.5495\n","Epoch 239/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0904 - accuracy: 0.5064\n","Epoch 240/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0274 - accuracy: 0.5597\n","Epoch 241/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0275 - accuracy: 0.5280\n","Epoch 242/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1325 - accuracy: 0.4576\n","Epoch 243/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0008 - accuracy: 0.5792\n","Epoch 244/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0985 - accuracy: 0.5242\n","Epoch 245/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0455 - accuracy: 0.5252\n","Epoch 246/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9980 - accuracy: 0.5010\n","Epoch 247/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0255 - accuracy: 0.5009\n","Epoch 248/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0496 - accuracy: 0.5140\n","Epoch 249/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1382 - accuracy: 0.4868\n","Epoch 250/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0326 - accuracy: 0.4756\n","Epoch 251/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0622 - accuracy: 0.4791\n","Epoch 252/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0738 - accuracy: 0.4680\n","Epoch 253/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9712 - accuracy: 0.5705\n","Epoch 254/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0525 - accuracy: 0.5415\n","Epoch 255/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0486 - accuracy: 0.5287\n","Epoch 256/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0723 - accuracy: 0.5270\n","Epoch 257/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0634 - accuracy: 0.5175\n","Epoch 258/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0605 - accuracy: 0.5182\n","Epoch 259/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0342 - accuracy: 0.5434\n","Epoch 260/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0295 - accuracy: 0.5171\n","Epoch 261/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0281 - accuracy: 0.5510\n","Epoch 262/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0171 - accuracy: 0.5553\n","Epoch 263/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9977 - accuracy: 0.4928\n","Epoch 264/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1409 - accuracy: 0.5256\n","Epoch 265/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0510 - accuracy: 0.4982\n","Epoch 266/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.5220\n","Epoch 267/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0232 - accuracy: 0.5377\n","Epoch 268/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0758 - accuracy: 0.4624\n","Epoch 269/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0054 - accuracy: 0.5316\n","Epoch 270/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0095 - accuracy: 0.5436\n","Epoch 271/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0386 - accuracy: 0.5201\n","Epoch 272/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9089 - accuracy: 0.5305\n","Epoch 273/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0432 - accuracy: 0.5284\n","Epoch 274/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0959 - accuracy: 0.4957\n","Epoch 275/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0582 - accuracy: 0.5339\n","Epoch 276/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0580 - accuracy: 0.4310\n","Epoch 277/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0427 - accuracy: 0.4965\n","Epoch 278/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9550 - accuracy: 0.5433\n","Epoch 279/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0684 - accuracy: 0.5185\n","Epoch 280/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0003 - accuracy: 0.5120\n","Epoch 281/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9865 - accuracy: 0.4634\n","Epoch 282/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0268 - accuracy: 0.5797\n","Epoch 283/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0645 - accuracy: 0.5487\n","Epoch 284/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0103 - accuracy: 0.5094\n","Epoch 285/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9863 - accuracy: 0.5691\n","Epoch 286/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0887 - accuracy: 0.4914\n","Epoch 287/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0368 - accuracy: 0.4645\n","Epoch 288/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1002 - accuracy: 0.4987\n","Epoch 289/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9909 - accuracy: 0.5383\n","Epoch 290/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0005 - accuracy: 0.5228\n","Epoch 291/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1116 - accuracy: 0.4816\n","Epoch 292/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1208 - accuracy: 0.4083\n","Epoch 293/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0657 - accuracy: 0.4895\n","Epoch 294/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0290 - accuracy: 0.5028\n","Epoch 295/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0765 - accuracy: 0.5282\n","Epoch 296/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9368 - accuracy: 0.5409\n","Epoch 297/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1388 - accuracy: 0.4934\n","Epoch 298/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0735 - accuracy: 0.5379\n","Epoch 299/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0766 - accuracy: 0.4787\n","Epoch 300/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0116 - accuracy: 0.5426\n","Epoch 301/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9351 - accuracy: 0.5462\n","Epoch 302/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9969 - accuracy: 0.5608\n","Epoch 303/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9982 - accuracy: 0.5525\n","Epoch 304/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0371 - accuracy: 0.5508\n","Epoch 305/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0681 - accuracy: 0.5032\n","Epoch 306/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9817 - accuracy: 0.5180\n","Epoch 307/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0626 - accuracy: 0.5112\n","Epoch 308/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0244 - accuracy: 0.5621\n","Epoch 309/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9901 - accuracy: 0.5286\n","Epoch 310/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0310 - accuracy: 0.5537\n","Epoch 311/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0047 - accuracy: 0.5860\n","Epoch 312/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0136 - accuracy: 0.4787\n","Epoch 313/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0140 - accuracy: 0.4266\n","Epoch 314/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0661 - accuracy: 0.4583\n","Epoch 315/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0055 - accuracy: 0.5191\n","Epoch 316/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0426 - accuracy: 0.4473\n","Epoch 317/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0754 - accuracy: 0.5013\n","Epoch 318/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0805 - accuracy: 0.5225\n","Epoch 319/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0191 - accuracy: 0.5126\n","Epoch 320/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0566 - accuracy: 0.4729\n","Epoch 321/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1681 - accuracy: 0.4576\n","Epoch 322/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0874 - accuracy: 0.4477\n","Epoch 323/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0835 - accuracy: 0.5160\n","Epoch 324/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0679 - accuracy: 0.5431\n","Epoch 325/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0059 - accuracy: 0.5832\n","Epoch 326/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0415 - accuracy: 0.4838\n","Epoch 327/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0716 - accuracy: 0.4319\n","Epoch 328/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0223 - accuracy: 0.5244\n","Epoch 329/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0021 - accuracy: 0.5060\n","Epoch 330/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0934 - accuracy: 0.4579\n","Epoch 331/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1031 - accuracy: 0.4755\n","Epoch 332/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9641 - accuracy: 0.5447\n","Epoch 333/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0577 - accuracy: 0.4997\n","Epoch 334/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0143 - accuracy: 0.5130\n","Epoch 335/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0485 - accuracy: 0.4730\n","Epoch 336/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0571 - accuracy: 0.5454\n","Epoch 337/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0787 - accuracy: 0.4954\n","Epoch 338/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0942 - accuracy: 0.4874\n","Epoch 339/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0997 - accuracy: 0.5126\n","Epoch 340/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0460 - accuracy: 0.4181\n","Epoch 341/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0342 - accuracy: 0.5173\n","Epoch 342/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0249 - accuracy: 0.4903\n","Epoch 343/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0860 - accuracy: 0.5142\n","Epoch 344/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0502 - accuracy: 0.4461\n","Epoch 345/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9886 - accuracy: 0.5496\n","Epoch 346/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9903 - accuracy: 0.5706\n","Epoch 347/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1240 - accuracy: 0.4533\n","Epoch 348/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9837 - accuracy: 0.4999\n","Epoch 349/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0788 - accuracy: 0.5374\n","Epoch 350/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0116 - accuracy: 0.5070\n","Epoch 351/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0774 - accuracy: 0.4403\n","Epoch 352/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0207 - accuracy: 0.5233\n","Epoch 353/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9436 - accuracy: 0.5658\n","Epoch 354/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9347 - accuracy: 0.5785\n","Epoch 355/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0103 - accuracy: 0.5057\n","Epoch 356/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0771 - accuracy: 0.4203\n","Epoch 357/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0700 - accuracy: 0.4849\n","Epoch 358/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0231 - accuracy: 0.4945\n","Epoch 359/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0417 - accuracy: 0.5282\n","Epoch 360/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0258 - accuracy: 0.5399\n","Epoch 361/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0099 - accuracy: 0.5361\n","Epoch 362/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0812 - accuracy: 0.4845\n","Epoch 363/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0526 - accuracy: 0.5036\n","Epoch 364/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9915 - accuracy: 0.5443\n","Epoch 365/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9992 - accuracy: 0.5246\n","Epoch 366/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0442 - accuracy: 0.5545\n","Epoch 367/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0044 - accuracy: 0.4249\n","Epoch 368/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0389 - accuracy: 0.5414\n","Epoch 369/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0067 - accuracy: 0.5242\n","Epoch 370/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0587 - accuracy: 0.4882\n","Epoch 371/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9888 - accuracy: 0.5043\n","Epoch 372/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0101 - accuracy: 0.5209\n","Epoch 373/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0398 - accuracy: 0.5353\n","Epoch 374/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0918 - accuracy: 0.5222\n","Epoch 375/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1474 - accuracy: 0.4424\n","Epoch 376/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9499 - accuracy: 0.5415\n","Epoch 377/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0768 - accuracy: 0.4878\n","Epoch 378/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1725 - accuracy: 0.4622\n","Epoch 379/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9219 - accuracy: 0.5848\n","Epoch 380/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0588 - accuracy: 0.4629\n","Epoch 381/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9348 - accuracy: 0.5541\n","Epoch 382/500\n","28/28 [==============================] - 0s 4ms/step - loss: 1.0738 - accuracy: 0.4963\n","Epoch 383/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1634 - accuracy: 0.4501\n","Epoch 384/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0368 - accuracy: 0.5542\n","Epoch 385/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1564 - accuracy: 0.4766\n","Epoch 386/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9979 - accuracy: 0.5209\n","Epoch 387/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0063 - accuracy: 0.5445\n","Epoch 388/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0211 - accuracy: 0.4992\n","Epoch 389/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0535 - accuracy: 0.5247\n","Epoch 390/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9693 - accuracy: 0.5334\n","Epoch 391/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0735 - accuracy: 0.4986\n","Epoch 392/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0776 - accuracy: 0.5378\n","Epoch 393/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0045 - accuracy: 0.5232\n","Epoch 394/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0711 - accuracy: 0.4261\n","Epoch 395/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9917 - accuracy: 0.5306\n","Epoch 396/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1066 - accuracy: 0.5269\n","Epoch 397/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0604 - accuracy: 0.5169\n","Epoch 398/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0152 - accuracy: 0.4478\n","Epoch 399/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0131 - accuracy: 0.5266\n","Epoch 400/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0960 - accuracy: 0.3868\n","Epoch 401/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0410 - accuracy: 0.5027\n","Epoch 402/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9957 - accuracy: 0.4775\n","Epoch 403/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9653 - accuracy: 0.5336\n","Epoch 404/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0793 - accuracy: 0.4856\n","Epoch 405/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0470 - accuracy: 0.4870\n","Epoch 406/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0035 - accuracy: 0.4879\n","Epoch 407/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9394 - accuracy: 0.5597\n","Epoch 408/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0840 - accuracy: 0.4529\n","Epoch 409/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9997 - accuracy: 0.5312\n","Epoch 410/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0570 - accuracy: 0.5193\n","Epoch 411/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0832 - accuracy: 0.5262\n","Epoch 412/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0050 - accuracy: 0.4972\n","Epoch 413/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1223 - accuracy: 0.4245\n","Epoch 414/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1096 - accuracy: 0.4413\n","Epoch 415/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0472 - accuracy: 0.4989\n","Epoch 416/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0203 - accuracy: 0.4915\n","Epoch 417/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0358 - accuracy: 0.5348\n","Epoch 418/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9916 - accuracy: 0.5724\n","Epoch 419/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1037 - accuracy: 0.4593\n","Epoch 420/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0212 - accuracy: 0.4933\n","Epoch 421/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0560 - accuracy: 0.4818\n","Epoch 422/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0305 - accuracy: 0.4938\n","Epoch 423/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0213 - accuracy: 0.4927\n","Epoch 424/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1082 - accuracy: 0.4568\n","Epoch 425/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0380 - accuracy: 0.5337\n","Epoch 426/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0434 - accuracy: 0.5914\n","Epoch 427/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0659 - accuracy: 0.4915\n","Epoch 428/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0180 - accuracy: 0.5302\n","Epoch 429/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9441 - accuracy: 0.5422\n","Epoch 430/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0019 - accuracy: 0.5041\n","Epoch 431/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0816 - accuracy: 0.5030\n","Epoch 432/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1138 - accuracy: 0.4251\n","Epoch 433/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0221 - accuracy: 0.4730\n","Epoch 434/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0733 - accuracy: 0.4884\n","Epoch 435/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0147 - accuracy: 0.5789\n","Epoch 436/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0104 - accuracy: 0.4961\n","Epoch 437/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0300 - accuracy: 0.5574\n","Epoch 438/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0773 - accuracy: 0.4834\n","Epoch 439/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0693 - accuracy: 0.5024\n","Epoch 440/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0495 - accuracy: 0.5148\n","Epoch 441/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0410 - accuracy: 0.5058\n","Epoch 442/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0881 - accuracy: 0.4827\n","Epoch 443/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0470 - accuracy: 0.5067\n","Epoch 444/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9980 - accuracy: 0.5036\n","Epoch 445/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0463 - accuracy: 0.5204\n","Epoch 446/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0266 - accuracy: 0.5094\n","Epoch 447/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0114 - accuracy: 0.4737\n","Epoch 448/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0892 - accuracy: 0.4931\n","Epoch 449/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0423 - accuracy: 0.5107\n","Epoch 450/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0128 - accuracy: 0.5409\n","Epoch 451/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1130 - accuracy: 0.4526\n","Epoch 452/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0325 - accuracy: 0.4976\n","Epoch 453/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9849 - accuracy: 0.5571\n","Epoch 454/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.5217\n","Epoch 455/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0927 - accuracy: 0.5153\n","Epoch 456/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0392 - accuracy: 0.4930\n","Epoch 457/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1346 - accuracy: 0.4926\n","Epoch 458/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0459 - accuracy: 0.5250\n","Epoch 459/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0286 - accuracy: 0.5283\n","Epoch 460/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0561 - accuracy: 0.5350\n","Epoch 461/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1001 - accuracy: 0.4918\n","Epoch 462/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0266 - accuracy: 0.5231\n","Epoch 463/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0080 - accuracy: 0.5057\n","Epoch 464/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9653 - accuracy: 0.5686\n","Epoch 465/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0559 - accuracy: 0.4683\n","Epoch 466/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0344 - accuracy: 0.5595\n","Epoch 467/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9666 - accuracy: 0.5545\n","Epoch 468/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0959 - accuracy: 0.4396\n","Epoch 469/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0045 - accuracy: 0.4560\n","Epoch 470/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0488 - accuracy: 0.4888\n","Epoch 471/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1048 - accuracy: 0.5289\n","Epoch 472/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0289 - accuracy: 0.5602\n","Epoch 473/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0633 - accuracy: 0.5577\n","Epoch 474/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0705 - accuracy: 0.5345\n","Epoch 475/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0641 - accuracy: 0.4946\n","Epoch 476/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1170 - accuracy: 0.4787\n","Epoch 477/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0179 - accuracy: 0.5135\n","Epoch 478/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0533 - accuracy: 0.4904\n","Epoch 479/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0841 - accuracy: 0.4610\n","Epoch 480/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0533 - accuracy: 0.5493\n","Epoch 481/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0661 - accuracy: 0.5132\n","Epoch 482/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0861 - accuracy: 0.4837\n","Epoch 483/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0719 - accuracy: 0.4467\n","Epoch 484/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0344 - accuracy: 0.4990\n","Epoch 485/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9854 - accuracy: 0.5512\n","Epoch 486/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0165 - accuracy: 0.5206\n","Epoch 487/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9799 - accuracy: 0.5226\n","Epoch 488/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1480 - accuracy: 0.5211\n","Epoch 489/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0927 - accuracy: 0.4856\n","Epoch 490/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0091 - accuracy: 0.5433\n","Epoch 491/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0613 - accuracy: 0.5056\n","Epoch 492/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0063 - accuracy: 0.4725\n","Epoch 493/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1072 - accuracy: 0.5114\n","Epoch 494/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9821 - accuracy: 0.5774\n","Epoch 495/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2343 - accuracy: 0.4144\n","Epoch 496/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0545 - accuracy: 0.5329\n","Epoch 497/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0583 - accuracy: 0.5069\n","Epoch 498/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0852 - accuracy: 0.4909\n","Epoch 499/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9991 - accuracy: 0.5323\n","Epoch 500/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9879 - accuracy: 0.4583\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa01858f290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 174ms/step - loss: 1.0944 - accuracy: 0.4667\n","Epoch 1/500\n","28/28 [==============================] - 1s 2ms/step - loss: 5286.1447 - accuracy: 0.3969\n","Epoch 2/500\n","28/28 [==============================] - 0s 2ms/step - loss: 11105.4133 - accuracy: 0.3290\n","Epoch 3/500\n","28/28 [==============================] - 0s 3ms/step - loss: 984.3580 - accuracy: 0.4080\n","Epoch 4/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4048.6170 - accuracy: 0.3863\n","Epoch 5/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1475.9806 - accuracy: 0.3794\n","Epoch 6/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3003.2850 - accuracy: 0.4655\n","Epoch 7/500\n","28/28 [==============================] - 0s 2ms/step - loss: 678.4433 - accuracy: 0.4884\n","Epoch 8/500\n","28/28 [==============================] - 0s 2ms/step - loss: 527.9141 - accuracy: 0.4078\n","Epoch 9/500\n","28/28 [==============================] - 0s 3ms/step - loss: 256.3600 - accuracy: 0.3527\n","Epoch 10/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1575.4245 - accuracy: 0.4323\n","Epoch 11/500\n","28/28 [==============================] - 0s 3ms/step - loss: 261.5366 - accuracy: 0.4626\n","Epoch 12/500\n","28/28 [==============================] - 0s 3ms/step - loss: 221.3046 - accuracy: 0.4179\n","Epoch 13/500\n","28/28 [==============================] - 0s 3ms/step - loss: 661.6613 - accuracy: 0.3671\n","Epoch 14/500\n","28/28 [==============================] - 0s 3ms/step - loss: 271.1863 - accuracy: 0.3867\n","Epoch 15/500\n","28/28 [==============================] - 0s 4ms/step - loss: 85.2025 - accuracy: 0.5607\n","Epoch 16/500\n","28/28 [==============================] - 0s 3ms/step - loss: 54.5481 - accuracy: 0.4032\n","Epoch 17/500\n","28/28 [==============================] - 0s 3ms/step - loss: 85.5161 - accuracy: 0.5454\n","Epoch 18/500\n","28/28 [==============================] - 0s 3ms/step - loss: 47.6180 - accuracy: 0.4533\n","Epoch 19/500\n","28/28 [==============================] - 0s 2ms/step - loss: 214.1276 - accuracy: 0.4287\n","Epoch 20/500\n","28/28 [==============================] - 0s 3ms/step - loss: 77.5586 - accuracy: 0.4242\n","Epoch 21/500\n","28/28 [==============================] - 0s 3ms/step - loss: 76.1436 - accuracy: 0.4119\n","Epoch 22/500\n","28/28 [==============================] - 0s 3ms/step - loss: 78.0355 - accuracy: 0.4896\n","Epoch 23/500\n","28/28 [==============================] - 0s 2ms/step - loss: 34.6819 - accuracy: 0.3633\n","Epoch 24/500\n","28/28 [==============================] - 0s 2ms/step - loss: 90.3618 - accuracy: 0.3671\n","Epoch 25/500\n","28/28 [==============================] - 0s 3ms/step - loss: 68.0078 - accuracy: 0.3177\n","Epoch 26/500\n","28/28 [==============================] - 0s 3ms/step - loss: 60.6912 - accuracy: 0.4261\n","Epoch 27/500\n","28/28 [==============================] - 0s 3ms/step - loss: 50.0859 - accuracy: 0.4094\n","Epoch 28/500\n","28/28 [==============================] - 0s 2ms/step - loss: 93.1130 - accuracy: 0.4958\n","Epoch 29/500\n","28/28 [==============================] - 0s 3ms/step - loss: 20.6315 - accuracy: 0.4551\n","Epoch 30/500\n","28/28 [==============================] - 0s 3ms/step - loss: 12.2176 - accuracy: 0.5381\n","Epoch 31/500\n","28/28 [==============================] - 0s 3ms/step - loss: 11.6716 - accuracy: 0.3987\n","Epoch 32/500\n","28/28 [==============================] - 0s 3ms/step - loss: 92.1894 - accuracy: 0.4968\n","Epoch 33/500\n","28/28 [==============================] - 0s 3ms/step - loss: 171.5177 - accuracy: 0.4579\n","Epoch 34/500\n","28/28 [==============================] - 0s 3ms/step - loss: 158.7273 - accuracy: 0.4675\n","Epoch 35/500\n","28/28 [==============================] - 0s 2ms/step - loss: 26.1330 - accuracy: 0.5624\n","Epoch 36/500\n","28/28 [==============================] - 0s 2ms/step - loss: 63.5640 - accuracy: 0.5051\n","Epoch 37/500\n","28/28 [==============================] - 0s 3ms/step - loss: 72.5997 - accuracy: 0.4458\n","Epoch 38/500\n","28/28 [==============================] - 0s 3ms/step - loss: 11.0769 - accuracy: 0.4080\n","Epoch 39/500\n","28/28 [==============================] - 0s 3ms/step - loss: 6.6266 - accuracy: 0.5366\n","Epoch 40/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.3759 - accuracy: 0.5260\n","Epoch 41/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.0582 - accuracy: 0.5353\n","Epoch 42/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.1589 - accuracy: 0.5361\n","Epoch 43/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.9129 - accuracy: 0.5148\n","Epoch 44/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.6511 - accuracy: 0.6025\n","Epoch 45/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2324 - accuracy: 0.6734\n","Epoch 46/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.2402 - accuracy: 0.5329\n","Epoch 47/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.7702 - accuracy: 0.5283\n","Epoch 48/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.4353 - accuracy: 0.4490\n","Epoch 49/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.3731 - accuracy: 0.5655\n","Epoch 50/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.0048 - accuracy: 0.4240\n","Epoch 51/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.7773 - accuracy: 0.5267\n","Epoch 52/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2114 - accuracy: 0.6563\n","Epoch 53/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.9342 - accuracy: 0.6089\n","Epoch 54/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.8214 - accuracy: 0.4113\n","Epoch 55/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.4542 - accuracy: 0.4473\n","Epoch 56/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.6778 - accuracy: 0.4734\n","Epoch 57/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1612 - accuracy: 0.5998\n","Epoch 58/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.3187 - accuracy: 0.6066\n","Epoch 59/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.8507 - accuracy: 0.4638\n","Epoch 60/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2658 - accuracy: 0.4503\n","Epoch 61/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2087 - accuracy: 0.5492\n","Epoch 62/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.8065 - accuracy: 0.5012\n","Epoch 63/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2674 - accuracy: 0.5055\n","Epoch 64/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.6626 - accuracy: 0.4532\n","Epoch 65/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.1183 - accuracy: 0.6034\n","Epoch 66/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.8664 - accuracy: 0.6333\n","Epoch 67/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9976 - accuracy: 0.6411\n","Epoch 68/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0994 - accuracy: 0.5586\n","Epoch 69/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1893 - accuracy: 0.5725\n","Epoch 70/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1268 - accuracy: 0.6402\n","Epoch 71/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9759 - accuracy: 0.6469\n","Epoch 72/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9546 - accuracy: 0.6118\n","Epoch 73/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8425 - accuracy: 0.6230\n","Epoch 74/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9172 - accuracy: 0.6231\n","Epoch 75/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1852 - accuracy: 0.6035\n","Epoch 76/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8653 - accuracy: 0.6326\n","Epoch 77/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9796 - accuracy: 0.6171\n","Epoch 78/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2670 - accuracy: 0.5179\n","Epoch 79/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.3720 - accuracy: 0.5453\n","Epoch 80/500\n","28/28 [==============================] - 0s 4ms/step - loss: 0.9439 - accuracy: 0.6181\n","Epoch 81/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1027 - accuracy: 0.5664\n","Epoch 82/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8777 - accuracy: 0.6590\n","Epoch 83/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1636 - accuracy: 0.5633\n","Epoch 84/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.7620 - accuracy: 0.6184\n","Epoch 85/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.0542 - accuracy: 0.5778\n","Epoch 86/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.3917 - accuracy: 0.4610\n","Epoch 87/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.5671 - accuracy: 0.4905\n","Epoch 88/500\n","28/28 [==============================] - 0s 3ms/step - loss: 21.4452 - accuracy: 0.4730\n","Epoch 89/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.7802 - accuracy: 0.4627\n","Epoch 90/500\n","28/28 [==============================] - 0s 3ms/step - loss: 15.0367 - accuracy: 0.5170\n","Epoch 91/500\n","28/28 [==============================] - 0s 2ms/step - loss: 41.6722 - accuracy: 0.5700\n","Epoch 92/500\n","28/28 [==============================] - 0s 2ms/step - loss: 35.0539 - accuracy: 0.5168\n","Epoch 93/500\n","28/28 [==============================] - 0s 3ms/step - loss: 79.5721 - accuracy: 0.4641\n","Epoch 94/500\n","28/28 [==============================] - 0s 2ms/step - loss: 139.2605 - accuracy: 0.5058\n","Epoch 95/500\n","28/28 [==============================] - 0s 3ms/step - loss: 245.7766 - accuracy: 0.4766\n","Epoch 96/500\n","28/28 [==============================] - 0s 2ms/step - loss: 415.2405 - accuracy: 0.4139\n","Epoch 97/500\n","28/28 [==============================] - 0s 3ms/step - loss: 646.7501 - accuracy: 0.4058\n","Epoch 98/500\n","28/28 [==============================] - 0s 2ms/step - loss: 198.6313 - accuracy: 0.5363\n","Epoch 99/500\n","28/28 [==============================] - 0s 3ms/step - loss: 38.2928 - accuracy: 0.5209\n","Epoch 100/500\n","28/28 [==============================] - 0s 3ms/step - loss: 92.4288 - accuracy: 0.5567\n","Epoch 101/500\n","28/28 [==============================] - 0s 3ms/step - loss: 115.7595 - accuracy: 0.4678\n","Epoch 102/500\n","28/28 [==============================] - 0s 3ms/step - loss: 191.0068 - accuracy: 0.5356\n","Epoch 103/500\n","28/28 [==============================] - 0s 2ms/step - loss: 120.9206 - accuracy: 0.5863\n","Epoch 104/500\n","28/28 [==============================] - 0s 2ms/step - loss: 24.6340 - accuracy: 0.5638\n","Epoch 105/500\n","28/28 [==============================] - 0s 3ms/step - loss: 79.2296 - accuracy: 0.4728\n","Epoch 106/500\n","28/28 [==============================] - 0s 3ms/step - loss: 59.0935 - accuracy: 0.4778\n","Epoch 107/500\n","28/28 [==============================] - 0s 3ms/step - loss: 27.2245 - accuracy: 0.5717\n","Epoch 108/500\n","28/28 [==============================] - 0s 3ms/step - loss: 14.6418 - accuracy: 0.6082\n","Epoch 109/500\n","28/28 [==============================] - 0s 3ms/step - loss: 14.0604 - accuracy: 0.4843\n","Epoch 110/500\n","28/28 [==============================] - 0s 2ms/step - loss: 66.8936 - accuracy: 0.5534\n","Epoch 111/500\n","28/28 [==============================] - 0s 2ms/step - loss: 33.4804 - accuracy: 0.5159\n","Epoch 112/500\n","28/28 [==============================] - 0s 2ms/step - loss: 48.1578 - accuracy: 0.4274\n","Epoch 113/500\n","28/28 [==============================] - 0s 3ms/step - loss: 13.4196 - accuracy: 0.4970\n","Epoch 114/500\n","28/28 [==============================] - 0s 3ms/step - loss: 45.6942 - accuracy: 0.4786\n","Epoch 115/500\n","28/28 [==============================] - 0s 3ms/step - loss: 12.9811 - accuracy: 0.4525\n","Epoch 116/500\n","28/28 [==============================] - 0s 2ms/step - loss: 20.1703 - accuracy: 0.5260\n","Epoch 117/500\n","28/28 [==============================] - 0s 3ms/step - loss: 8.0298 - accuracy: 0.5440\n","Epoch 118/500\n","28/28 [==============================] - 0s 3ms/step - loss: 6.8260 - accuracy: 0.5416\n","Epoch 119/500\n","28/28 [==============================] - 0s 2ms/step - loss: 28.0615 - accuracy: 0.4919\n","Epoch 120/500\n","28/28 [==============================] - 0s 3ms/step - loss: 6.2605 - accuracy: 0.5963\n","Epoch 121/500\n","28/28 [==============================] - 0s 3ms/step - loss: 14.2229 - accuracy: 0.5238\n","Epoch 122/500\n","28/28 [==============================] - 0s 3ms/step - loss: 6.2188 - accuracy: 0.5245\n","Epoch 123/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.2931 - accuracy: 0.5098\n","Epoch 124/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.6778 - accuracy: 0.6714\n","Epoch 125/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9944 - accuracy: 0.5806\n","Epoch 126/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.5461 - accuracy: 0.5639\n","Epoch 127/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.4443 - accuracy: 0.5137\n","Epoch 128/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9760 - accuracy: 0.5968\n","Epoch 129/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.5851 - accuracy: 0.4970\n","Epoch 130/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.5921 - accuracy: 0.5289\n","Epoch 131/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2237 - accuracy: 0.4649\n","Epoch 132/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2220 - accuracy: 0.5876\n","Epoch 133/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0174 - accuracy: 0.5472\n","Epoch 134/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9680 - accuracy: 0.5619\n","Epoch 135/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0470 - accuracy: 0.5673\n","Epoch 136/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9588 - accuracy: 0.5161\n","Epoch 137/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1268 - accuracy: 0.5732\n","Epoch 138/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9828 - accuracy: 0.4953\n","Epoch 139/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1099 - accuracy: 0.5639\n","Epoch 140/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0840 - accuracy: 0.5464\n","Epoch 141/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9398 - accuracy: 0.5932\n","Epoch 142/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1440 - accuracy: 0.5015\n","Epoch 143/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0996 - accuracy: 0.5194\n","Epoch 144/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0414 - accuracy: 0.5188\n","Epoch 145/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0356 - accuracy: 0.5584\n","Epoch 146/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0243 - accuracy: 0.5863\n","Epoch 147/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0565 - accuracy: 0.4858\n","Epoch 148/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9907 - accuracy: 0.5419\n","Epoch 149/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9855 - accuracy: 0.5405\n","Epoch 150/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0081 - accuracy: 0.5630\n","Epoch 151/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9874 - accuracy: 0.5871\n","Epoch 152/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0199 - accuracy: 0.5376\n","Epoch 153/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.8950 - accuracy: 0.6428\n","Epoch 154/500\n","28/28 [==============================] - 0s 5ms/step - loss: 1.0167 - accuracy: 0.5922\n","Epoch 155/500\n","28/28 [==============================] - 0s 6ms/step - loss: 0.9456 - accuracy: 0.5893\n","Epoch 156/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9721 - accuracy: 0.5643\n","Epoch 157/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0373 - accuracy: 0.5510\n","Epoch 158/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.3097 - accuracy: 0.5073\n","Epoch 159/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9468 - accuracy: 0.5153\n","Epoch 160/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1458 - accuracy: 0.5248\n","Epoch 161/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9837 - accuracy: 0.5392\n","Epoch 162/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9544 - accuracy: 0.5275\n","Epoch 163/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9456 - accuracy: 0.5527\n","Epoch 164/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0824 - accuracy: 0.5441\n","Epoch 165/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1812 - accuracy: 0.4952\n","Epoch 166/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9870 - accuracy: 0.5579\n","Epoch 167/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9738 - accuracy: 0.6539\n","Epoch 168/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9146 - accuracy: 0.5746\n","Epoch 169/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9373 - accuracy: 0.5793\n","Epoch 170/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9782 - accuracy: 0.5435\n","Epoch 171/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0105 - accuracy: 0.5508\n","Epoch 172/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0412 - accuracy: 0.4783\n","Epoch 173/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9709 - accuracy: 0.5314\n","Epoch 174/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9430 - accuracy: 0.5229\n","Epoch 175/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0737 - accuracy: 0.5853\n","Epoch 176/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0397 - accuracy: 0.5005\n","Epoch 177/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9972 - accuracy: 0.5332\n","Epoch 178/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0675 - accuracy: 0.5875\n","Epoch 179/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0295 - accuracy: 0.5211\n","Epoch 180/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0876 - accuracy: 0.4815\n","Epoch 181/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9680 - accuracy: 0.5826\n","Epoch 182/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1850 - accuracy: 0.5571\n","Epoch 183/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9564 - accuracy: 0.6035\n","Epoch 184/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1414 - accuracy: 0.5531\n","Epoch 185/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0142 - accuracy: 0.5738\n","Epoch 186/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1148 - accuracy: 0.5557\n","Epoch 187/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9987 - accuracy: 0.5166\n","Epoch 188/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9703 - accuracy: 0.5088\n","Epoch 189/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0157 - accuracy: 0.5518\n","Epoch 190/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9768 - accuracy: 0.6030\n","Epoch 191/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0561 - accuracy: 0.4965\n","Epoch 192/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9880 - accuracy: 0.5387\n","Epoch 193/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9994 - accuracy: 0.5584\n","Epoch 194/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8766 - accuracy: 0.5935\n","Epoch 195/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8855 - accuracy: 0.5893\n","Epoch 196/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0738 - accuracy: 0.4916\n","Epoch 197/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9559 - accuracy: 0.5386\n","Epoch 198/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.8754 - accuracy: 0.5863\n","Epoch 199/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0222 - accuracy: 0.5604\n","Epoch 200/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9722 - accuracy: 0.5746\n","Epoch 201/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9114 - accuracy: 0.5696\n","Epoch 202/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9880 - accuracy: 0.5619\n","Epoch 203/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9179 - accuracy: 0.6049\n","Epoch 204/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0111 - accuracy: 0.5708\n","Epoch 205/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9207 - accuracy: 0.5757\n","Epoch 206/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0183 - accuracy: 0.5677\n","Epoch 207/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9325 - accuracy: 0.5701\n","Epoch 208/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9867 - accuracy: 0.5160\n","Epoch 209/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9796 - accuracy: 0.5568\n","Epoch 210/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9736 - accuracy: 0.5941\n","Epoch 211/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9738 - accuracy: 0.5373\n","Epoch 212/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8512 - accuracy: 0.6321\n","Epoch 213/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9363 - accuracy: 0.5718\n","Epoch 214/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9513 - accuracy: 0.5860\n","Epoch 215/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9566 - accuracy: 0.5444\n","Epoch 216/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9713 - accuracy: 0.5467\n","Epoch 217/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9968 - accuracy: 0.5469\n","Epoch 218/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0681 - accuracy: 0.4884\n","Epoch 219/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9842 - accuracy: 0.5492\n","Epoch 220/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9630 - accuracy: 0.5507\n","Epoch 221/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9806 - accuracy: 0.5502\n","Epoch 222/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9679 - accuracy: 0.5677\n","Epoch 223/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0258 - accuracy: 0.5283\n","Epoch 224/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9770 - accuracy: 0.5489\n","Epoch 225/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9641 - accuracy: 0.5470\n","Epoch 226/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9333 - accuracy: 0.5532\n","Epoch 227/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9253 - accuracy: 0.5954\n","Epoch 228/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0020 - accuracy: 0.5122\n","Epoch 229/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9667 - accuracy: 0.5634\n","Epoch 230/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9965 - accuracy: 0.5519\n","Epoch 231/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0226 - accuracy: 0.6030\n","Epoch 232/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9767 - accuracy: 0.6009\n","Epoch 233/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0787 - accuracy: 0.4877\n","Epoch 234/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9646 - accuracy: 0.5422\n","Epoch 235/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9396 - accuracy: 0.5859\n","Epoch 236/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9563 - accuracy: 0.5476\n","Epoch 237/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0335 - accuracy: 0.5345\n","Epoch 238/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9370 - accuracy: 0.5798\n","Epoch 239/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0243 - accuracy: 0.5291\n","Epoch 240/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9791 - accuracy: 0.5393\n","Epoch 241/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9838 - accuracy: 0.5281\n","Epoch 242/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0515 - accuracy: 0.5210\n","Epoch 243/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9415 - accuracy: 0.6199\n","Epoch 244/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0211 - accuracy: 0.5286\n","Epoch 245/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0506 - accuracy: 0.5299\n","Epoch 246/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9323 - accuracy: 0.5738\n","Epoch 247/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9094 - accuracy: 0.5711\n","Epoch 248/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0678 - accuracy: 0.5273\n","Epoch 249/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0262 - accuracy: 0.5603\n","Epoch 250/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9255 - accuracy: 0.5385\n","Epoch 251/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9762 - accuracy: 0.5207\n","Epoch 252/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0069 - accuracy: 0.5484\n","Epoch 253/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9128 - accuracy: 0.5749\n","Epoch 254/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0135 - accuracy: 0.5396\n","Epoch 255/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9881 - accuracy: 0.5550\n","Epoch 256/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0920 - accuracy: 0.5338\n","Epoch 257/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0331 - accuracy: 0.5738\n","Epoch 258/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.8990 - accuracy: 0.6062\n","Epoch 259/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9482 - accuracy: 0.5779\n","Epoch 260/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0775 - accuracy: 0.4764\n","Epoch 261/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9716 - accuracy: 0.5877\n","Epoch 262/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0310 - accuracy: 0.6059\n","Epoch 263/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9627 - accuracy: 0.5360\n","Epoch 264/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0388 - accuracy: 0.5571\n","Epoch 265/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9356 - accuracy: 0.5386\n","Epoch 266/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9571 - accuracy: 0.5317\n","Epoch 267/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9648 - accuracy: 0.5925\n","Epoch 268/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0143 - accuracy: 0.5497\n","Epoch 269/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8739 - accuracy: 0.6039\n","Epoch 270/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9703 - accuracy: 0.5463\n","Epoch 271/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9932 - accuracy: 0.5578\n","Epoch 272/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8986 - accuracy: 0.5689\n","Epoch 273/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9813 - accuracy: 0.5625\n","Epoch 274/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9231 - accuracy: 0.5766\n","Epoch 275/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9557 - accuracy: 0.6118\n","Epoch 276/500\n","28/28 [==============================] - 0s 4ms/step - loss: 1.0189 - accuracy: 0.4620\n","Epoch 277/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9754 - accuracy: 0.5564\n","Epoch 278/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9250 - accuracy: 0.5267\n","Epoch 279/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0535 - accuracy: 0.5692\n","Epoch 280/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9709 - accuracy: 0.5138\n","Epoch 281/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.8929 - accuracy: 0.5008\n","Epoch 282/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0073 - accuracy: 0.5798\n","Epoch 283/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0195 - accuracy: 0.5911\n","Epoch 284/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1966 - accuracy: 0.5091\n","Epoch 285/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.8801 - accuracy: 0.6486\n","Epoch 286/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0646 - accuracy: 0.5018\n","Epoch 287/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.8897 - accuracy: 0.5814\n","Epoch 288/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9421 - accuracy: 0.5845\n","Epoch 289/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9265 - accuracy: 0.6073\n","Epoch 290/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9122 - accuracy: 0.5377\n","Epoch 291/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9952 - accuracy: 0.5675\n","Epoch 292/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0208 - accuracy: 0.5169\n","Epoch 293/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9622 - accuracy: 0.5414\n","Epoch 294/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8430 - accuracy: 0.6244\n","Epoch 295/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9858 - accuracy: 0.5451\n","Epoch 296/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8801 - accuracy: 0.5799\n","Epoch 297/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0354 - accuracy: 0.5939\n","Epoch 298/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0577 - accuracy: 0.5282\n","Epoch 299/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9995 - accuracy: 0.5287\n","Epoch 300/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9574 - accuracy: 0.6080\n","Epoch 301/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9649 - accuracy: 0.5303\n","Epoch 302/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9390 - accuracy: 0.5374\n","Epoch 303/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9019 - accuracy: 0.5832\n","Epoch 304/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0622 - accuracy: 0.5151\n","Epoch 305/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9327 - accuracy: 0.5463\n","Epoch 306/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9341 - accuracy: 0.5485\n","Epoch 307/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0016 - accuracy: 0.5787\n","Epoch 308/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9488 - accuracy: 0.5894\n","Epoch 309/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8938 - accuracy: 0.6061\n","Epoch 310/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9613 - accuracy: 0.5699\n","Epoch 311/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8966 - accuracy: 0.6183\n","Epoch 312/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0426 - accuracy: 0.4802\n","Epoch 313/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0308 - accuracy: 0.4980\n","Epoch 314/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0298 - accuracy: 0.5086\n","Epoch 315/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9848 - accuracy: 0.5558\n","Epoch 316/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0723 - accuracy: 0.4396\n","Epoch 317/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0177 - accuracy: 0.5174\n","Epoch 318/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0167 - accuracy: 0.5464\n","Epoch 319/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9411 - accuracy: 0.5803\n","Epoch 320/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0282 - accuracy: 0.5054\n","Epoch 321/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0475 - accuracy: 0.5379\n","Epoch 322/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9676 - accuracy: 0.5373\n","Epoch 323/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9401 - accuracy: 0.5339\n","Epoch 324/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0121 - accuracy: 0.5467\n","Epoch 325/500\n","28/28 [==============================] - 0s 4ms/step - loss: 0.9200 - accuracy: 0.6091\n","Epoch 326/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9559 - accuracy: 0.5296\n","Epoch 327/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0121 - accuracy: 0.4932\n","Epoch 328/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0433 - accuracy: 0.5076\n","Epoch 329/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9669 - accuracy: 0.5487\n","Epoch 330/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0638 - accuracy: 0.5123\n","Epoch 331/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0661 - accuracy: 0.5463\n","Epoch 332/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9359 - accuracy: 0.5586\n","Epoch 333/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9480 - accuracy: 0.5706\n","Epoch 334/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9378 - accuracy: 0.5809\n","Epoch 335/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0448 - accuracy: 0.4885\n","Epoch 336/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9180 - accuracy: 0.6247\n","Epoch 337/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9182 - accuracy: 0.5930\n","Epoch 338/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9976 - accuracy: 0.5757\n","Epoch 339/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9985 - accuracy: 0.5613\n","Epoch 340/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9999 - accuracy: 0.4824\n","Epoch 341/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0228 - accuracy: 0.5245\n","Epoch 342/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0422 - accuracy: 0.4970\n","Epoch 343/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9865 - accuracy: 0.5371\n","Epoch 344/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0192 - accuracy: 0.5136\n","Epoch 345/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8878 - accuracy: 0.5890\n","Epoch 346/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9428 - accuracy: 0.5739\n","Epoch 347/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9836 - accuracy: 0.5222\n","Epoch 348/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9648 - accuracy: 0.5361\n","Epoch 349/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9952 - accuracy: 0.5654\n","Epoch 350/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8851 - accuracy: 0.6030\n","Epoch 351/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9220 - accuracy: 0.5395\n","Epoch 352/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9667 - accuracy: 0.5758\n","Epoch 353/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8897 - accuracy: 0.6017\n","Epoch 354/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9808 - accuracy: 0.5734\n","Epoch 355/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9599 - accuracy: 0.5370\n","Epoch 356/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9605 - accuracy: 0.4799\n","Epoch 357/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.3218 - accuracy: 0.4635\n","Epoch 358/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.2350 - accuracy: 0.4908\n","Epoch 359/500\n","28/28 [==============================] - 0s 2ms/step - loss: 139.5139 - accuracy: 0.4552\n","Epoch 360/500\n","28/28 [==============================] - 0s 3ms/step - loss: 558.2816 - accuracy: 0.4412\n","Epoch 361/500\n","28/28 [==============================] - 0s 2ms/step - loss: 738.9254 - accuracy: 0.5003\n","Epoch 362/500\n","28/28 [==============================] - 0s 3ms/step - loss: 521.7650 - accuracy: 0.4529\n","Epoch 363/500\n","28/28 [==============================] - 0s 3ms/step - loss: 729.7585 - accuracy: 0.4916\n","Epoch 364/500\n","28/28 [==============================] - 0s 2ms/step - loss: 460.8802 - accuracy: 0.5122\n","Epoch 365/500\n","28/28 [==============================] - 0s 2ms/step - loss: 79.7556 - accuracy: 0.4698\n","Epoch 366/500\n","28/28 [==============================] - 0s 3ms/step - loss: 83.1637 - accuracy: 0.5381\n","Epoch 367/500\n","28/28 [==============================] - 0s 2ms/step - loss: 30.1855 - accuracy: 0.4031\n","Epoch 368/500\n","28/28 [==============================] - 0s 2ms/step - loss: 147.0342 - accuracy: 0.5030\n","Epoch 369/500\n","28/28 [==============================] - 0s 2ms/step - loss: 58.5959 - accuracy: 0.4459\n","Epoch 370/500\n","28/28 [==============================] - 0s 3ms/step - loss: 113.2280 - accuracy: 0.4603\n","Epoch 371/500\n","28/28 [==============================] - 0s 2ms/step - loss: 126.1690 - accuracy: 0.4491\n","Epoch 372/500\n","28/28 [==============================] - 0s 2ms/step - loss: 30.9685 - accuracy: 0.5154\n","Epoch 373/500\n","28/28 [==============================] - 0s 2ms/step - loss: 22.4795 - accuracy: 0.4749\n","Epoch 374/500\n","28/28 [==============================] - 0s 2ms/step - loss: 5.1915 - accuracy: 0.5193\n","Epoch 375/500\n","28/28 [==============================] - 0s 2ms/step - loss: 20.0661 - accuracy: 0.4106\n","Epoch 376/500\n","28/28 [==============================] - 0s 3ms/step - loss: 7.8429 - accuracy: 0.5113\n","Epoch 377/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.1146 - accuracy: 0.5528\n","Epoch 378/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.4689 - accuracy: 0.5126\n","Epoch 379/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.4334 - accuracy: 0.5042\n","Epoch 380/500\n","28/28 [==============================] - 0s 3ms/step - loss: 29.1463 - accuracy: 0.4423\n","Epoch 381/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.4902 - accuracy: 0.5657\n","Epoch 382/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.2416 - accuracy: 0.4948\n","Epoch 383/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.4505 - accuracy: 0.4859\n","Epoch 384/500\n","28/28 [==============================] - 0s 2ms/step - loss: 17.9416 - accuracy: 0.5031\n","Epoch 385/500\n","28/28 [==============================] - 0s 2ms/step - loss: 21.4114 - accuracy: 0.5192\n","Epoch 386/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.6892 - accuracy: 0.4607\n","Epoch 387/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.3888 - accuracy: 0.5395\n","Epoch 388/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0662 - accuracy: 0.5222\n","Epoch 389/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.3254 - accuracy: 0.5197\n","Epoch 390/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.1437 - accuracy: 0.5108\n","Epoch 391/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.0344 - accuracy: 0.4858\n","Epoch 392/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0133 - accuracy: 0.5791\n","Epoch 393/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.9351 - accuracy: 0.5226\n","Epoch 394/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.7484 - accuracy: 0.4734\n","Epoch 395/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2080 - accuracy: 0.4842\n","Epoch 396/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1359 - accuracy: 0.5435\n","Epoch 397/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9447 - accuracy: 0.5271\n","Epoch 398/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9720 - accuracy: 0.4825\n","Epoch 399/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9732 - accuracy: 0.5554\n","Epoch 400/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0692 - accuracy: 0.4676\n","Epoch 401/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9737 - accuracy: 0.5863\n","Epoch 402/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0405 - accuracy: 0.4687\n","Epoch 403/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0469 - accuracy: 0.4784\n","Epoch 404/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0673 - accuracy: 0.4581\n","Epoch 405/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9982 - accuracy: 0.5554\n","Epoch 406/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9496 - accuracy: 0.5129\n","Epoch 407/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9699 - accuracy: 0.5587\n","Epoch 408/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0806 - accuracy: 0.4743\n","Epoch 409/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9750 - accuracy: 0.5179\n","Epoch 410/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0866 - accuracy: 0.5813\n","Epoch 411/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9997 - accuracy: 0.5703\n","Epoch 412/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1090 - accuracy: 0.4602\n","Epoch 413/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1432 - accuracy: 0.3793\n","Epoch 414/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0097 - accuracy: 0.4930\n","Epoch 415/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0560 - accuracy: 0.5140\n","Epoch 416/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1183 - accuracy: 0.4372\n","Epoch 417/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0016 - accuracy: 0.5635\n","Epoch 418/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9932 - accuracy: 0.5508\n","Epoch 419/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1028 - accuracy: 0.4243\n","Epoch 420/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0141 - accuracy: 0.5161\n","Epoch 421/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0419 - accuracy: 0.4598\n","Epoch 422/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0502 - accuracy: 0.4712\n","Epoch 423/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9471 - accuracy: 0.5292\n","Epoch 424/500\n","28/28 [==============================] - 0s 4ms/step - loss: 1.0565 - accuracy: 0.4656\n","Epoch 425/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0465 - accuracy: 0.5473\n","Epoch 426/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9884 - accuracy: 0.5966\n","Epoch 427/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0488 - accuracy: 0.5151\n","Epoch 428/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9913 - accuracy: 0.5416\n","Epoch 429/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0010 - accuracy: 0.5103\n","Epoch 430/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1247 - accuracy: 0.4631\n","Epoch 431/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0120 - accuracy: 0.4979\n","Epoch 432/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0688 - accuracy: 0.4570\n","Epoch 433/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0781 - accuracy: 0.4521\n","Epoch 434/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0209 - accuracy: 0.5289\n","Epoch 435/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0112 - accuracy: 0.5144\n","Epoch 436/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0047 - accuracy: 0.4854\n","Epoch 437/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0145 - accuracy: 0.5468\n","Epoch 438/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0909 - accuracy: 0.5081\n","Epoch 439/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0435 - accuracy: 0.5272\n","Epoch 440/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0193 - accuracy: 0.5099\n","Epoch 441/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0062 - accuracy: 0.5036\n","Epoch 442/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0372 - accuracy: 0.5345\n","Epoch 443/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0864 - accuracy: 0.4572\n","Epoch 444/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0906 - accuracy: 0.4462\n","Epoch 445/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0420 - accuracy: 0.5388\n","Epoch 446/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0471 - accuracy: 0.4839\n","Epoch 447/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0427 - accuracy: 0.4937\n","Epoch 448/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0497 - accuracy: 0.5095\n","Epoch 449/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9779 - accuracy: 0.5508\n","Epoch 450/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9763 - accuracy: 0.5913\n","Epoch 451/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0015 - accuracy: 0.5275\n","Epoch 452/500\n","28/28 [==============================] - 0s 4ms/step - loss: 1.0404 - accuracy: 0.4680\n","Epoch 453/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9880 - accuracy: 0.5518\n","Epoch 454/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0281 - accuracy: 0.5180\n","Epoch 455/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0203 - accuracy: 0.5593\n","Epoch 456/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0492 - accuracy: 0.4890\n","Epoch 457/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0777 - accuracy: 0.5126\n","Epoch 458/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0364 - accuracy: 0.5096\n","Epoch 459/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0763 - accuracy: 0.4800\n","Epoch 460/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0842 - accuracy: 0.5478\n","Epoch 461/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0439 - accuracy: 0.5530\n","Epoch 462/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0116 - accuracy: 0.5423\n","Epoch 463/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9767 - accuracy: 0.4912\n","Epoch 464/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9541 - accuracy: 0.5142\n","Epoch 465/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9793 - accuracy: 0.5234\n","Epoch 466/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9666 - accuracy: 0.5802\n","Epoch 467/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9682 - accuracy: 0.5639\n","Epoch 468/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1002 - accuracy: 0.4449\n","Epoch 469/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9736 - accuracy: 0.4827\n","Epoch 470/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0194 - accuracy: 0.5517\n","Epoch 471/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1370 - accuracy: 0.5024\n","Epoch 472/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0491 - accuracy: 0.5319\n","Epoch 473/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0874 - accuracy: 0.5229\n","Epoch 474/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0084 - accuracy: 0.5424\n","Epoch 475/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0459 - accuracy: 0.5106\n","Epoch 476/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1052 - accuracy: 0.5024\n","Epoch 477/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9864 - accuracy: 0.5146\n","Epoch 478/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0307 - accuracy: 0.5682\n","Epoch 479/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0727 - accuracy: 0.4580\n","Epoch 480/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9777 - accuracy: 0.5296\n","Epoch 481/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9564 - accuracy: 0.5436\n","Epoch 482/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0486 - accuracy: 0.5015\n","Epoch 483/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9597 - accuracy: 0.5539\n","Epoch 484/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9936 - accuracy: 0.5260\n","Epoch 485/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0098 - accuracy: 0.5080\n","Epoch 486/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0688 - accuracy: 0.4955\n","Epoch 487/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9840 - accuracy: 0.4959\n","Epoch 488/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0374 - accuracy: 0.5619\n","Epoch 489/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0118 - accuracy: 0.5296\n","Epoch 490/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0407 - accuracy: 0.5533\n","Epoch 491/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0943 - accuracy: 0.4914\n","Epoch 492/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9794 - accuracy: 0.5020\n","Epoch 493/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0846 - accuracy: 0.5229\n","Epoch 494/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9874 - accuracy: 0.5525\n","Epoch 495/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1140 - accuracy: 0.4694\n","Epoch 496/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0540 - accuracy: 0.5591\n","Epoch 497/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0759 - accuracy: 0.5013\n","Epoch 498/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9324 - accuracy: 0.6039\n","Epoch 499/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9820 - accuracy: 0.5141\n","Epoch 500/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0535 - accuracy: 0.4507\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa01859b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 182ms/step - loss: 4.3550 - accuracy: 0.4667\n","Epoch 1/500\n","28/28 [==============================] - 1s 3ms/step - loss: 3802.4075 - accuracy: 0.3700\n","Epoch 2/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1993.0095 - accuracy: 0.4980\n","Epoch 3/500\n","28/28 [==============================] - 0s 2ms/step - loss: 5162.6434 - accuracy: 0.3477\n","Epoch 4/500\n","28/28 [==============================] - 0s 3ms/step - loss: 561.7202 - accuracy: 0.4839\n","Epoch 5/500\n","28/28 [==============================] - 0s 2ms/step - loss: 437.8444 - accuracy: 0.4332\n","Epoch 6/500\n","28/28 [==============================] - 0s 3ms/step - loss: 506.1907 - accuracy: 0.3303\n","Epoch 7/500\n","28/28 [==============================] - 0s 2ms/step - loss: 847.4073 - accuracy: 0.5419\n","Epoch 8/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1031.0987 - accuracy: 0.3860\n","Epoch 9/500\n","28/28 [==============================] - 0s 2ms/step - loss: 138.4610 - accuracy: 0.3862\n","Epoch 10/500\n","28/28 [==============================] - 0s 2ms/step - loss: 192.8134 - accuracy: 0.4900\n","Epoch 11/500\n","28/28 [==============================] - 0s 2ms/step - loss: 185.7040 - accuracy: 0.4636\n","Epoch 12/500\n","28/28 [==============================] - 0s 3ms/step - loss: 68.3815 - accuracy: 0.5453\n","Epoch 13/500\n","28/28 [==============================] - 0s 2ms/step - loss: 71.7252 - accuracy: 0.4668\n","Epoch 14/500\n","28/28 [==============================] - 0s 3ms/step - loss: 28.7117 - accuracy: 0.4885\n","Epoch 15/500\n","28/28 [==============================] - 0s 3ms/step - loss: 25.9097 - accuracy: 0.4727\n","Epoch 16/500\n","28/28 [==============================] - 0s 2ms/step - loss: 73.4831 - accuracy: 0.4536\n","Epoch 17/500\n","28/28 [==============================] - 0s 3ms/step - loss: 81.2275 - accuracy: 0.4583\n","Epoch 18/500\n","28/28 [==============================] - 0s 2ms/step - loss: 36.9298 - accuracy: 0.4615\n","Epoch 19/500\n","28/28 [==============================] - 0s 2ms/step - loss: 40.4874 - accuracy: 0.4967\n","Epoch 20/500\n","28/28 [==============================] - 0s 2ms/step - loss: 33.8528 - accuracy: 0.4391\n","Epoch 21/500\n","28/28 [==============================] - 0s 3ms/step - loss: 30.9986 - accuracy: 0.4485\n","Epoch 22/500\n","28/28 [==============================] - 0s 2ms/step - loss: 16.6406 - accuracy: 0.4803\n","Epoch 23/500\n","28/28 [==============================] - 0s 2ms/step - loss: 14.9620 - accuracy: 0.4632\n","Epoch 24/500\n","28/28 [==============================] - 0s 3ms/step - loss: 7.6567 - accuracy: 0.5087\n","Epoch 25/500\n","28/28 [==============================] - 0s 3ms/step - loss: 6.1890 - accuracy: 0.4495\n","Epoch 26/500\n","28/28 [==============================] - 0s 3ms/step - loss: 16.9007 - accuracy: 0.4074\n","Epoch 27/500\n","28/28 [==============================] - 0s 3ms/step - loss: 10.4834 - accuracy: 0.5034\n","Epoch 28/500\n","28/28 [==============================] - 0s 3ms/step - loss: 11.5146 - accuracy: 0.5586\n","Epoch 29/500\n","28/28 [==============================] - 0s 2ms/step - loss: 9.7411 - accuracy: 0.4889\n","Epoch 30/500\n","28/28 [==============================] - 0s 2ms/step - loss: 6.3859 - accuracy: 0.4354\n","Epoch 31/500\n","28/28 [==============================] - 0s 3ms/step - loss: 9.1906 - accuracy: 0.4920\n","Epoch 32/500\n","28/28 [==============================] - 0s 3ms/step - loss: 9.1713 - accuracy: 0.5111\n","Epoch 33/500\n","28/28 [==============================] - 0s 2ms/step - loss: 18.4680 - accuracy: 0.5693\n","Epoch 34/500\n","28/28 [==============================] - 0s 3ms/step - loss: 9.5565 - accuracy: 0.4712\n","Epoch 35/500\n","28/28 [==============================] - 0s 3ms/step - loss: 7.1769 - accuracy: 0.4628\n","Epoch 36/500\n","28/28 [==============================] - 0s 3ms/step - loss: 8.0075 - accuracy: 0.5339\n","Epoch 37/500\n","28/28 [==============================] - 0s 3ms/step - loss: 8.6123 - accuracy: 0.4344\n","Epoch 38/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.3762 - accuracy: 0.4319\n","Epoch 39/500\n","28/28 [==============================] - 0s 3ms/step - loss: 6.1918 - accuracy: 0.5380\n","Epoch 40/500\n","28/28 [==============================] - 0s 2ms/step - loss: 7.4705 - accuracy: 0.4121\n","Epoch 41/500\n","28/28 [==============================] - 0s 2ms/step - loss: 10.2084 - accuracy: 0.4166\n","Epoch 42/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.7147 - accuracy: 0.6192\n","Epoch 43/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.2508 - accuracy: 0.5623\n","Epoch 44/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.9045 - accuracy: 0.5131\n","Epoch 45/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.4974 - accuracy: 0.6003\n","Epoch 46/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.8366 - accuracy: 0.5668\n","Epoch 47/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.2009 - accuracy: 0.5149\n","Epoch 48/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.2389 - accuracy: 0.5176\n","Epoch 49/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.2437 - accuracy: 0.5480\n","Epoch 50/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.3078 - accuracy: 0.4002\n","Epoch 51/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.9024 - accuracy: 0.5860\n","Epoch 52/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.2975 - accuracy: 0.5648\n","Epoch 53/500\n","28/28 [==============================] - 0s 2ms/step - loss: 5.2929 - accuracy: 0.5190\n","Epoch 54/500\n","28/28 [==============================] - 0s 2ms/step - loss: 6.6645 - accuracy: 0.4158\n","Epoch 55/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.6695 - accuracy: 0.4402\n","Epoch 56/500\n","28/28 [==============================] - 0s 3ms/step - loss: 9.8479 - accuracy: 0.3937\n","Epoch 57/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.7241 - accuracy: 0.5341\n","Epoch 58/500\n","28/28 [==============================] - 0s 3ms/step - loss: 6.0200 - accuracy: 0.4494\n","Epoch 59/500\n","28/28 [==============================] - 0s 3ms/step - loss: 5.6075 - accuracy: 0.4541\n","Epoch 60/500\n","28/28 [==============================] - 0s 3ms/step - loss: 12.9149 - accuracy: 0.4702\n","Epoch 61/500\n","28/28 [==============================] - 0s 3ms/step - loss: 6.1123 - accuracy: 0.6117\n","Epoch 62/500\n","28/28 [==============================] - 0s 3ms/step - loss: 11.2701 - accuracy: 0.3917\n","Epoch 63/500\n","28/28 [==============================] - 0s 3ms/step - loss: 7.1725 - accuracy: 0.4686\n","Epoch 64/500\n","28/28 [==============================] - 0s 3ms/step - loss: 39.5880 - accuracy: 0.4568\n","Epoch 65/500\n","28/28 [==============================] - 0s 3ms/step - loss: 94.5070 - accuracy: 0.4219\n","Epoch 66/500\n","28/28 [==============================] - 0s 2ms/step - loss: 23.1606 - accuracy: 0.4657\n","Epoch 67/500\n","28/28 [==============================] - 0s 3ms/step - loss: 9.6107 - accuracy: 0.4483\n","Epoch 68/500\n","28/28 [==============================] - 0s 3ms/step - loss: 6.9585 - accuracy: 0.5220\n","Epoch 69/500\n","28/28 [==============================] - 0s 3ms/step - loss: 12.0897 - accuracy: 0.3685\n","Epoch 70/500\n","28/28 [==============================] - 0s 2ms/step - loss: 4.4798 - accuracy: 0.5517\n","Epoch 71/500\n","28/28 [==============================] - 0s 3ms/step - loss: 6.8550 - accuracy: 0.4695\n","Epoch 72/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.7331 - accuracy: 0.4704\n","Epoch 73/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.5366 - accuracy: 0.4310\n","Epoch 74/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.7258 - accuracy: 0.5961\n","Epoch 75/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.9857 - accuracy: 0.4540\n","Epoch 76/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.8987 - accuracy: 0.4945\n","Epoch 77/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.9239 - accuracy: 0.5121\n","Epoch 78/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.6380 - accuracy: 0.5146\n","Epoch 79/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.8028 - accuracy: 0.5029\n","Epoch 80/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.6630 - accuracy: 0.5899\n","Epoch 81/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.5201 - accuracy: 0.5681\n","Epoch 82/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.0854 - accuracy: 0.4675\n","Epoch 83/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.1744 - accuracy: 0.4895\n","Epoch 84/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.4815 - accuracy: 0.5216\n","Epoch 85/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.6722 - accuracy: 0.5242\n","Epoch 86/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.4028 - accuracy: 0.6047\n","Epoch 87/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.1592 - accuracy: 0.5239\n","Epoch 88/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.6434 - accuracy: 0.4942\n","Epoch 89/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.2832 - accuracy: 0.4580\n","Epoch 90/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0006 - accuracy: 0.6318\n","Epoch 91/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0362 - accuracy: 0.5546\n","Epoch 92/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2555 - accuracy: 0.5828\n","Epoch 93/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2289 - accuracy: 0.5877\n","Epoch 94/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1347 - accuracy: 0.5533\n","Epoch 95/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1002 - accuracy: 0.6289\n","Epoch 96/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0490 - accuracy: 0.6278\n","Epoch 97/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.5636 - accuracy: 0.5587\n","Epoch 98/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.8866 - accuracy: 0.3622\n","Epoch 99/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.0340 - accuracy: 0.5557\n","Epoch 100/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.3734 - accuracy: 0.6387\n","Epoch 101/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0825 - accuracy: 0.6018\n","Epoch 102/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.5948 - accuracy: 0.5598\n","Epoch 103/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1089 - accuracy: 0.5789\n","Epoch 104/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.0413 - accuracy: 0.4985\n","Epoch 105/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.2244 - accuracy: 0.4892\n","Epoch 106/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.3397 - accuracy: 0.5425\n","Epoch 107/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.6611 - accuracy: 0.5773\n","Epoch 108/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.6340 - accuracy: 0.4349\n","Epoch 109/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2268 - accuracy: 0.4477\n","Epoch 110/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1177 - accuracy: 0.5237\n","Epoch 111/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.5134 - accuracy: 0.6100\n","Epoch 112/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.3403 - accuracy: 0.6226\n","Epoch 113/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.6793 - accuracy: 0.5402\n","Epoch 114/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.4788 - accuracy: 0.4937\n","Epoch 115/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.8961 - accuracy: 0.4516\n","Epoch 116/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.2928 - accuracy: 0.5636\n","Epoch 117/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.8496 - accuracy: 0.5250\n","Epoch 118/500\n","28/28 [==============================] - 0s 2ms/step - loss: 6.8088 - accuracy: 0.4721\n","Epoch 119/500\n","28/28 [==============================] - 0s 2ms/step - loss: 3.7208 - accuracy: 0.4794\n","Epoch 120/500\n","28/28 [==============================] - 0s 3ms/step - loss: 3.0926 - accuracy: 0.4141\n","Epoch 121/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.9524 - accuracy: 0.5139\n","Epoch 122/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.0147 - accuracy: 0.5153\n","Epoch 123/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.5155 - accuracy: 0.5062\n","Epoch 124/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.8913 - accuracy: 0.5271\n","Epoch 125/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2574 - accuracy: 0.5398\n","Epoch 126/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.6826 - accuracy: 0.5031\n","Epoch 127/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0982 - accuracy: 0.6063\n","Epoch 128/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.6992 - accuracy: 0.5167\n","Epoch 129/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.3789 - accuracy: 0.5193\n","Epoch 130/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.3129 - accuracy: 0.6053\n","Epoch 131/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.0045 - accuracy: 0.5579\n","Epoch 132/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1648 - accuracy: 0.6098\n","Epoch 133/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.4394 - accuracy: 0.6098\n","Epoch 134/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.0688 - accuracy: 0.4312\n","Epoch 135/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.6950 - accuracy: 0.5219\n","Epoch 136/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.3678 - accuracy: 0.4977\n","Epoch 137/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.6185 - accuracy: 0.5177\n","Epoch 138/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.4075 - accuracy: 0.6095\n","Epoch 139/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.8552 - accuracy: 0.4218\n","Epoch 140/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.9126 - accuracy: 0.5575\n","Epoch 141/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.2603 - accuracy: 0.4953\n","Epoch 142/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.4583 - accuracy: 0.5320\n","Epoch 143/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0521 - accuracy: 0.5648\n","Epoch 144/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.7494 - accuracy: 0.5072\n","Epoch 145/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.2862 - accuracy: 0.4393\n","Epoch 146/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.9977 - accuracy: 0.4773\n","Epoch 147/500\n","28/28 [==============================] - 0s 2ms/step - loss: 132.0277 - accuracy: 0.3761\n","Epoch 148/500\n","28/28 [==============================] - 0s 3ms/step - loss: 87.6013 - accuracy: 0.3282\n","Epoch 149/500\n","28/28 [==============================] - 0s 3ms/step - loss: 22.8024 - accuracy: 0.2941\n","Epoch 150/500\n","28/28 [==============================] - 0s 3ms/step - loss: 29.3947 - accuracy: 0.3920\n","Epoch 151/500\n","28/28 [==============================] - 0s 3ms/step - loss: 20.2402 - accuracy: 0.4553\n","Epoch 152/500\n","28/28 [==============================] - 0s 3ms/step - loss: 33.1104 - accuracy: 0.4315\n","Epoch 153/500\n","28/28 [==============================] - 0s 3ms/step - loss: 29.2484 - accuracy: 0.4814\n","Epoch 154/500\n","28/28 [==============================] - 0s 3ms/step - loss: 149.6611 - accuracy: 0.4059\n","Epoch 155/500\n","28/28 [==============================] - 0s 3ms/step - loss: 21.7289 - accuracy: 0.4379\n","Epoch 156/500\n","28/28 [==============================] - 0s 3ms/step - loss: 34.2843 - accuracy: 0.2558\n","Epoch 157/500\n","28/28 [==============================] - 0s 3ms/step - loss: 56.7269 - accuracy: 0.4274\n","Epoch 158/500\n","28/28 [==============================] - 0s 3ms/step - loss: 19.3816 - accuracy: 0.4326\n","Epoch 159/500\n","28/28 [==============================] - 0s 3ms/step - loss: 21.0381 - accuracy: 0.5465\n","Epoch 160/500\n","28/28 [==============================] - 0s 3ms/step - loss: 17.1953 - accuracy: 0.5159\n","Epoch 161/500\n","28/28 [==============================] - 0s 3ms/step - loss: 4.7636 - accuracy: 0.5176\n","Epoch 162/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2694 - accuracy: 0.4432\n","Epoch 163/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.8190 - accuracy: 0.4945\n","Epoch 164/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.2864 - accuracy: 0.4874\n","Epoch 165/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1746 - accuracy: 0.5134\n","Epoch 166/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1694 - accuracy: 0.5015\n","Epoch 167/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1551 - accuracy: 0.5242\n","Epoch 168/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1565 - accuracy: 0.5289\n","Epoch 169/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0275 - accuracy: 0.5946\n","Epoch 170/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1097 - accuracy: 0.4815\n","Epoch 171/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1271 - accuracy: 0.5409\n","Epoch 172/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2295 - accuracy: 0.5103\n","Epoch 173/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1152 - accuracy: 0.4744\n","Epoch 174/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0590 - accuracy: 0.5095\n","Epoch 175/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0621 - accuracy: 0.5684\n","Epoch 176/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1673 - accuracy: 0.4660\n","Epoch 177/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0566 - accuracy: 0.4833\n","Epoch 178/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1071 - accuracy: 0.4794\n","Epoch 179/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0529 - accuracy: 0.5175\n","Epoch 180/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0976 - accuracy: 0.5361\n","Epoch 181/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0328 - accuracy: 0.4965\n","Epoch 182/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0143 - accuracy: 0.5387\n","Epoch 183/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0518 - accuracy: 0.5738\n","Epoch 184/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0649 - accuracy: 0.4563\n","Epoch 185/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0733 - accuracy: 0.5284\n","Epoch 186/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9585 - accuracy: 0.5767\n","Epoch 187/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0271 - accuracy: 0.4792\n","Epoch 188/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0813 - accuracy: 0.4665\n","Epoch 189/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0118 - accuracy: 0.5390\n","Epoch 190/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9847 - accuracy: 0.5681\n","Epoch 191/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0658 - accuracy: 0.5020\n","Epoch 192/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0359 - accuracy: 0.5556\n","Epoch 193/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0146 - accuracy: 0.4893\n","Epoch 194/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0289 - accuracy: 0.5626\n","Epoch 195/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9896 - accuracy: 0.5243\n","Epoch 196/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0532 - accuracy: 0.5018\n","Epoch 197/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1209 - accuracy: 0.4722\n","Epoch 198/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9981 - accuracy: 0.4808\n","Epoch 199/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0015 - accuracy: 0.5695\n","Epoch 200/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0140 - accuracy: 0.5822\n","Epoch 201/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9605 - accuracy: 0.5160\n","Epoch 202/500\n","28/28 [==============================] - 0s 4ms/step - loss: 1.0653 - accuracy: 0.5591\n","Epoch 203/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9636 - accuracy: 0.6010\n","Epoch 204/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9891 - accuracy: 0.5218\n","Epoch 205/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0289 - accuracy: 0.5500\n","Epoch 206/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0466 - accuracy: 0.5345\n","Epoch 207/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9838 - accuracy: 0.5336\n","Epoch 208/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0663 - accuracy: 0.4414\n","Epoch 209/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9261 - accuracy: 0.5270\n","Epoch 210/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9147 - accuracy: 0.6081\n","Epoch 211/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0117 - accuracy: 0.5586\n","Epoch 212/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9887 - accuracy: 0.6414\n","Epoch 213/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9843 - accuracy: 0.4801\n","Epoch 214/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0238 - accuracy: 0.5661\n","Epoch 215/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9115 - accuracy: 0.5520\n","Epoch 216/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9576 - accuracy: 0.6202\n","Epoch 217/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0685 - accuracy: 0.4605\n","Epoch 218/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0146 - accuracy: 0.4918\n","Epoch 219/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0260 - accuracy: 0.5040\n","Epoch 220/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9770 - accuracy: 0.5438\n","Epoch 221/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9884 - accuracy: 0.5106\n","Epoch 222/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0441 - accuracy: 0.4673\n","Epoch 223/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0553 - accuracy: 0.4714\n","Epoch 224/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1308 - accuracy: 0.4097\n","Epoch 225/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0253 - accuracy: 0.4634\n","Epoch 226/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9225 - accuracy: 0.5689\n","Epoch 227/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9475 - accuracy: 0.5333\n","Epoch 228/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9368 - accuracy: 0.5457\n","Epoch 229/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0429 - accuracy: 0.4739\n","Epoch 230/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0960 - accuracy: 0.4860\n","Epoch 231/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2268 - accuracy: 0.3361\n","Epoch 232/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0366 - accuracy: 0.4816\n","Epoch 233/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0336 - accuracy: 0.4929\n","Epoch 234/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0842 - accuracy: 0.4455\n","Epoch 235/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0848 - accuracy: 0.5289\n","Epoch 236/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0376 - accuracy: 0.4694\n","Epoch 237/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0507 - accuracy: 0.4608\n","Epoch 238/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9068 - accuracy: 0.5922\n","Epoch 239/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0295 - accuracy: 0.5337\n","Epoch 240/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0069 - accuracy: 0.5218\n","Epoch 241/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0234 - accuracy: 0.5526\n","Epoch 242/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0076 - accuracy: 0.5688\n","Epoch 243/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0268 - accuracy: 0.5541\n","Epoch 244/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0425 - accuracy: 0.5773\n","Epoch 245/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9430 - accuracy: 0.5764\n","Epoch 246/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9503 - accuracy: 0.5462\n","Epoch 247/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9617 - accuracy: 0.5483\n","Epoch 248/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0311 - accuracy: 0.5480\n","Epoch 249/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0847 - accuracy: 0.4812\n","Epoch 250/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9785 - accuracy: 0.4993\n","Epoch 251/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9960 - accuracy: 0.5168\n","Epoch 252/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0094 - accuracy: 0.5148\n","Epoch 253/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9572 - accuracy: 0.5331\n","Epoch 254/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9992 - accuracy: 0.5722\n","Epoch 255/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0990 - accuracy: 0.4647\n","Epoch 256/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9656 - accuracy: 0.5256\n","Epoch 257/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0628 - accuracy: 0.4833\n","Epoch 258/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9814 - accuracy: 0.5530\n","Epoch 259/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9662 - accuracy: 0.5949\n","Epoch 260/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9270 - accuracy: 0.5800\n","Epoch 261/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9698 - accuracy: 0.5543\n","Epoch 262/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1526 - accuracy: 0.4014\n","Epoch 263/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0212 - accuracy: 0.5383\n","Epoch 264/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0328 - accuracy: 0.5033\n","Epoch 265/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9899 - accuracy: 0.4975\n","Epoch 266/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9425 - accuracy: 0.5086\n","Epoch 267/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0368 - accuracy: 0.5516\n","Epoch 268/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0562 - accuracy: 0.4647\n","Epoch 269/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9606 - accuracy: 0.5396\n","Epoch 270/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9840 - accuracy: 0.5553\n","Epoch 271/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0251 - accuracy: 0.4619\n","Epoch 272/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.8833 - accuracy: 0.6089\n","Epoch 273/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1362 - accuracy: 0.5234\n","Epoch 274/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0164 - accuracy: 0.5183\n","Epoch 275/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9662 - accuracy: 0.5631\n","Epoch 276/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0167 - accuracy: 0.5572\n","Epoch 277/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0472 - accuracy: 0.5330\n","Epoch 278/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9814 - accuracy: 0.5262\n","Epoch 279/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0052 - accuracy: 0.5140\n","Epoch 280/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9385 - accuracy: 0.5136\n","Epoch 281/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0057 - accuracy: 0.4901\n","Epoch 282/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9553 - accuracy: 0.5423\n","Epoch 283/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0719 - accuracy: 0.5734\n","Epoch 284/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9541 - accuracy: 0.5760\n","Epoch 285/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9709 - accuracy: 0.5176\n","Epoch 286/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0140 - accuracy: 0.5209\n","Epoch 287/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1331 - accuracy: 0.5716\n","Epoch 288/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0552 - accuracy: 0.5447\n","Epoch 289/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1857 - accuracy: 0.3380\n","Epoch 290/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1466 - accuracy: 0.3454\n","Epoch 291/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1978 - accuracy: 0.3982\n","Epoch 292/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0954 - accuracy: 0.4615\n","Epoch 293/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1163 - accuracy: 0.3937\n","Epoch 294/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1321 - accuracy: 0.3702\n","Epoch 295/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1441 - accuracy: 0.3375\n","Epoch 296/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0497 - accuracy: 0.4436\n","Epoch 297/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1619 - accuracy: 0.3377\n","Epoch 298/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1436 - accuracy: 0.3345\n","Epoch 299/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1209 - accuracy: 0.3984\n","Epoch 300/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1142 - accuracy: 0.3665\n","Epoch 301/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0562 - accuracy: 0.5477\n","Epoch 302/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0735 - accuracy: 0.5479\n","Epoch 303/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0396 - accuracy: 0.5579\n","Epoch 304/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0423 - accuracy: 0.5585\n","Epoch 305/500\n","28/28 [==============================] - 0s 4ms/step - loss: 1.0328 - accuracy: 0.5076\n","Epoch 306/500\n","28/28 [==============================] - 0s 3ms/step - loss: 0.9946 - accuracy: 0.5154\n","Epoch 307/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0636 - accuracy: 0.5230\n","Epoch 308/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0589 - accuracy: 0.5100\n","Epoch 309/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0721 - accuracy: 0.4910\n","Epoch 310/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0715 - accuracy: 0.5762\n","Epoch 311/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0559 - accuracy: 0.5645\n","Epoch 312/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0571 - accuracy: 0.5150\n","Epoch 313/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0538 - accuracy: 0.4349\n","Epoch 314/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0358 - accuracy: 0.4757\n","Epoch 315/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0825 - accuracy: 0.4796\n","Epoch 316/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2612 - accuracy: 0.4747\n","Epoch 317/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1281 - accuracy: 0.5087\n","Epoch 318/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1371 - accuracy: 0.5189\n","Epoch 319/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0955 - accuracy: 0.5066\n","Epoch 320/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0797 - accuracy: 0.5344\n","Epoch 321/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1068 - accuracy: 0.5293\n","Epoch 322/500\n","28/28 [==============================] - 0s 4ms/step - loss: 1.0797 - accuracy: 0.4737\n","Epoch 323/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1053 - accuracy: 0.5135\n","Epoch 324/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1085 - accuracy: 0.5307\n","Epoch 325/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0179 - accuracy: 0.6119\n","Epoch 326/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0857 - accuracy: 0.5161\n","Epoch 327/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1116 - accuracy: 0.4404\n","Epoch 328/500\n","28/28 [==============================] - 0s 3ms/step - loss: 2.6987 - accuracy: 0.5014\n","Epoch 329/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.3232 - accuracy: 0.4970\n","Epoch 330/500\n","28/28 [==============================] - 0s 2ms/step - loss: 2.3645 - accuracy: 0.4482\n","Epoch 331/500\n","28/28 [==============================] - 0s 2ms/step - loss: 6.6868 - accuracy: 0.5017\n","Epoch 332/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0321 - accuracy: 0.5453\n","Epoch 333/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0957 - accuracy: 0.5348\n","Epoch 334/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1023 - accuracy: 0.4685\n","Epoch 335/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1607 - accuracy: 0.4553\n","Epoch 336/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1040 - accuracy: 0.5443\n","Epoch 337/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1102 - accuracy: 0.4799\n","Epoch 338/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1367 - accuracy: 0.5063\n","Epoch 339/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0869 - accuracy: 0.5186\n","Epoch 340/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1496 - accuracy: 0.4196\n","Epoch 341/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0805 - accuracy: 0.4979\n","Epoch 342/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1152 - accuracy: 0.5022\n","Epoch 343/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1265 - accuracy: 0.4735\n","Epoch 344/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1128 - accuracy: 0.4212\n","Epoch 345/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0412 - accuracy: 0.5326\n","Epoch 346/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0455 - accuracy: 0.5521\n","Epoch 347/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1498 - accuracy: 0.4591\n","Epoch 348/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0389 - accuracy: 0.4805\n","Epoch 349/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1239 - accuracy: 0.5095\n","Epoch 350/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0878 - accuracy: 0.4713\n","Epoch 351/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1067 - accuracy: 0.4480\n","Epoch 352/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0845 - accuracy: 0.5148\n","Epoch 353/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0084 - accuracy: 0.5575\n","Epoch 354/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0407 - accuracy: 0.5472\n","Epoch 355/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0506 - accuracy: 0.4838\n","Epoch 356/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1098 - accuracy: 0.4360\n","Epoch 357/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1145 - accuracy: 0.4719\n","Epoch 358/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0716 - accuracy: 0.4693\n","Epoch 359/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0935 - accuracy: 0.4970\n","Epoch 360/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1175 - accuracy: 0.4849\n","Epoch 361/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0693 - accuracy: 0.4743\n","Epoch 362/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0875 - accuracy: 0.4888\n","Epoch 363/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0887 - accuracy: 0.4636\n","Epoch 364/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0304 - accuracy: 0.5101\n","Epoch 365/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0612 - accuracy: 0.5071\n","Epoch 366/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0814 - accuracy: 0.4987\n","Epoch 367/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0583 - accuracy: 0.4106\n","Epoch 368/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1106 - accuracy: 0.5229\n","Epoch 369/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1076 - accuracy: 0.4508\n","Epoch 370/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1711 - accuracy: 0.4434\n","Epoch 371/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0898 - accuracy: 0.4772\n","Epoch 372/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0910 - accuracy: 0.5202\n","Epoch 373/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0628 - accuracy: 0.5183\n","Epoch 374/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0777 - accuracy: 0.5284\n","Epoch 375/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1396 - accuracy: 0.4610\n","Epoch 376/500\n","28/28 [==============================] - 0s 2ms/step - loss: 0.9978 - accuracy: 0.5118\n","Epoch 377/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0759 - accuracy: 0.5031\n","Epoch 378/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1808 - accuracy: 0.4764\n","Epoch 379/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0228 - accuracy: 0.5322\n","Epoch 380/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0967 - accuracy: 0.4572\n","Epoch 381/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0693 - accuracy: 0.5237\n","Epoch 382/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1358 - accuracy: 0.4803\n","Epoch 383/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1685 - accuracy: 0.4882\n","Epoch 384/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0869 - accuracy: 0.5018\n","Epoch 385/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1699 - accuracy: 0.4606\n","Epoch 386/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0431 - accuracy: 0.5070\n","Epoch 387/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0441 - accuracy: 0.5265\n","Epoch 388/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0952 - accuracy: 0.4786\n","Epoch 389/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0967 - accuracy: 0.4727\n","Epoch 390/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0488 - accuracy: 0.4842\n","Epoch 391/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1550 - accuracy: 0.4422\n","Epoch 392/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1119 - accuracy: 0.5284\n","Epoch 393/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0472 - accuracy: 0.5156\n","Epoch 394/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1607 - accuracy: 0.4409\n","Epoch 395/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0302 - accuracy: 0.5074\n","Epoch 396/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1642 - accuracy: 0.5077\n","Epoch 397/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0811 - accuracy: 0.5154\n","Epoch 398/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0835 - accuracy: 0.4100\n","Epoch 399/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0383 - accuracy: 0.5196\n","Epoch 400/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1912 - accuracy: 0.3739\n","Epoch 401/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0996 - accuracy: 0.4983\n","Epoch 402/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1122 - accuracy: 0.4385\n","Epoch 403/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0514 - accuracy: 0.4933\n","Epoch 404/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1511 - accuracy: 0.4625\n","Epoch 405/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0756 - accuracy: 0.4957\n","Epoch 406/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0455 - accuracy: 0.4616\n","Epoch 407/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0233 - accuracy: 0.5486\n","Epoch 408/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1815 - accuracy: 0.4111\n","Epoch 409/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0750 - accuracy: 0.4636\n","Epoch 410/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1248 - accuracy: 0.5127\n","Epoch 411/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0982 - accuracy: 0.5196\n","Epoch 412/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1304 - accuracy: 0.4523\n","Epoch 413/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1775 - accuracy: 0.4071\n","Epoch 414/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1227 - accuracy: 0.4580\n","Epoch 415/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2118 - accuracy: 0.4459\n","Epoch 416/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1714 - accuracy: 0.4367\n","Epoch 417/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0628 - accuracy: 0.5606\n","Epoch 418/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0697 - accuracy: 0.5586\n","Epoch 419/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1325 - accuracy: 0.4377\n","Epoch 420/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0257 - accuracy: 0.5064\n","Epoch 421/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1240 - accuracy: 0.4211\n","Epoch 422/500\n","28/28 [==============================] - 0s 4ms/step - loss: 1.0684 - accuracy: 0.4585\n","Epoch 423/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0321 - accuracy: 0.5061\n","Epoch 424/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1231 - accuracy: 0.4202\n","Epoch 425/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1094 - accuracy: 0.5253\n","Epoch 426/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0593 - accuracy: 0.5815\n","Epoch 427/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1454 - accuracy: 0.4373\n","Epoch 428/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0799 - accuracy: 0.4800\n","Epoch 429/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0515 - accuracy: 0.4648\n","Epoch 430/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1110 - accuracy: 0.4632\n","Epoch 431/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1382 - accuracy: 0.4552\n","Epoch 432/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1479 - accuracy: 0.4112\n","Epoch 433/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1231 - accuracy: 0.4799\n","Epoch 434/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1376 - accuracy: 0.4541\n","Epoch 435/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0452 - accuracy: 0.5157\n","Epoch 436/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0856 - accuracy: 0.4874\n","Epoch 437/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0817 - accuracy: 0.5111\n","Epoch 438/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1059 - accuracy: 0.4859\n","Epoch 439/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1220 - accuracy: 0.4697\n","Epoch 440/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0927 - accuracy: 0.4782\n","Epoch 441/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1715 - accuracy: 0.4515\n","Epoch 442/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1507 - accuracy: 0.4515\n","Epoch 443/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1226 - accuracy: 0.4590\n","Epoch 444/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1115 - accuracy: 0.4498\n","Epoch 445/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1117 - accuracy: 0.4659\n","Epoch 446/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0417 - accuracy: 0.5138\n","Epoch 447/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1023 - accuracy: 0.4563\n","Epoch 448/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1403 - accuracy: 0.4455\n","Epoch 449/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0944 - accuracy: 0.4616\n","Epoch 450/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0684 - accuracy: 0.5329\n","Epoch 451/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1111 - accuracy: 0.4761\n","Epoch 452/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1083 - accuracy: 0.4855\n","Epoch 453/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0337 - accuracy: 0.5223\n","Epoch 454/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1053 - accuracy: 0.4995\n","Epoch 455/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1709 - accuracy: 0.4719\n","Epoch 456/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1219 - accuracy: 0.4740\n","Epoch 457/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1200 - accuracy: 0.5019\n","Epoch 458/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1116 - accuracy: 0.4886\n","Epoch 459/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0978 - accuracy: 0.4958\n","Epoch 460/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1735 - accuracy: 0.4821\n","Epoch 461/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1342 - accuracy: 0.4923\n","Epoch 462/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0462 - accuracy: 0.5252\n","Epoch 463/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0642 - accuracy: 0.4750\n","Epoch 464/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0398 - accuracy: 0.5155\n","Epoch 465/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1068 - accuracy: 0.4418\n","Epoch 466/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0856 - accuracy: 0.5181\n","Epoch 467/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0245 - accuracy: 0.5363\n","Epoch 468/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1146 - accuracy: 0.4371\n","Epoch 469/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0862 - accuracy: 0.4568\n","Epoch 470/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1077 - accuracy: 0.4890\n","Epoch 471/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1339 - accuracy: 0.4839\n","Epoch 472/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0860 - accuracy: 0.5299\n","Epoch 473/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1059 - accuracy: 0.5039\n","Epoch 474/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1017 - accuracy: 0.5173\n","Epoch 475/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1225 - accuracy: 0.4831\n","Epoch 476/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1470 - accuracy: 0.4702\n","Epoch 477/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0831 - accuracy: 0.4802\n","Epoch 478/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1287 - accuracy: 0.4872\n","Epoch 479/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0920 - accuracy: 0.4611\n","Epoch 480/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1068 - accuracy: 0.5290\n","Epoch 481/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1072 - accuracy: 0.4717\n","Epoch 482/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1353 - accuracy: 0.4639\n","Epoch 483/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0922 - accuracy: 0.4774\n","Epoch 484/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0999 - accuracy: 0.4880\n","Epoch 485/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0171 - accuracy: 0.5302\n","Epoch 486/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0610 - accuracy: 0.5245\n","Epoch 487/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0690 - accuracy: 0.4797\n","Epoch 488/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1717 - accuracy: 0.5185\n","Epoch 489/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0915 - accuracy: 0.4592\n","Epoch 490/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0906 - accuracy: 0.4961\n","Epoch 491/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1922 - accuracy: 0.4259\n","Epoch 492/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0883 - accuracy: 0.4304\n","Epoch 493/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.1224 - accuracy: 0.4940\n","Epoch 494/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0914 - accuracy: 0.5186\n","Epoch 495/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.2334 - accuracy: 0.4326\n","Epoch 496/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0991 - accuracy: 0.5027\n","Epoch 497/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1179 - accuracy: 0.5015\n","Epoch 498/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.1498 - accuracy: 0.4916\n","Epoch 499/500\n","28/28 [==============================] - 0s 3ms/step - loss: 1.0720 - accuracy: 0.4503\n","Epoch 500/500\n","28/28 [==============================] - 0s 2ms/step - loss: 1.0231 - accuracy: 0.4713\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa0145fc9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 160ms/step - loss: 1.0858 - accuracy: 0.4667\n","\n"," 10 fold accuracy: ['0.4375', '0.2500', '0.5625', '0.5000', '0.5000', '0.4667', '0.5333', '0.4667', '0.4667', '0.4667']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9ypovYWfdJ5i"},"source":[""],"execution_count":null,"outputs":[]}]}