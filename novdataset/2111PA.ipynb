{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3611,"status":"ok","timestamp":1642029900850,"user":{"displayName":"최은우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09535764796893882081"},"user_tz":-540},"id":"jbEIH2WGI85_"},"outputs":[],"source":["#데이터셋 불러오고 X, Y 정하기\n","import numpy as np\n","import pandas as pd\n","\n","# ANN으로 한 번, 커널로 한 번, 트리나 xgb로 한 번, 다른 거 추가할 수 있으면 추가\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/Inhibitor classification/novdataset/PA_nov_Molprint2.csv\", index_col=None)\n","X = df.iloc[:,:-1].values\n","Y = df.iloc[:,-1].values\n","\n","seed=0\n","np.random.seed(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":842,"status":"ok","timestamp":1638339347295,"user":{"displayName":"최은우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09535764796893882081"},"user_tz":-540},"id":"dG1qR0XlxbM5","outputId":"acf3f18f-1326-46c4-ca84-b12e7930742f"},"outputs":[{"data":{"text/plain":["(115, 205)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["#feature 추리기\n","\n","#편차 거의 없는 거 제외하기\n","from sklearn.feature_selection import VarianceThreshold\n","\n","sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n","X = sel.fit_transform(X)\n","\n","#본격적인 피처 추리기\n","from sklearn.feature_selection import GenericUnivariateSelect, f_classif\n","\n","transformer = GenericUnivariateSelect(f_classif, mode='percentile', param=20)\n","X_new = transformer.fit_transform(X, Y)\n","X_new.shape\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"bcMa4IupvzJ4","executionInfo":{"status":"ok","timestamp":1641772638636,"user_tz":-540,"elapsed":315,"user":{"displayName":"최은우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09535764796893882081"}}},"outputs":[],"source":["#train, testset 나누기\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer, RobustScaler, MaxAbsScaler,  QuantileTransformer\n","from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n","#scaler = StandardScaler()\n","#X_scaled = scaler.fit_transform(X)\n","\n","train_input, test_input, train_target, test_target = train_test_split(X, Y, test_size=0.2, random_state=seed)\n","#정확도 어느 정도 올라가면 train이랑 test set 별도로 저장하기"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8wHGqxBAPdyQ","executionInfo":{"status":"ok","timestamp":1642029907437,"user_tz":-540,"elapsed":1078,"user":{"displayName":"최은우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09535764796893882081"}}},"outputs":[],"source":["#층화임의추출\n","\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n","\n","for train_index, test_index in sss.split(X, Y):\n","    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","    X_train, X_test = X[train_index], X[test_index]\n","    Y_train, Y_test = Y[train_index], Y[test_index]"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"pPvrKS05HPr8","executionInfo":{"status":"ok","timestamp":1642029909421,"user_tz":-540,"elapsed":437,"user":{"displayName":"최은우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09535764796893882081"}}},"outputs":[],"source":["#Train만 oversampling\n","from imblearn.over_sampling import SMOTE\n","\n","smote = SMOTE(random_state=seed)\n","X_over, Y_over = smote.fit_resample(X_train, Y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"skC8fvmIKOAC","executionInfo":{"status":"ok","timestamp":1638959786501,"user_tz":-540,"elapsed":849069,"user":{"displayName":"최은우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09535764796893882081"}},"outputId":"6459c4c2-0927-4cd9-80be-006fa5711d89"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'C': 4.685334837751994, 'gamma': 0.17213362209787414, 'kernel': 'rbf'}\n","SVM train 정확도: 0.9521\n","SVM test 정확도: 0.8696\n","SVM total 정확도: 0.8783\n","[[46  0  0  1]\n"," [ 0 47  0  0]\n"," [ 0  0 40  7]\n"," [ 0  0  1 46]]\n","[[ 5  0  0  0]\n"," [ 1 12  0  0]\n"," [ 0  0  2  0]\n"," [ 0  2  0  1]]\n","[[27  5  0  0]\n"," [ 4 55  0  0]\n"," [ 0  2  9  0]\n"," [ 0  3  0 10]]\n"]}],"source":["# SVC로 분류해보기\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer, RobustScaler, MaxAbsScaler,  QuantileTransformer\n","from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n","from sklearn.utils.fixes import loguniform\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from imblearn.combine import SMOTEENN\n","\n","#smote = SMOTEENN(random_state=seed)\n","#X_over, Y_over = smote.fit_resample(X_train, Y_train)\n","\n","#scaler = StandardScaler()\n","#X_scaled = scaler.fit_transform(X)\n","\n","#train_input, test_input, train_target, test_target = train_test_split(X, Y, test_size=0.2, random_state=seed)\n","\n","param_grid = [{'kernel':['poly','rbf','linear','sigmoid'],  'C': loguniform(1, 1e3), 'gamma': loguniform(1e-3, 1)}]\n","grid =RandomizedSearchCV(SVC(probability=True, random_state=seed), param_grid, n_jobs=-1, n_iter=5000, cv=5, scoring='accuracy')\n","svc = SVC(probability=True, random_state=seed)\n","grid.fit(X_over, Y_over)\n","\n","pred_train = grid.predict(X_over)\n","pred_test = grid.predict(test_input)\n","pred_total = grid.predict(X)\n","accuracy = accuracy_score(Y_over, pred_train)\n","ex_accuracy = accuracy_score(test_target, pred_test)\n","tot_accuracy = accuracy_score(Y, pred_total)\n","\n","print(grid.best_params_)\n","\n","print('SVM train 정확도: {0:.4f}'.format(accuracy))\n","print('SVM test 정확도: {0:.4f}'.format(ex_accuracy))\n","print('SVM total 정확도: {0:.4f}'.format(tot_accuracy))\n","\n","conf = confusion_matrix(Y_over, pred_train, labels=[0,1,2,3])\n","exconf = confusion_matrix(test_target, pred_test, labels=[0,1,2,3])\n","totconf = confusion_matrix(Y, pred_total, labels=[0,1,2,3])\n","\n","print(conf)\n","print(exconf)\n","print(totconf)\n","\n","#모델 저장 \n","import joblib\n","\n","svm = grid.best_estimator_\n","\n","saved_model = joblib.dump(svm,'/content/drive/MyDrive/Inhibitor classification/novdataset/PA_SVM_1203_molprint2_over_tune05.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5258370,"status":"ok","timestamp":1640773322910,"user":{"displayName":"최은우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09535764796893882081"},"user_tz":-540},"id":"wYcDJrMtvtRk","outputId":"0f4702fe-5617-41e8-da0f-37066e8e5cb6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","50 fits failed out of a total of 500.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n","    callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n","    xgb_model=xgb_model, callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n","    bst.update(dtrain, i, obj)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n","    dtrain.handle))\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n","    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n","xgboost.core.XGBoostError: value 1.00068 for Parameter subsample exceed bound [0,1]\n","\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n","    callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n","    xgb_model=xgb_model, callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n","    bst.update(dtrain, i, obj)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n","    dtrain.handle))\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n","    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n","xgboost.core.XGBoostError: value 1.03206 for Parameter subsample exceed bound [0,1]\n","\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n","    callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n","    xgb_model=xgb_model, callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n","    bst.update(dtrain, i, obj)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n","    dtrain.handle))\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n","    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n","xgboost.core.XGBoostError: value 1.04278 for Parameter subsample exceed bound [0,1]\n","\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n","    callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n","    xgb_model=xgb_model, callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n","    bst.update(dtrain, i, obj)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n","    dtrain.handle))\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n","    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n","xgboost.core.XGBoostError: value 1.03384 for Parameter subsample exceed bound [0,1]\n","\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n","    callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n","    xgb_model=xgb_model, callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n","    bst.update(dtrain, i, obj)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n","    dtrain.handle))\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n","    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n","xgboost.core.XGBoostError: value 1.04383 for Parameter subsample exceed bound [0,1]\n","\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n","    callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n","    xgb_model=xgb_model, callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n","    bst.update(dtrain, i, obj)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n","    dtrain.handle))\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n","    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n","xgboost.core.XGBoostError: value 1.07477 for Parameter subsample exceed bound [0,1]\n","\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n","    callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n","    xgb_model=xgb_model, callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n","    bst.update(dtrain, i, obj)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n","    dtrain.handle))\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n","    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n","xgboost.core.XGBoostError: value 1.08912 for Parameter subsample exceed bound [0,1]\n","\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n","    callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n","    xgb_model=xgb_model, callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n","    bst.update(dtrain, i, obj)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n","    dtrain.handle))\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n","    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n","xgboost.core.XGBoostError: value 1.05751 for Parameter subsample exceed bound [0,1]\n","\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n","    callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n","    xgb_model=xgb_model, callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n","    bst.update(dtrain, i, obj)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n","    dtrain.handle))\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n","    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n","xgboost.core.XGBoostError: value 1.05222 for Parameter subsample exceed bound [0,1]\n","\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n","    callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n","    xgb_model=xgb_model, callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n","    bst.update(dtrain, i, obj)\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n","    dtrain.handle))\n","  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 176, in _check_call\n","    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n","xgboost.core.XGBoostError: value 1.06493 for Parameter subsample exceed bound [0,1]\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.24480797 0.54324324 0.67596017        nan 0.65462304 0.50526316\n"," 0.55917496 0.54822191 0.6601707  0.69758179 0.56458037 0.67596017\n"," 0.41536273 0.66543385 0.62816501 0.63399716 0.56984353 0.61251778\n"," 0.25547653 0.62788051 0.68691323 0.5002845  0.58051209 0.67055477\n"," 0.57510669 0.64978663 0.66529161 0.67041252 0.68108108 0.58065434\n"," 0.59658606 0.67098151 0.49473684 0.67098151 0.5487909         nan\n"," 0.68648649 0.57510669 0.30426743 0.60725462 0.66002845 0.49985775\n"," 0.56984353 0.68150782 0.67027027 0.68662873 0.50554765 0.66486486\n","        nan 0.60170697 0.66529161 0.53214794 0.33058321 0.23940256\n"," 0.68662873 0.52645804 0.67083926 0.47866287        nan 0.64935989\n"," 0.51052632 0.5        0.62788051 0.6601707  0.67638691 0.67055477\n","        nan        nan 0.23940256 0.40995733 0.48933144 0.61792319\n"," 0.67553343 0.68136558 0.59103841 0.6544808  0.67581792 0.66031294\n"," 0.64423898 0.52133713 0.65490754        nan 0.64423898 0.66500711\n"," 0.46244666 0.24466572 0.36216216 0.53769559 0.64935989 0.5916074\n"," 0.61792319 0.64423898 0.67041252 0.5913229  0.59118065 0.67596017\n","        nan        nan 0.66002845        nan]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["{'gamma': 0.16897605441274532, 'learning_rate': 0.11907525266549945, 'max_depth': 17, 'min_child_weight': 0.7454811652397759, 'n_estimators': 1882, 'subsample': 0.4112467981437029}\n","xgb train 정확도: 0.9681\n","[[46  0  0  1]\n"," [ 0 47  0  0]\n"," [ 0  0 42  5]\n"," [ 0  0  0 47]]\n","xgb test 정확도: 0.3478\n","[[3 3 0 0]\n"," [5 4 1 2]\n"," [0 1 0 1]\n"," [0 1 1 1]]\n","xgb 전체 정확도: 0.8696\n","[[29  3  0  0]\n"," [ 5 51  1  2]\n"," [ 0  1  9  1]\n"," [ 0  1  1 11]]\n"]}],"source":["#xgboost\n","import xgboost as xgb\n","\n","from xgboost import XGBClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from scipy.stats import randint, uniform, loguniform\n","\n","xgb = XGBClassifier()\n","params = {'max_depth': list(range(2,20)),'learning_rate': uniform(1e-5, 0.3),'subsample': uniform(0.1, 1), \n","          'min_child_weight': uniform(0.5, 10),'gamma': uniform(0, 1),'n_estimators': list(range(500, 2000))}\n","\n","xgb_wrapper = RandomizedSearchCV(xgb, params, n_iter = 100, n_jobs=-1, cv=5)\n","\n","xgbs = xgb_wrapper.fit(X_over, Y_over)\n","\n","best_params = xgbs.best_params_\n","print(best_params)\n","xgbs1 = xgbs.best_estimator_\n","#xgbs1 = xgb.fit(X_over, Y_over)\n","pred = xgbs1.predict(X_over)\n","accuracy = accuracy_score(Y_over, pred)\n","print('xgb train 정확도: {0:.4f}'.format(accuracy))\n","conf_matrix = confusion_matrix(Y_over, pred)\n","print(conf_matrix)\n","\n","expred = xgbs1.predict(X_test)\n","accuracy = accuracy_score(Y_test, expred)\n","print('xgb test 정확도: {0:.4f}'.format(accuracy))\n","ex_conf_matrix = confusion_matrix(Y_test, expred)\n","print(ex_conf_matrix)\n","\n","totpred = xgbs1.predict(X)\n","accuracy = accuracy_score(Y, totpred)\n","print('xgb 전체 정확도: {0:.4f}'.format(accuracy))\n","tot_conf_matrix = confusion_matrix(Y, totpred)\n","print(tot_conf_matrix)\n","\n","\n","import joblib\n","\n","saved_model = joblib.dump(xgbs1,'/content/drive/MyDrive/Inhibitor classification/novdataset/PA_XGB_1229_over_tune04.pkl')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"4ovGzPE3vvRk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642037431019,"user_tz":-540,"elapsed":3644863,"user":{"displayName":"최은우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09535764796893882081"}},"outputId":"ae811bc8-2043-457c-b4e1-4b7e5a6ff55d"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'random_state': 7, 'n_estimators': 22, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_depth': 9, 'criterion': 'gini'}\n","rf train 정확도: 0.8777\n","[[40  1  3  3]\n"," [ 4 41  0  2]\n"," [ 0  0 38  9]\n"," [ 0  0  1 46]]\n","rf test 정확도: 0.3913\n","[[3 1 1 1]\n"," [3 3 2 4]\n"," [1 0 0 1]\n"," [0 0 0 3]]\n","rf 전체 정확도: 0.8000\n","[[27  2  2  1]\n"," [ 7 44  2  6]\n"," [ 1  0  8  2]\n"," [ 0  0  0 13]]\n"]}],"source":["#RF\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","\n","params = {'n_estimators': list(range(10,1000)), 'criterion': ['gini', 'entropy'], 'max_depth': list(range(2,10)), \n","          'min_samples_split': list(range(2,13)), 'min_samples_leaf': list(range(1,10)), 'random_state': list(range(1,100))}\n","\n","rf = RandomForestClassifier()\n","#rfs1 = rf.fit(X_over, Y_over)\n","\n","rf_wrapper = RandomizedSearchCV(rf, params, n_iter = 1000, n_jobs=-1, cv=5)\n","\n","rfs = rf_wrapper.fit(X_over, Y_over)\n","\n","best_params = rfs.best_params_\n","print(best_params)\n","rfs1 = rfs.best_estimator_\n","\n","pred = rfs1.predict(X_over)\n","accuracy = accuracy_score(Y_over, pred)\n","print('rf train 정확도: {0:.4f}'.format(accuracy))\n","conf_matrix = confusion_matrix(Y_over, pred)\n","print(conf_matrix)\n","\n","expred = rfs1.predict(X_test)\n","accuracy = accuracy_score(Y_test, expred)\n","print('rf test 정확도: {0:.4f}'.format(accuracy))\n","ex_conf_matrix = confusion_matrix(Y_test, expred)\n","print(ex_conf_matrix)\n","\n","totpred = rfs1.predict(X)\n","accuracy = accuracy_score(Y, totpred)\n","print('rf 전체 정확도: {0:.4f}'.format(accuracy))\n","tot_conf_matrix = confusion_matrix(Y, totpred)\n","print(tot_conf_matrix)\n","\n","\n","import joblib\n","\n","saved_model = joblib.dump(rfs1,'/content/drive/MyDrive/Inhibitor classification/novdataset/PA_RF_0113_overtune05.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yn5OnpamrdIo"},"outputs":[],"source":["#모델을 잘 만들어도 set 내부의 과적합 문제를 해결하지 못하면 의미가 없다.\n","#과적합 해결해야 함"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":155393,"status":"ok","timestamp":1637713695730,"user":{"displayName":"최은우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09535764796893882081"},"user_tz":-540},"id":"9yzrdp_NHkfh","outputId":"bd1b7528-6e17-4843-b172-562d2bb96124"},"outputs":[{"name":"stdout","output_type":"stream","text":["Score: 0.478 (0.500)\n"]}],"source":["#LOOCV 시험\n","import xgboost as xgb\n","\n","from numpy import mean\n","from numpy import std\n","from sklearn.model_selection import LeaveOneOut\n","from sklearn.ensemble import RandomForestClassifier # 0.4 중반\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import cross_val_score\n","from xgboost import XGBClassifier # 0.4 후반\n","from sklearn.linear_model import LogisticRegression # 0.47\n","from sklearn.svm import SVC #0.53\n","from lightgbm import LGBMClassifier #0.48\n","\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from scipy.stats import randint, uniform, loguniform\n","\n","# create loocv procedure\n","cv = LeaveOneOut()\n","# create model\n","model = LGBMClassifier(random_state=seed)\n","# evaluate model\n","scores = cross_val_score(model, X_scaled, Y, cv=cv, n_jobs=-1)\n","# report performance\n","print('Score: %.3f (%.3f)' % (mean(scores), std(scores)))\n","#print(cv.get_n_splits(X_scaled))\n","#print(cv.split(X_scaled))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W8IEarYXrGLv"},"outputs":[],"source":["#데이터 입력\n","df = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/Inhibitor/PA/MORDRED_2D/PA_morgan_2D_apppendscore_dropsmiles.csv')\n","data = pd.read_csv('/content/drive/MyDrive/Inhibitor classification/210518 dataset/PA/PA_descriptors_drop_SMILES.csv')\n","\n","#데이터 분류\n","ref = df.values\n","X_ref = ref[:,0:-1]\n","Y_ref = ref[:,-1]\n","\n","dataset = data.values\n","X = dataset\n","\n","#X 표준화\n","\n","scaler = StandardScaler()\n","\n","X_ref_scaled = scaler.fit_transform(X_ref)\n","X_scaled = scaler.transform(X)\n","\n","#load model\n","\n","loaded_model = joblib.load('/content/drive/MyDrive/Inhibitor classification/210518 dataset/PA/PA_SVC_0412_02.pkl')\n","\n","#모델로 예측\n","\n","pred = loaded_model.predict(X_scaled)\n","result = pd.DataFrame({'class' : pred})\n","complete = pd.concat([data, result], axis=1)\n","complete\n","complete.to_csv('/content/drive/MyDrive/Inhibitor classification/210518 dataset/PA/PA_result.csv')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"2111PA.ipynb","provenance":[],"mount_file_id":"1e4iuxvGp7mPq5U0DnBPcQe6Fo90a0yyr","authorship_tag":"ABX9TyMdKm/C9Edi4xAfeupyeT6C"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}